{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s1mphiw3/Malware-detection/blob/main/Copy_of_Untitled1_(1)_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2lv-cJ5HP4O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "572e4c74-bfba-464b-9f2c-86fa5c3f9075"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfVof9cBdopJ"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hURN0HhJHEmo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import seaborn as sns \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import balanced_accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxuq01s_dopM"
      },
      "source": [
        "# Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "la6Y1BKwHEmw"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/top_1000_pe_imports.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxa9ezSHHEmx"
      },
      "source": [
        "# Data Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "nlZrdlfGHEmy",
        "outputId": "237bc373-88f6-4e85-e87b-6e8521a7581e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               hash  GetProcAddress  ExitProcess  WriteFile  \\\n",
              "0  071e8c3f8922e186e57548cd4c703a5d               1            1          1   \n",
              "1  33f8e6d08a6aae939f25a8e0d63dd523               1            1          1   \n",
              "2  b68abd064e975e1c6d5f25e748663076               1            1          1   \n",
              "3  72049be7bd30ea61297ea624ae198067               1            1          1   \n",
              "4  c9b3700a77facf29172f32df6bc77f48               1            1          1   \n",
              "5  cc6217be863e606e49da90fee2252f52               0            0          0   \n",
              "6  f7a1a3c38809d807b3f5f4cc00b1e9b7               1            1          1   \n",
              "7  a2597ae310f53a6b70c6951a3245dc4a               1            1          1   \n",
              "8  164b56522eb24164184460f8523ed7e2               1            1          1   \n",
              "9  56ae1459ba61a14eb119982d6ec793d7               1            1          1   \n",
              "\n",
              "   GetLastError  CloseHandle  FreeLibrary  Sleep  GetStdHandle  \\\n",
              "0             1            1            1      1             1   \n",
              "1             1            1            1      1             1   \n",
              "2             1            1            0      1             0   \n",
              "3             1            0            0      1             1   \n",
              "4             1            1            1      1             1   \n",
              "5             0            0            0      0             0   \n",
              "6             1            1            1      1             1   \n",
              "7             1            1            1      1             1   \n",
              "8             1            1            1      1             1   \n",
              "9             1            1            1      0             1   \n",
              "\n",
              "   MultiByteToWideChar  ...  bind  RegEnumKeyExA  WinHttpOpen  _controlfp  \\\n",
              "0                    1  ...     0              0            0           0   \n",
              "1                    1  ...     0              0            0           0   \n",
              "2                    1  ...     0              1            0           0   \n",
              "3                    1  ...     0              0            0           0   \n",
              "4                    1  ...     0              0            0           0   \n",
              "5                    0  ...     0              0            0           0   \n",
              "6                    1  ...     0              0            0           0   \n",
              "7                    1  ...     0              0            0           0   \n",
              "8                    1  ...     1              0            0           0   \n",
              "9                    1  ...     0              0            0           0   \n",
              "\n",
              "   WinExec  GetSecurityDescriptorDacl  FindFirstFreeAce  GetTimeFormatW  \\\n",
              "0        0                          0                 0               0   \n",
              "1        0                          0                 0               0   \n",
              "2        0                          0                 0               0   \n",
              "3        0                          0                 0               0   \n",
              "4        0                          0                 0               0   \n",
              "5        0                          0                 0               0   \n",
              "6        0                          0                 0               0   \n",
              "7        0                          0                 0               0   \n",
              "8        0                          0                 0               0   \n",
              "9        0                          0                 0               0   \n",
              "\n",
              "   LookupAccountSidW  malware  \n",
              "0                  0        1  \n",
              "1                  0        1  \n",
              "2                  0        1  \n",
              "3                  0        1  \n",
              "4                  0        1  \n",
              "5                  0        1  \n",
              "6                  0        1  \n",
              "7                  0        1  \n",
              "8                  0        1  \n",
              "9                  0        1  \n",
              "\n",
              "[10 rows x 1002 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a4d0c7fa-8781-440f-a4fa-d760ae81ebae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hash</th>\n",
              "      <th>GetProcAddress</th>\n",
              "      <th>ExitProcess</th>\n",
              "      <th>WriteFile</th>\n",
              "      <th>GetLastError</th>\n",
              "      <th>CloseHandle</th>\n",
              "      <th>FreeLibrary</th>\n",
              "      <th>Sleep</th>\n",
              "      <th>GetStdHandle</th>\n",
              "      <th>MultiByteToWideChar</th>\n",
              "      <th>...</th>\n",
              "      <th>bind</th>\n",
              "      <th>RegEnumKeyExA</th>\n",
              "      <th>WinHttpOpen</th>\n",
              "      <th>_controlfp</th>\n",
              "      <th>WinExec</th>\n",
              "      <th>GetSecurityDescriptorDacl</th>\n",
              "      <th>FindFirstFreeAce</th>\n",
              "      <th>GetTimeFormatW</th>\n",
              "      <th>LookupAccountSidW</th>\n",
              "      <th>malware</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>071e8c3f8922e186e57548cd4c703a5d</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>33f8e6d08a6aae939f25a8e0d63dd523</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b68abd064e975e1c6d5f25e748663076</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>72049be7bd30ea61297ea624ae198067</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>c9b3700a77facf29172f32df6bc77f48</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>cc6217be863e606e49da90fee2252f52</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>f7a1a3c38809d807b3f5f4cc00b1e9b7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>a2597ae310f53a6b70c6951a3245dc4a</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>164b56522eb24164184460f8523ed7e2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>56ae1459ba61a14eb119982d6ec793d7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 1002 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4d0c7fa-8781-440f-a4fa-d760ae81ebae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a4d0c7fa-8781-440f-a4fa-d760ae81ebae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a4d0c7fa-8781-440f-a4fa-d760ae81ebae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "mbG7OalyHEm0",
        "outputId": "c6beb41f-0a5b-4e77-e252-a0662c1f1387"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       GetProcAddress   ExitProcess     WriteFile  GetLastError   CloseHandle  \\\n",
              "count    47580.000000  47580.000000  47580.000000  47580.000000  47580.000000   \n",
              "mean         0.872236      0.847079      0.760004      0.783459      0.770618   \n",
              "std          0.333830      0.359915      0.427085      0.411891      0.420440   \n",
              "min          0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%          1.000000      1.000000      1.000000      1.000000      1.000000   \n",
              "50%          1.000000      1.000000      1.000000      1.000000      1.000000   \n",
              "75%          1.000000      1.000000      1.000000      1.000000      1.000000   \n",
              "max          1.000000      1.000000      1.000000      1.000000      1.000000   \n",
              "\n",
              "        FreeLibrary         Sleep  GetStdHandle  MultiByteToWideChar  \\\n",
              "count  47580.000000  47580.000000  47580.000000         47580.000000   \n",
              "mean       0.683501      0.665826      0.669966             0.756578   \n",
              "std        0.465115      0.471706      0.470230             0.429152   \n",
              "min        0.000000      0.000000      0.000000             0.000000   \n",
              "25%        0.000000      0.000000      0.000000             1.000000   \n",
              "50%        1.000000      1.000000      1.000000             1.000000   \n",
              "75%        1.000000      1.000000      1.000000             1.000000   \n",
              "max        1.000000      1.000000      1.000000             1.000000   \n",
              "\n",
              "       GetCurrentThreadId  ...          bind  RegEnumKeyExA   WinHttpOpen  \\\n",
              "count        47580.000000  ...  47580.000000   47580.000000  47580.000000   \n",
              "mean             0.674107  ...      0.024800       0.024590      0.024401   \n",
              "std              0.468713  ...      0.155518       0.154874      0.154292   \n",
              "min              0.000000  ...      0.000000       0.000000      0.000000   \n",
              "25%              0.000000  ...      0.000000       0.000000      0.000000   \n",
              "50%              1.000000  ...      0.000000       0.000000      0.000000   \n",
              "75%              1.000000  ...      0.000000       0.000000      0.000000   \n",
              "max              1.000000  ...      1.000000       1.000000      1.000000   \n",
              "\n",
              "         _controlfp       WinExec  GetSecurityDescriptorDacl  \\\n",
              "count  47580.000000  47580.000000               47580.000000   \n",
              "mean       0.024359      0.024275                   0.024191   \n",
              "std        0.154163      0.153903                   0.153643   \n",
              "min        0.000000      0.000000                   0.000000   \n",
              "25%        0.000000      0.000000                   0.000000   \n",
              "50%        0.000000      0.000000                   0.000000   \n",
              "75%        0.000000      0.000000                   0.000000   \n",
              "max        1.000000      1.000000                   1.000000   \n",
              "\n",
              "       FindFirstFreeAce  GetTimeFormatW  LookupAccountSidW       malware  \n",
              "count      47580.000000    47580.000000       47580.000000  47580.000000  \n",
              "mean           0.024149        0.023939           0.023686      0.959458  \n",
              "std            0.153513        0.152860           0.152072      0.197229  \n",
              "min            0.000000        0.000000           0.000000      0.000000  \n",
              "25%            0.000000        0.000000           0.000000      1.000000  \n",
              "50%            0.000000        0.000000           0.000000      1.000000  \n",
              "75%            0.000000        0.000000           0.000000      1.000000  \n",
              "max            1.000000        1.000000           1.000000      1.000000  \n",
              "\n",
              "[8 rows x 1001 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d242da75-0bb8-42c3-bd82-0f8146bd2373\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GetProcAddress</th>\n",
              "      <th>ExitProcess</th>\n",
              "      <th>WriteFile</th>\n",
              "      <th>GetLastError</th>\n",
              "      <th>CloseHandle</th>\n",
              "      <th>FreeLibrary</th>\n",
              "      <th>Sleep</th>\n",
              "      <th>GetStdHandle</th>\n",
              "      <th>MultiByteToWideChar</th>\n",
              "      <th>GetCurrentThreadId</th>\n",
              "      <th>...</th>\n",
              "      <th>bind</th>\n",
              "      <th>RegEnumKeyExA</th>\n",
              "      <th>WinHttpOpen</th>\n",
              "      <th>_controlfp</th>\n",
              "      <th>WinExec</th>\n",
              "      <th>GetSecurityDescriptorDacl</th>\n",
              "      <th>FindFirstFreeAce</th>\n",
              "      <th>GetTimeFormatW</th>\n",
              "      <th>LookupAccountSidW</th>\n",
              "      <th>malware</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>47580.000000</td>\n",
              "      <td>47580.000000</td>\n",
              "      <td>47580.000000</td>\n",
              "      <td>47580.000000</td>\n",
              "      <td>47580.000000</td>\n",
              "      <td>47580.000000</td>\n",
              "      <td>47580.000000</td>\n",
              "      <td>47580.000000</td>\n",
              "      <td>47580.000000</td>\n",
              "      <td>47580.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>47580.000000</td>\n",
              "      <td>47580.000000</td>\n",
              "      <td>47580.000000</td>\n",
              "      <td>47580.000000</td>\n",
              "      <td>47580.000000</td>\n",
              "      <td>47580.000000</td>\n",
              "      <td>47580.000000</td>\n",
              "      <td>47580.000000</td>\n",
              "      <td>47580.000000</td>\n",
              "      <td>47580.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.872236</td>\n",
              "      <td>0.847079</td>\n",
              "      <td>0.760004</td>\n",
              "      <td>0.783459</td>\n",
              "      <td>0.770618</td>\n",
              "      <td>0.683501</td>\n",
              "      <td>0.665826</td>\n",
              "      <td>0.669966</td>\n",
              "      <td>0.756578</td>\n",
              "      <td>0.674107</td>\n",
              "      <td>...</td>\n",
              "      <td>0.024800</td>\n",
              "      <td>0.024590</td>\n",
              "      <td>0.024401</td>\n",
              "      <td>0.024359</td>\n",
              "      <td>0.024275</td>\n",
              "      <td>0.024191</td>\n",
              "      <td>0.024149</td>\n",
              "      <td>0.023939</td>\n",
              "      <td>0.023686</td>\n",
              "      <td>0.959458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.333830</td>\n",
              "      <td>0.359915</td>\n",
              "      <td>0.427085</td>\n",
              "      <td>0.411891</td>\n",
              "      <td>0.420440</td>\n",
              "      <td>0.465115</td>\n",
              "      <td>0.471706</td>\n",
              "      <td>0.470230</td>\n",
              "      <td>0.429152</td>\n",
              "      <td>0.468713</td>\n",
              "      <td>...</td>\n",
              "      <td>0.155518</td>\n",
              "      <td>0.154874</td>\n",
              "      <td>0.154292</td>\n",
              "      <td>0.154163</td>\n",
              "      <td>0.153903</td>\n",
              "      <td>0.153643</td>\n",
              "      <td>0.153513</td>\n",
              "      <td>0.152860</td>\n",
              "      <td>0.152072</td>\n",
              "      <td>0.197229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 1001 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d242da75-0bb8-42c3-bd82-0f8146bd2373')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d242da75-0bb8-42c3-bd82-0f8146bd2373 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d242da75-0bb8-42c3-bd82-0f8146bd2373');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRoXrXbfHEm2",
        "outputId": "8f98c8b8-9a04-481e-d839-2181b74d3b74"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(47580, 1002)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "mtwuStnHHEm3",
        "outputId": "fd57ad15-89ef-477b-ddca-0c120f6488ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               0\n",
              "hash                       47547\n",
              "GetProcAddress                 2\n",
              "ExitProcess                    2\n",
              "WriteFile                      2\n",
              "GetLastError                   2\n",
              "...                          ...\n",
              "GetSecurityDescriptorDacl      2\n",
              "FindFirstFreeAce               2\n",
              "GetTimeFormatW                 2\n",
              "LookupAccountSidW              2\n",
              "malware                        2\n",
              "\n",
              "[1002 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-abc5d2f9-2f0b-49fa-bf41-2c3044b09f2d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>hash</th>\n",
              "      <td>47547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GetProcAddress</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ExitProcess</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WriteFile</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GetLastError</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GetSecurityDescriptorDacl</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FindFirstFreeAce</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GetTimeFormatW</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LookupAccountSidW</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>malware</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1002 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-abc5d2f9-2f0b-49fa-bf41-2c3044b09f2d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-abc5d2f9-2f0b-49fa-bf41-2c3044b09f2d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-abc5d2f9-2f0b-49fa-bf41-2c3044b09f2d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "er=pd.DataFrame(df.nunique())\n",
        "er"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjpfxmHKdopQ"
      },
      "source": [
        "# Missing values and duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nEqCcSGdopQ",
        "outputId": "4427357d-d679-4aef-9503-64719363b2ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#check for null values\n",
        "df.isnull().sum().any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7x8GWfcdopR",
        "outputId": "decc4152-a7c0-4bfc-8ebf-f922f1960970"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(47553, 1002)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Check for duplicates\n",
        "df.duplicated().any()\n",
        "\n",
        "ggg = df[df.duplicated()]\n",
        "df = df.drop_duplicates()\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwurPBOzHEm6",
        "outputId": "809d9509-049e-4687-9a59-b0da66606498"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 47553 entries, 0 to 47579\n",
            "Columns: 1002 entries, hash to malware\n",
            "dtypes: int64(1001), object(1)\n",
            "memory usage: 363.9+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "XsCwWyMudopS"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7PZaNA4dopS"
      },
      "source": [
        "# Feature selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "Yoyg_sSTHEm9",
        "outputId": "a6c4381e-808f-49a0-8323-7890cb29b9a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           GetProcAddress  ExitProcess  WriteFile  \\\n",
              "GetProcAddress                   1.000000     0.848189   0.649601   \n",
              "ExitProcess                      0.848189     1.000000   0.702508   \n",
              "WriteFile                        0.649601     0.702508   1.000000   \n",
              "GetLastError                     0.637072     0.647590   0.914140   \n",
              "CloseHandle                      0.637143     0.658430   0.923466   \n",
              "...                                   ...          ...        ...   \n",
              "GetSecurityDescriptorDacl        0.056181     0.049424   0.079824   \n",
              "FindFirstFreeAce                 0.058586     0.064951   0.086793   \n",
              "GetTimeFormatW                   0.049151     0.045419   0.075951   \n",
              "LookupAccountSidW                0.054249     0.051213   0.077813   \n",
              "malware                          0.030531     0.124399   0.109011   \n",
              "\n",
              "                           GetLastError  CloseHandle  FreeLibrary     Sleep  \\\n",
              "GetProcAddress                 0.637072     0.637143     0.546108  0.482712   \n",
              "ExitProcess                    0.647590     0.658430     0.549262  0.483543   \n",
              "WriteFile                      0.914140     0.923466     0.748727  0.684904   \n",
              "GetLastError                   1.000000     0.927379     0.752932  0.702949   \n",
              "CloseHandle                    0.927379     1.000000     0.761037  0.697669   \n",
              "...                                 ...          ...          ...       ...   \n",
              "GetSecurityDescriptorDacl      0.080136     0.083624     0.100105  0.107484   \n",
              "FindFirstFreeAce               0.081390     0.084849     0.105892  0.109994   \n",
              "GetTimeFormatW                 0.080568     0.081396     0.097565  0.059119   \n",
              "LookupAccountSidW              0.080898     0.082020     0.100664  0.108296   \n",
              "malware                       -0.004902     0.033930     0.024707 -0.038307   \n",
              "\n",
              "                           GetStdHandle  MultiByteToWideChar  \\\n",
              "GetProcAddress                 0.521421             0.651480   \n",
              "ExitProcess                    0.575093             0.687255   \n",
              "WriteFile                      0.786790             0.952707   \n",
              "GetLastError                   0.738679             0.913770   \n",
              "CloseHandle                    0.731371             0.908496   \n",
              "...                                 ...                  ...   \n",
              "GetSecurityDescriptorDacl      0.099757             0.081675   \n",
              "FindFirstFreeAce               0.109552             0.087972   \n",
              "GetTimeFormatW                 0.095433             0.081349   \n",
              "LookupAccountSidW              0.095519             0.081926   \n",
              "malware                        0.149130             0.081044   \n",
              "\n",
              "                           GetCurrentThreadId  ...      bind  RegEnumKeyExA  \\\n",
              "GetProcAddress                       0.494800  ...  0.054170       0.057100   \n",
              "ExitProcess                          0.484991  ...  0.038098       0.053863   \n",
              "WriteFile                            0.704922  ...  0.071883       0.077415   \n",
              "GetLastError                         0.726799  ...  0.074995       0.080488   \n",
              "CloseHandle                          0.707432  ...  0.077036       0.083035   \n",
              "...                                       ...  ...       ...            ...   \n",
              "GetSecurityDescriptorDacl            0.106858  ...  0.171033       0.113730   \n",
              "FindFirstFreeAce                     0.107927  ... -0.025101       0.098835   \n",
              "GetTimeFormatW                       0.077606  ...  0.205216      -0.007049   \n",
              "LookupAccountSidW                    0.106540  ...  0.085347       0.139537   \n",
              "malware                              0.027780  ... -0.044016      -0.011950   \n",
              "\n",
              "                           WinHttpOpen  _controlfp   WinExec  \\\n",
              "GetProcAddress                0.058915   -0.093602  0.047293   \n",
              "ExitProcess                   0.062667   -0.219845  0.054886   \n",
              "WriteFile                    -0.225762   -0.101032  0.064321   \n",
              "GetLastError                 -0.241380    0.014484  0.071997   \n",
              "CloseHandle                  -0.233640   -0.002756  0.070132   \n",
              "...                                ...         ...       ...   \n",
              "GetSecurityDescriptorDacl    -0.019595    0.011515 -0.013294   \n",
              "FindFirstFreeAce             -0.024893   -0.024860  0.305218   \n",
              "GetTimeFormatW               -0.004225    0.037825 -0.011264   \n",
              "LookupAccountSidW            -0.004941    0.011261  0.084978   \n",
              "malware                       0.021860   -0.341632  0.016868   \n",
              "\n",
              "                           GetSecurityDescriptorDacl  FindFirstFreeAce  \\\n",
              "GetProcAddress                              0.056181          0.058586   \n",
              "ExitProcess                                 0.049424          0.064951   \n",
              "WriteFile                                   0.079824          0.086793   \n",
              "GetLastError                                0.080136          0.081390   \n",
              "CloseHandle                                 0.083624          0.084849   \n",
              "...                                              ...               ...   \n",
              "GetSecurityDescriptorDacl                   1.000000          0.549987   \n",
              "FindFirstFreeAce                            0.549987          1.000000   \n",
              "GetTimeFormatW                              0.166225         -0.024617   \n",
              "LookupAccountSidW                           0.132884          0.105130   \n",
              "malware                                    -0.004862          0.032119   \n",
              "\n",
              "                           GetTimeFormatW  LookupAccountSidW   malware  \n",
              "GetProcAddress                   0.049151           0.054249  0.030531  \n",
              "ExitProcess                      0.045419           0.051213  0.124399  \n",
              "WriteFile                        0.075951           0.077813  0.109011  \n",
              "GetLastError                     0.080568           0.080898 -0.004902  \n",
              "CloseHandle                      0.081396           0.082020  0.033930  \n",
              "...                                   ...                ...       ...  \n",
              "GetSecurityDescriptorDacl        0.166225           0.132884 -0.004862  \n",
              "FindFirstFreeAce                -0.024617           0.105130  0.032119  \n",
              "GetTimeFormatW                   1.000000           0.009123 -0.061537  \n",
              "LookupAccountSidW                0.009123           1.000000 -0.030988  \n",
              "malware                         -0.061537          -0.030988  1.000000  \n",
              "\n",
              "[1001 rows x 1001 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6283b8b9-101c-4b70-9bd5-7a7cfbe45aa5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GetProcAddress</th>\n",
              "      <th>ExitProcess</th>\n",
              "      <th>WriteFile</th>\n",
              "      <th>GetLastError</th>\n",
              "      <th>CloseHandle</th>\n",
              "      <th>FreeLibrary</th>\n",
              "      <th>Sleep</th>\n",
              "      <th>GetStdHandle</th>\n",
              "      <th>MultiByteToWideChar</th>\n",
              "      <th>GetCurrentThreadId</th>\n",
              "      <th>...</th>\n",
              "      <th>bind</th>\n",
              "      <th>RegEnumKeyExA</th>\n",
              "      <th>WinHttpOpen</th>\n",
              "      <th>_controlfp</th>\n",
              "      <th>WinExec</th>\n",
              "      <th>GetSecurityDescriptorDacl</th>\n",
              "      <th>FindFirstFreeAce</th>\n",
              "      <th>GetTimeFormatW</th>\n",
              "      <th>LookupAccountSidW</th>\n",
              "      <th>malware</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>GetProcAddress</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.848189</td>\n",
              "      <td>0.649601</td>\n",
              "      <td>0.637072</td>\n",
              "      <td>0.637143</td>\n",
              "      <td>0.546108</td>\n",
              "      <td>0.482712</td>\n",
              "      <td>0.521421</td>\n",
              "      <td>0.651480</td>\n",
              "      <td>0.494800</td>\n",
              "      <td>...</td>\n",
              "      <td>0.054170</td>\n",
              "      <td>0.057100</td>\n",
              "      <td>0.058915</td>\n",
              "      <td>-0.093602</td>\n",
              "      <td>0.047293</td>\n",
              "      <td>0.056181</td>\n",
              "      <td>0.058586</td>\n",
              "      <td>0.049151</td>\n",
              "      <td>0.054249</td>\n",
              "      <td>0.030531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ExitProcess</th>\n",
              "      <td>0.848189</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.702508</td>\n",
              "      <td>0.647590</td>\n",
              "      <td>0.658430</td>\n",
              "      <td>0.549262</td>\n",
              "      <td>0.483543</td>\n",
              "      <td>0.575093</td>\n",
              "      <td>0.687255</td>\n",
              "      <td>0.484991</td>\n",
              "      <td>...</td>\n",
              "      <td>0.038098</td>\n",
              "      <td>0.053863</td>\n",
              "      <td>0.062667</td>\n",
              "      <td>-0.219845</td>\n",
              "      <td>0.054886</td>\n",
              "      <td>0.049424</td>\n",
              "      <td>0.064951</td>\n",
              "      <td>0.045419</td>\n",
              "      <td>0.051213</td>\n",
              "      <td>0.124399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WriteFile</th>\n",
              "      <td>0.649601</td>\n",
              "      <td>0.702508</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.914140</td>\n",
              "      <td>0.923466</td>\n",
              "      <td>0.748727</td>\n",
              "      <td>0.684904</td>\n",
              "      <td>0.786790</td>\n",
              "      <td>0.952707</td>\n",
              "      <td>0.704922</td>\n",
              "      <td>...</td>\n",
              "      <td>0.071883</td>\n",
              "      <td>0.077415</td>\n",
              "      <td>-0.225762</td>\n",
              "      <td>-0.101032</td>\n",
              "      <td>0.064321</td>\n",
              "      <td>0.079824</td>\n",
              "      <td>0.086793</td>\n",
              "      <td>0.075951</td>\n",
              "      <td>0.077813</td>\n",
              "      <td>0.109011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GetLastError</th>\n",
              "      <td>0.637072</td>\n",
              "      <td>0.647590</td>\n",
              "      <td>0.914140</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.927379</td>\n",
              "      <td>0.752932</td>\n",
              "      <td>0.702949</td>\n",
              "      <td>0.738679</td>\n",
              "      <td>0.913770</td>\n",
              "      <td>0.726799</td>\n",
              "      <td>...</td>\n",
              "      <td>0.074995</td>\n",
              "      <td>0.080488</td>\n",
              "      <td>-0.241380</td>\n",
              "      <td>0.014484</td>\n",
              "      <td>0.071997</td>\n",
              "      <td>0.080136</td>\n",
              "      <td>0.081390</td>\n",
              "      <td>0.080568</td>\n",
              "      <td>0.080898</td>\n",
              "      <td>-0.004902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CloseHandle</th>\n",
              "      <td>0.637143</td>\n",
              "      <td>0.658430</td>\n",
              "      <td>0.923466</td>\n",
              "      <td>0.927379</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.761037</td>\n",
              "      <td>0.697669</td>\n",
              "      <td>0.731371</td>\n",
              "      <td>0.908496</td>\n",
              "      <td>0.707432</td>\n",
              "      <td>...</td>\n",
              "      <td>0.077036</td>\n",
              "      <td>0.083035</td>\n",
              "      <td>-0.233640</td>\n",
              "      <td>-0.002756</td>\n",
              "      <td>0.070132</td>\n",
              "      <td>0.083624</td>\n",
              "      <td>0.084849</td>\n",
              "      <td>0.081396</td>\n",
              "      <td>0.082020</td>\n",
              "      <td>0.033930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GetSecurityDescriptorDacl</th>\n",
              "      <td>0.056181</td>\n",
              "      <td>0.049424</td>\n",
              "      <td>0.079824</td>\n",
              "      <td>0.080136</td>\n",
              "      <td>0.083624</td>\n",
              "      <td>0.100105</td>\n",
              "      <td>0.107484</td>\n",
              "      <td>0.099757</td>\n",
              "      <td>0.081675</td>\n",
              "      <td>0.106858</td>\n",
              "      <td>...</td>\n",
              "      <td>0.171033</td>\n",
              "      <td>0.113730</td>\n",
              "      <td>-0.019595</td>\n",
              "      <td>0.011515</td>\n",
              "      <td>-0.013294</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.549987</td>\n",
              "      <td>0.166225</td>\n",
              "      <td>0.132884</td>\n",
              "      <td>-0.004862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FindFirstFreeAce</th>\n",
              "      <td>0.058586</td>\n",
              "      <td>0.064951</td>\n",
              "      <td>0.086793</td>\n",
              "      <td>0.081390</td>\n",
              "      <td>0.084849</td>\n",
              "      <td>0.105892</td>\n",
              "      <td>0.109994</td>\n",
              "      <td>0.109552</td>\n",
              "      <td>0.087972</td>\n",
              "      <td>0.107927</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.025101</td>\n",
              "      <td>0.098835</td>\n",
              "      <td>-0.024893</td>\n",
              "      <td>-0.024860</td>\n",
              "      <td>0.305218</td>\n",
              "      <td>0.549987</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.024617</td>\n",
              "      <td>0.105130</td>\n",
              "      <td>0.032119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GetTimeFormatW</th>\n",
              "      <td>0.049151</td>\n",
              "      <td>0.045419</td>\n",
              "      <td>0.075951</td>\n",
              "      <td>0.080568</td>\n",
              "      <td>0.081396</td>\n",
              "      <td>0.097565</td>\n",
              "      <td>0.059119</td>\n",
              "      <td>0.095433</td>\n",
              "      <td>0.081349</td>\n",
              "      <td>0.077606</td>\n",
              "      <td>...</td>\n",
              "      <td>0.205216</td>\n",
              "      <td>-0.007049</td>\n",
              "      <td>-0.004225</td>\n",
              "      <td>0.037825</td>\n",
              "      <td>-0.011264</td>\n",
              "      <td>0.166225</td>\n",
              "      <td>-0.024617</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.009123</td>\n",
              "      <td>-0.061537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LookupAccountSidW</th>\n",
              "      <td>0.054249</td>\n",
              "      <td>0.051213</td>\n",
              "      <td>0.077813</td>\n",
              "      <td>0.080898</td>\n",
              "      <td>0.082020</td>\n",
              "      <td>0.100664</td>\n",
              "      <td>0.108296</td>\n",
              "      <td>0.095519</td>\n",
              "      <td>0.081926</td>\n",
              "      <td>0.106540</td>\n",
              "      <td>...</td>\n",
              "      <td>0.085347</td>\n",
              "      <td>0.139537</td>\n",
              "      <td>-0.004941</td>\n",
              "      <td>0.011261</td>\n",
              "      <td>0.084978</td>\n",
              "      <td>0.132884</td>\n",
              "      <td>0.105130</td>\n",
              "      <td>0.009123</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.030988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>malware</th>\n",
              "      <td>0.030531</td>\n",
              "      <td>0.124399</td>\n",
              "      <td>0.109011</td>\n",
              "      <td>-0.004902</td>\n",
              "      <td>0.033930</td>\n",
              "      <td>0.024707</td>\n",
              "      <td>-0.038307</td>\n",
              "      <td>0.149130</td>\n",
              "      <td>0.081044</td>\n",
              "      <td>0.027780</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.044016</td>\n",
              "      <td>-0.011950</td>\n",
              "      <td>0.021860</td>\n",
              "      <td>-0.341632</td>\n",
              "      <td>0.016868</td>\n",
              "      <td>-0.004862</td>\n",
              "      <td>0.032119</td>\n",
              "      <td>-0.061537</td>\n",
              "      <td>-0.030988</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1001 rows × 1001 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6283b8b9-101c-4b70-9bd5-7a7cfbe45aa5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6283b8b9-101c-4b70-9bd5-7a7cfbe45aa5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6283b8b9-101c-4b70-9bd5-7a7cfbe45aa5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "corr=df.corr()\n",
        "corr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AnjSq80HEm_"
      },
      "outputs": [],
      "source": [
        "# plt.figure(figsize=(10,8), dpi = 1000)\n",
        "# sns.heatmap(corr, annot=True , fmt=\".2f\", linewidth=.5)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmOap589HEnA"
      },
      "outputs": [],
      "source": [
        "def correlation(dataset,threshold):\n",
        "    col_corr = set()\n",
        "    corr_matrix = dataset.corr()\n",
        "    for i in range(len (corr_matrix.columns )):\n",
        "        for j in range(i):\n",
        "            if(corr_matrix.iloc[i,j])> threshold:\n",
        "              colname= corr_matrix.columns[i]\n",
        "              col_corr.add(colname)\n",
        "            \n",
        "    return col_corr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7R9ZfoQHEnB",
        "outputId": "e0cd0a61-bb3b-4a6c-917f-6f7b3d8d66f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'AbortDoc',\n",
              " 'AccessCheckByTypeAndAuditAlarmW',\n",
              " 'AccessCheckByTypeResultList',\n",
              " 'AccessCheckByTypeResultListAndAuditAlarmA',\n",
              " 'AccessCheckByTypeResultListAndAuditAlarmW',\n",
              " 'AccessibleObjectFromWindow',\n",
              " 'ActivateKeyboardLayout',\n",
              " 'AddAccessAllowedAceEx',\n",
              " 'AddAccessAllowedObjectAce',\n",
              " 'AddAccessDeniedAceEx',\n",
              " 'AddAccessDeniedObjectAce',\n",
              " 'AddAuditAccessAce',\n",
              " 'AddAuditAccessAceEx',\n",
              " 'AddAuditAccessObjectAce',\n",
              " 'AdjustTokenGroups',\n",
              " 'AdjustTokenPrivileges',\n",
              " 'AdjustWindowRectEx',\n",
              " 'AllocateLocallyUniqueId',\n",
              " 'AngleArc',\n",
              " 'AppendMenuA',\n",
              " 'Arc',\n",
              " 'ArcTo',\n",
              " 'AreAllAccessesGranted',\n",
              " 'AreAnyAccessesGranted',\n",
              " 'BackupEventLogW',\n",
              " 'BeginPaint',\n",
              " 'BitBlt',\n",
              " 'BringWindowToTop',\n",
              " 'CLSIDFromProgID',\n",
              " 'CLSIDFromString',\n",
              " 'CallNextHookEx',\n",
              " 'CallWindowProcA',\n",
              " 'CallWindowProcW',\n",
              " 'CharLowerA',\n",
              " 'CharLowerBuffA',\n",
              " 'CharLowerBuffW',\n",
              " 'CharLowerW',\n",
              " 'CharNextW',\n",
              " 'CharPrevA',\n",
              " 'CharToOemA',\n",
              " 'CharUpperBuffW',\n",
              " 'CharUpperW',\n",
              " 'CheckMenuItem',\n",
              " 'ChildWindowFromPoint',\n",
              " 'ChooseFontA',\n",
              " 'Chord',\n",
              " 'ClientToScreen',\n",
              " 'CloseClipboard',\n",
              " 'CloseEnhMetaFile',\n",
              " 'CloseHandle',\n",
              " 'ClosePrinter',\n",
              " 'CoCreateGuid',\n",
              " 'CoGetClassObject',\n",
              " 'CoInitialize',\n",
              " 'CoTaskMemAlloc',\n",
              " 'CoTaskMemFree',\n",
              " 'CoTaskMemRealloc',\n",
              " 'CoUninitialize',\n",
              " 'CompareFileTime',\n",
              " 'CompareStringA',\n",
              " 'CopyEnhMetaFileA',\n",
              " 'CopyEnhMetaFileW',\n",
              " 'CopyFileA',\n",
              " 'CopyIcon',\n",
              " 'CopyImage',\n",
              " 'CreateAcceleratorTableW',\n",
              " 'CreateBitmap',\n",
              " 'CreateBrushIndirect',\n",
              " 'CreateCompatibleBitmap',\n",
              " 'CreateCompatibleDC',\n",
              " 'CreateDCA',\n",
              " 'CreateDCW',\n",
              " 'CreateDIBSection',\n",
              " 'CreateDIBitmap',\n",
              " 'CreateDialogParamA',\n",
              " 'CreateDirectoryA',\n",
              " 'CreateEnhMetaFileW',\n",
              " 'CreateErrorInfo',\n",
              " 'CreateEventA',\n",
              " 'CreateEventW',\n",
              " 'CreateFileA',\n",
              " 'CreateFileW',\n",
              " 'CreateFontIndirectA',\n",
              " 'CreateFontIndirectW',\n",
              " 'CreateHalftonePalette',\n",
              " 'CreateICA',\n",
              " 'CreateICW',\n",
              " 'CreateIcon',\n",
              " 'CreateMenu',\n",
              " 'CreatePalette',\n",
              " 'CreatePenIndirect',\n",
              " 'CreatePopupMenu',\n",
              " 'CreateProcessA',\n",
              " 'CreateProcessAsUserW',\n",
              " 'CreateRectRgn',\n",
              " 'CreateRoundRectRgn',\n",
              " 'CreateSolidBrush',\n",
              " 'CreateStreamOnHGlobal',\n",
              " 'CreateThread',\n",
              " 'CreateWindowExA',\n",
              " 'CreateWindowExW',\n",
              " 'CryptAcquireContextW',\n",
              " 'CryptCreateHash',\n",
              " 'CryptDestroyHash',\n",
              " 'CryptGetHashParam',\n",
              " 'CryptHashData',\n",
              " 'CryptReleaseContext',\n",
              " 'DebugBreak',\n",
              " 'DecodePointer',\n",
              " 'DefFrameProcA',\n",
              " 'DefFrameProcW',\n",
              " 'DefMDIChildProcA',\n",
              " 'DefMDIChildProcW',\n",
              " 'DefWindowProcA',\n",
              " 'DefWindowProcW',\n",
              " 'DeleteCriticalSection',\n",
              " 'DeleteDC',\n",
              " 'DeleteEnhMetaFile',\n",
              " 'DeleteFileW',\n",
              " 'DeleteMenu',\n",
              " 'DeleteObject',\n",
              " 'DestroyAcceleratorTable',\n",
              " 'DestroyCursor',\n",
              " 'DestroyIcon',\n",
              " 'DestroyMenu',\n",
              " 'DestroyWindow',\n",
              " 'DialogBoxParamA',\n",
              " 'DispCallFunc',\n",
              " 'DispatchMessageA',\n",
              " 'DispatchMessageW',\n",
              " 'DllFunctionCall',\n",
              " 'DocumentPropertiesA',\n",
              " 'DocumentPropertiesW',\n",
              " 'DragAcceptFiles',\n",
              " 'DragQueryFileA',\n",
              " 'DrawEdge',\n",
              " 'DrawFocusRect',\n",
              " 'DrawFrameControl',\n",
              " 'DrawIcon',\n",
              " 'DrawIconEx',\n",
              " 'DrawMenuBar',\n",
              " 'DrawStateW',\n",
              " 'DrawTextA',\n",
              " 'DrawTextExW',\n",
              " 'DrawTextW',\n",
              " 'EVENT_SINK_AddRef',\n",
              " 'EVENT_SINK_QueryInterface',\n",
              " 'EVENT_SINK_Release',\n",
              " 'Ellipse',\n",
              " 'EmptyClipboard',\n",
              " 'EnableMenuItem',\n",
              " 'EnableScrollBar',\n",
              " 'EnableWindow',\n",
              " 'EncodePointer',\n",
              " 'EndDoc',\n",
              " 'EndMenu',\n",
              " 'EndPage',\n",
              " 'EndPaint',\n",
              " 'EnterCriticalSection',\n",
              " 'EnumCalendarInfoA',\n",
              " 'EnumCalendarInfoW',\n",
              " 'EnumChildWindows',\n",
              " 'EnumClipboardFormats',\n",
              " 'EnumDisplayMonitors',\n",
              " 'EnumFontFamiliesExW',\n",
              " 'EnumFontsW',\n",
              " 'EnumPrintersA',\n",
              " 'EnumPrintersW',\n",
              " 'EnumResourceNamesW',\n",
              " 'EnumSystemLocalesW',\n",
              " 'EnumThreadWindows',\n",
              " 'EnumWindows',\n",
              " 'EqualRect',\n",
              " 'ExcludeClipRect',\n",
              " 'ExitProcess',\n",
              " 'ExtFloodFill',\n",
              " 'ExtTextOutW',\n",
              " 'FileTimeToDosDateTime',\n",
              " 'FillRect',\n",
              " 'FindClose',\n",
              " 'FindFirstFileA',\n",
              " 'FindFirstFileExW',\n",
              " 'FindFirstFreeAce',\n",
              " 'FindResourceA',\n",
              " 'FindResourceExW',\n",
              " 'FindResourceW',\n",
              " 'FindTextA',\n",
              " 'FindWindowA',\n",
              " 'FindWindowExA',\n",
              " 'FindWindowExW',\n",
              " 'FindWindowW',\n",
              " 'FlatSB_GetScrollInfo',\n",
              " 'FlatSB_GetScrollPos',\n",
              " 'FlatSB_SetScrollInfo',\n",
              " 'FlatSB_SetScrollPos',\n",
              " 'FlatSB_SetScrollProp',\n",
              " 'FlushFileBuffers',\n",
              " 'FlushInstructionCache',\n",
              " 'FormatMessageW',\n",
              " 'FrameRect',\n",
              " 'FrameRgn',\n",
              " 'FreeEnvironmentStringsA',\n",
              " 'FreeEnvironmentStringsW',\n",
              " 'FreeResource',\n",
              " 'GdiFlush',\n",
              " 'GetACP',\n",
              " 'GetAclInformation',\n",
              " 'GetActiveObject',\n",
              " 'GetActiveWindow',\n",
              " 'GetBitmapBits',\n",
              " 'GetBrushOrgEx',\n",
              " 'GetCPInfo',\n",
              " 'GetCPInfoExW',\n",
              " 'GetCapture',\n",
              " 'GetClassInfoA',\n",
              " 'GetClassInfoExW',\n",
              " 'GetClassInfoW',\n",
              " 'GetClassLongW',\n",
              " 'GetClassNameA',\n",
              " 'GetClassNameW',\n",
              " 'GetClientRect',\n",
              " 'GetClipBox',\n",
              " 'GetClipboardData',\n",
              " 'GetCommandLineW',\n",
              " 'GetComputerNameW',\n",
              " 'GetConsoleCP',\n",
              " 'GetConsoleMode',\n",
              " 'GetCurrentPositionEx',\n",
              " 'GetCurrentProcessId',\n",
              " 'GetCurrentThread',\n",
              " 'GetCurrentThreadId',\n",
              " 'GetCursor',\n",
              " 'GetCursorPos',\n",
              " 'GetDCEx',\n",
              " 'GetDCOrgEx',\n",
              " 'GetDCPenColor',\n",
              " 'GetDIBColorTable',\n",
              " 'GetDIBits',\n",
              " 'GetDateFormatA',\n",
              " 'GetDateFormatW',\n",
              " 'GetDefaultPrinterW',\n",
              " 'GetDesktopWindow',\n",
              " 'GetDeviceCaps',\n",
              " 'GetDiskFreeSpaceA',\n",
              " 'GetDlgCtrlID',\n",
              " 'GetDlgItemTextA',\n",
              " 'GetDlgItemTextW',\n",
              " 'GetEnhMetaFileBits',\n",
              " 'GetEnhMetaFileDescriptionW',\n",
              " 'GetEnhMetaFileHeader',\n",
              " 'GetEnhMetaFilePaletteEntries',\n",
              " 'GetEnvironmentStrings',\n",
              " 'GetEnvironmentStringsW',\n",
              " 'GetErrorInfo',\n",
              " 'GetFileAttributesA',\n",
              " 'GetFileAttributesW',\n",
              " 'GetFileVersionInfoA',\n",
              " 'GetFileVersionInfoSizeA',\n",
              " 'GetFileVersionInfoSizeW',\n",
              " 'GetFileVersionInfoW',\n",
              " 'GetFocus',\n",
              " 'GetForegroundWindow',\n",
              " 'GetFullPathNameA',\n",
              " 'GetFullPathNameW',\n",
              " 'GetIconInfo',\n",
              " 'GetKeyNameTextA',\n",
              " 'GetKeyNameTextW',\n",
              " 'GetKeyState',\n",
              " 'GetKeyboardLayout',\n",
              " 'GetKeyboardLayoutList',\n",
              " 'GetKeyboardLayoutNameW',\n",
              " 'GetKeyboardState',\n",
              " 'GetLastActivePopup',\n",
              " 'GetLastError',\n",
              " 'GetMenu',\n",
              " 'GetMenuItemCount',\n",
              " 'GetMenuItemID',\n",
              " 'GetMenuItemInfoA',\n",
              " 'GetMenuItemInfoW',\n",
              " 'GetMenuState',\n",
              " 'GetMenuStringA',\n",
              " 'GetMenuStringW',\n",
              " 'GetMessageExtraInfo',\n",
              " 'GetMessageTime',\n",
              " 'GetModuleFileNameW',\n",
              " 'GetModuleHandleExW',\n",
              " 'GetOEMCP',\n",
              " 'GetObjectA',\n",
              " 'GetObjectW',\n",
              " 'GetOpenFileNameA',\n",
              " 'GetPaletteEntries',\n",
              " 'GetParent',\n",
              " 'GetPixel',\n",
              " 'GetPrivateProfileStringA',\n",
              " 'GetPrivateProfileStringW',\n",
              " 'GetProcessHeap',\n",
              " 'GetProcessId',\n",
              " 'GetProfileIntA',\n",
              " 'GetProfileStringA',\n",
              " 'GetPropA',\n",
              " 'GetPropW',\n",
              " 'GetRgnBox',\n",
              " 'GetSaveFileNameA',\n",
              " 'GetScrollBarInfo',\n",
              " 'GetScrollInfo',\n",
              " 'GetScrollPos',\n",
              " 'GetScrollRange',\n",
              " 'GetShortPathNameA',\n",
              " 'GetStartupInfoW',\n",
              " 'GetStockObject',\n",
              " 'GetStretchBltMode',\n",
              " 'GetStringTypeA',\n",
              " 'GetStringTypeExA',\n",
              " 'GetStringTypeW',\n",
              " 'GetSubMenu',\n",
              " 'GetSysColor',\n",
              " 'GetSysColorBrush',\n",
              " 'GetSystemDefaultUILanguage',\n",
              " 'GetSystemInfo',\n",
              " 'GetSystemMenu',\n",
              " 'GetSystemMetrics',\n",
              " 'GetSystemPaletteEntries',\n",
              " 'GetSystemTimeAsFileTime',\n",
              " 'GetTempFileNameA',\n",
              " 'GetTextExtentPoint32A',\n",
              " 'GetTextExtentPoint32W',\n",
              " 'GetTextExtentPointA',\n",
              " 'GetTextExtentPointW',\n",
              " 'GetTextMetricsA',\n",
              " 'GetTextMetricsW',\n",
              " 'GetThreadContext',\n",
              " 'GetThreadPriority',\n",
              " 'GetTopWindow',\n",
              " 'GetUserDefaultLCID',\n",
              " 'GetUserDefaultUILanguage',\n",
              " 'GetVersionExA',\n",
              " 'GetWinMetaFileBits',\n",
              " 'GetWindow',\n",
              " 'GetWindowDC',\n",
              " 'GetWindowLongA',\n",
              " 'GetWindowLongW',\n",
              " 'GetWindowOrgEx',\n",
              " 'GetWindowPlacement',\n",
              " 'GetWindowRect',\n",
              " 'GetWindowTextA',\n",
              " 'GetWindowTextLengthW',\n",
              " 'GetWindowTextW',\n",
              " 'GetWindowThreadProcessId',\n",
              " 'GetWindowsDirectoryA',\n",
              " 'GlobalAddAtomA',\n",
              " 'GlobalAddAtomW',\n",
              " 'GlobalAlloc',\n",
              " 'GlobalDeleteAtom',\n",
              " 'GlobalFindAtomA',\n",
              " 'GlobalFindAtomW',\n",
              " 'GlobalFree',\n",
              " 'GlobalHandle',\n",
              " 'GlobalLock',\n",
              " 'GlobalReAlloc',\n",
              " 'GlobalSize',\n",
              " 'GlobalUnlock',\n",
              " 'HeapAlloc',\n",
              " 'HeapFree',\n",
              " 'HeapReAlloc',\n",
              " 'HeapSize',\n",
              " 'HideCaret',\n",
              " 'HttpOpenRequestW',\n",
              " 'HttpSendRequestW',\n",
              " 'ImageList_AddMasked',\n",
              " 'ImageList_BeginDrag',\n",
              " 'ImageList_Copy',\n",
              " 'ImageList_Create',\n",
              " 'ImageList_Destroy',\n",
              " 'ImageList_DragEnter',\n",
              " 'ImageList_DragLeave',\n",
              " 'ImageList_DragMove',\n",
              " 'ImageList_DragShowNolock',\n",
              " 'ImageList_Draw',\n",
              " 'ImageList_DrawEx',\n",
              " 'ImageList_EndDrag',\n",
              " 'ImageList_GetBkColor',\n",
              " 'ImageList_GetDragImage',\n",
              " 'ImageList_GetIcon',\n",
              " 'ImageList_GetIconSize',\n",
              " 'ImageList_GetImageCount',\n",
              " 'ImageList_GetImageInfo',\n",
              " 'ImageList_LoadImageW',\n",
              " 'ImageList_Read',\n",
              " 'ImageList_Remove',\n",
              " 'ImageList_Replace',\n",
              " 'ImageList_ReplaceIcon',\n",
              " 'ImageList_SetBkColor',\n",
              " 'ImageList_SetDragCursorImage',\n",
              " 'ImageList_SetIconSize',\n",
              " 'ImageList_SetImageCount',\n",
              " 'ImageList_SetOverlayImage',\n",
              " 'ImageList_Write',\n",
              " 'InflateRect',\n",
              " 'InitializeCriticalSectionAndSpinCount',\n",
              " 'InitializeFlatSB',\n",
              " 'InitializeSListHead',\n",
              " 'InsertMenuA',\n",
              " 'InsertMenuItemA',\n",
              " 'InsertMenuItemW',\n",
              " 'InsertMenuW',\n",
              " 'InterlockedDecrement',\n",
              " 'InterlockedPopEntrySList',\n",
              " 'InterlockedPushEntrySList',\n",
              " 'InternetCloseHandle',\n",
              " 'InternetConnectW',\n",
              " 'InternetCrackUrlW',\n",
              " 'InternetOpenW',\n",
              " 'IntersectClipRect',\n",
              " 'IntersectRect',\n",
              " 'InvalidateRect',\n",
              " 'InvalidateRgn',\n",
              " 'IsAccelerator',\n",
              " 'IsChild',\n",
              " 'IsDebuggerPresent',\n",
              " 'IsDialogMessageA',\n",
              " 'IsDialogMessageW',\n",
              " 'IsIconic',\n",
              " 'IsProcessorFeaturePresent',\n",
              " 'IsRectEmpty',\n",
              " 'IsValidCodePage',\n",
              " 'IsValidLocale',\n",
              " 'IsWindow',\n",
              " 'IsWindowEnabled',\n",
              " 'IsWindowUnicode',\n",
              " 'IsWindowVisible',\n",
              " 'IsZoomed',\n",
              " 'KillTimer',\n",
              " 'LCMapStringW',\n",
              " 'LPtoDP',\n",
              " 'LeaveCriticalSection',\n",
              " 'LineTo',\n",
              " 'LoadBitmapA',\n",
              " 'LoadBitmapW',\n",
              " 'LoadCursorA',\n",
              " 'LoadCursorW',\n",
              " 'LoadIconA',\n",
              " 'LoadImageA',\n",
              " 'LoadKeyboardLayoutA',\n",
              " 'LoadKeyboardLayoutW',\n",
              " 'LoadLibraryExW',\n",
              " 'LoadLibraryW',\n",
              " 'LoadRegTypeLib',\n",
              " 'LoadResource',\n",
              " 'LoadTypeLib',\n",
              " 'LockResource',\n",
              " 'MapViewOfFile',\n",
              " 'MapVirtualKeyA',\n",
              " 'MapVirtualKeyW',\n",
              " 'MaskBlt',\n",
              " 'MessageBeep',\n",
              " 'MessageBoxIndirectA',\n",
              " 'MessageBoxIndirectW',\n",
              " 'MessageBoxW',\n",
              " 'MonitorFromPoint',\n",
              " 'MonitorFromRect',\n",
              " 'MonitorFromWindow',\n",
              " 'MoveFileA',\n",
              " 'MoveToEx',\n",
              " 'MoveWindow',\n",
              " 'MsgWaitForMultipleObjectsEx',\n",
              " 'MulDiv',\n",
              " 'MultiByteToWideChar',\n",
              " 'NetApiBufferFree',\n",
              " 'NetWkstaGetInfo',\n",
              " 'NotifyWinEvent',\n",
              " 'OemToCharA',\n",
              " 'OffsetRect',\n",
              " 'OleCreateFontIndirect',\n",
              " 'OleDraw',\n",
              " 'OleInitialize',\n",
              " 'OleLockRunning',\n",
              " 'OleRegEnumVerbs',\n",
              " 'OleSetMenuDescriptor',\n",
              " 'OleUninitialize',\n",
              " 'OpenClipboard',\n",
              " 'OpenPrinterA',\n",
              " 'OpenPrinterW',\n",
              " 'PageSetupDlgA',\n",
              " 'PatBlt',\n",
              " 'PathAddBackslashW',\n",
              " 'PathAppendW',\n",
              " 'PeekMessageA',\n",
              " 'PeekMessageW',\n",
              " 'Pie',\n",
              " 'PlayEnhMetaFile',\n",
              " 'PolyBezier',\n",
              " 'PolyBezierTo',\n",
              " 'Polygon',\n",
              " 'Polyline',\n",
              " 'PostMessageA',\n",
              " 'PostMessageW',\n",
              " 'PostQuitMessage',\n",
              " 'PrintDlgA',\n",
              " 'Process32FirstW',\n",
              " 'Process32NextW',\n",
              " 'ProgIDFromCLSID',\n",
              " 'QueryPerformanceCounter',\n",
              " 'QueryPerformanceFrequency',\n",
              " 'RaiseException',\n",
              " 'ReadConsoleW',\n",
              " 'ReadFile',\n",
              " 'RealizePalette',\n",
              " 'RectVisible',\n",
              " 'RedrawWindow',\n",
              " 'RegCloseKey',\n",
              " 'RegConnectRegistryW',\n",
              " 'RegCreateKeyExA',\n",
              " 'RegCreateKeyExW',\n",
              " 'RegDeleteKeyA',\n",
              " 'RegDeleteKeyW',\n",
              " 'RegDeleteValueA',\n",
              " 'RegDeleteValueW',\n",
              " 'RegEnumKeyExW',\n",
              " 'RegEnumKeyW',\n",
              " 'RegEnumValueA',\n",
              " 'RegEnumValueW',\n",
              " 'RegFlushKey',\n",
              " 'RegLoadKeyW',\n",
              " 'RegOpenKeyExA',\n",
              " 'RegQueryInfoKeyW',\n",
              " 'RegQueryValueExA',\n",
              " 'RegQueryValueExW',\n",
              " 'RegReplaceKeyW',\n",
              " 'RegRestoreKeyW',\n",
              " 'RegSaveKeyW',\n",
              " 'RegSetValueExW',\n",
              " 'RegUnLoadKeyW',\n",
              " 'RegisterClassA',\n",
              " 'RegisterClassExW',\n",
              " 'RegisterClipboardFormatA',\n",
              " 'RegisterClipboardFormatW',\n",
              " 'RegisterWindowMessageA',\n",
              " 'RegisterWindowMessageW',\n",
              " 'ReleaseCapture',\n",
              " 'ReleaseDC',\n",
              " 'RemoveDirectoryA',\n",
              " 'RemoveDirectoryW',\n",
              " 'RemoveMenu',\n",
              " 'RemovePropA',\n",
              " 'RemovePropW',\n",
              " 'ReplaceTextA',\n",
              " 'ResetEvent',\n",
              " 'RestoreDC',\n",
              " 'ResumeThread',\n",
              " 'RoundRect',\n",
              " 'RtlUnwind',\n",
              " 'SHBrowseForFolderA',\n",
              " 'SHBrowseForFolderW',\n",
              " 'SHFileOperationA',\n",
              " 'SHGetFileInfoA',\n",
              " 'SHGetFolderPathA',\n",
              " 'SHGetFolderPathW',\n",
              " 'SHGetPathFromIDListA',\n",
              " 'SafeArrayCreate',\n",
              " 'SafeArrayGetElement',\n",
              " 'SafeArrayGetLBound',\n",
              " 'SafeArrayGetUBound',\n",
              " 'SafeArrayPtrOfIndex',\n",
              " 'SafeArrayPutElement',\n",
              " 'SafeArrayUnaccessData',\n",
              " 'SaveDC',\n",
              " 'ScreenToClient',\n",
              " 'ScrollWindow',\n",
              " 'SearchPathA',\n",
              " 'SelectObject',\n",
              " 'SelectPalette',\n",
              " 'SendDlgItemMessageA',\n",
              " 'SendMessageA',\n",
              " 'SendMessageTimeoutA',\n",
              " 'SendMessageW',\n",
              " 'SetAbortProc',\n",
              " 'SetActiveWindow',\n",
              " 'SetBkColor',\n",
              " 'SetBkMode',\n",
              " 'SetBrushOrgEx',\n",
              " 'SetCapture',\n",
              " 'SetClassLongA',\n",
              " 'SetClassLongW',\n",
              " 'SetClipboardData',\n",
              " 'SetCurrentDirectoryA',\n",
              " 'SetCursor',\n",
              " 'SetCursorPos',\n",
              " 'SetDCPenColor',\n",
              " 'SetDIBColorTable',\n",
              " 'SetDIBits',\n",
              " 'SetDlgItemTextA',\n",
              " 'SetEnhMetaFileBits',\n",
              " 'SetErrorMode',\n",
              " 'SetFileAttributesW',\n",
              " 'SetFilePointer',\n",
              " 'SetFilePointerEx',\n",
              " 'SetFocus',\n",
              " 'SetForegroundWindow',\n",
              " 'SetLastError',\n",
              " 'SetLayeredWindowAttributes',\n",
              " 'SetMenu',\n",
              " 'SetMenuItemInfoA',\n",
              " 'SetMenuItemInfoW',\n",
              " 'SetParent',\n",
              " 'SetPixel',\n",
              " 'SetPropA',\n",
              " 'SetPropW',\n",
              " 'SetROP2',\n",
              " 'SetRect',\n",
              " 'SetRectRgn',\n",
              " 'SetScrollInfo',\n",
              " 'SetScrollPos',\n",
              " 'SetScrollRange',\n",
              " 'SetStdHandle',\n",
              " 'SetStretchBltMode',\n",
              " 'SetTextColor',\n",
              " 'SetThreadLocale',\n",
              " 'SetThreadPriority',\n",
              " 'SetTimer',\n",
              " 'SetViewportOrgEx',\n",
              " 'SetWinMetaFileBits',\n",
              " 'SetWindowLongA',\n",
              " 'SetWindowLongW',\n",
              " 'SetWindowOrgEx',\n",
              " 'SetWindowPlacement',\n",
              " 'SetWindowPos',\n",
              " 'SetWindowRgn',\n",
              " 'SetWindowTextA',\n",
              " 'SetWindowTextW',\n",
              " 'SetWindowsHookExA',\n",
              " 'SetWindowsHookExW',\n",
              " 'ShellExecuteExW',\n",
              " 'Shell_NotifyIconW',\n",
              " 'ShowCaret',\n",
              " 'ShowCursor',\n",
              " 'ShowOwnedPopups',\n",
              " 'ShowScrollBar',\n",
              " 'ShowWindow',\n",
              " 'SizeofResource',\n",
              " 'SleepEx',\n",
              " 'StartDocA',\n",
              " 'StartDocW',\n",
              " 'StartPage',\n",
              " 'StretchBlt',\n",
              " 'StretchDIBits',\n",
              " 'StringFromCLSID',\n",
              " 'StringFromGUID2',\n",
              " 'SuspendThread',\n",
              " 'SysAllocString',\n",
              " 'SysAllocStringLen',\n",
              " 'SysFreeString',\n",
              " 'SysReAllocStringLen',\n",
              " 'SysStringByteLen',\n",
              " 'SysStringLen',\n",
              " 'SystemParametersInfoA',\n",
              " 'SystemParametersInfoW',\n",
              " 'TerminateProcess',\n",
              " 'TextOutA',\n",
              " 'TlsAlloc',\n",
              " 'TlsFree',\n",
              " 'TlsGetValue',\n",
              " 'TlsSetValue',\n",
              " 'TrackPopupMenu',\n",
              " 'TranslateMDISysAccel',\n",
              " 'TranslateMessage',\n",
              " 'TryEnterCriticalSection',\n",
              " 'UnhandledExceptionFilter',\n",
              " 'UnhookWindowsHookEx',\n",
              " 'UnrealizeObject',\n",
              " 'UnregisterClassW',\n",
              " 'UpdateWindow',\n",
              " 'UrlEscapeW',\n",
              " 'UrlUnescapeW',\n",
              " 'VarBstrCat',\n",
              " 'VarBstrCmp',\n",
              " 'VarUI4FromStr',\n",
              " 'VariantChangeType',\n",
              " 'VariantClear',\n",
              " 'VariantCopy',\n",
              " 'VerQueryValueA',\n",
              " 'VerifyVersionInfoW',\n",
              " 'VirtualFree',\n",
              " 'VirtualProtectEx',\n",
              " 'VirtualQuery',\n",
              " 'VirtualQueryEx',\n",
              " 'WSACleanup',\n",
              " 'WSAGetLastError',\n",
              " 'WaitForMultipleObjectsEx',\n",
              " 'WaitForSingleObject',\n",
              " 'WaitMessage',\n",
              " 'WideCharToMultiByte',\n",
              " 'WinHelpA',\n",
              " 'WindowFromPoint',\n",
              " 'WriteConsoleW',\n",
              " 'WritePrivateProfileStringA',\n",
              " '_CIatan',\n",
              " '_CIcos',\n",
              " '_CIexp',\n",
              " '_CIlog',\n",
              " '_CIsin',\n",
              " '_CIsqrt',\n",
              " '_CItan',\n",
              " '_TrackMouseEvent',\n",
              " '_XcptFilter',\n",
              " '__getmainargs',\n",
              " '__p__commode',\n",
              " '__p__fmode',\n",
              " '__setusermatherr',\n",
              " '__vbaChkstk',\n",
              " '__vbaFPException',\n",
              " '__vbaFreeObj',\n",
              " '__vbaFreeStr',\n",
              " '__vbaFreeVar',\n",
              " '__vbaFreeVarList',\n",
              " '__vbaHresultCheckObj',\n",
              " '__vbaNew2',\n",
              " '__vbaSetSystemError',\n",
              " '__vbaStrMove',\n",
              " '__vbaVarMove',\n",
              " '_adj_fdiv_m16i',\n",
              " '_adj_fdiv_m32',\n",
              " '_adj_fdiv_m32i',\n",
              " '_adj_fdiv_m64',\n",
              " '_adj_fdiv_r',\n",
              " '_adj_fdivr_m16i',\n",
              " '_adj_fdivr_m32',\n",
              " '_adj_fdivr_m32i',\n",
              " '_adj_fdivr_m64',\n",
              " '_adj_fpatan',\n",
              " '_adj_fprem',\n",
              " '_adj_fprem1',\n",
              " '_adj_fptan',\n",
              " '_allmul',\n",
              " '_cexit',\n",
              " '_controlfp',\n",
              " '_exit',\n",
              " '_initterm',\n",
              " '_onexit',\n",
              " 'bind',\n",
              " 'closesocket',\n",
              " 'connect',\n",
              " 'exit',\n",
              " 'gethostname',\n",
              " 'htons',\n",
              " 'ioctlsocket',\n",
              " 'listen',\n",
              " 'lstrcatW',\n",
              " 'lstrcmpiW',\n",
              " 'lstrcpyW',\n",
              " 'lstrcpynA',\n",
              " 'lstrlenW',\n",
              " 'malloc',\n",
              " 'ntohs',\n",
              " 'recv',\n",
              " 'select',\n",
              " 'send',\n",
              " 'setsockopt',\n",
              " 'sndPlaySoundW',\n",
              " 'socket',\n",
              " 'wsprintfA'}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "corr_features = correlation(df,0.8)\n",
        "len(set(corr_features))\n",
        "\n",
        "corr_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAaxGN8QHEnD"
      },
      "outputs": [],
      "source": [
        "# V=pd.DataFrame(corr_features)\n",
        "# V.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H46Y2xa8dopU"
      },
      "source": [
        "# Target Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "MD7dPiC8HEnD",
        "outputId": "6eb5d6dc-a54b-4e4c-a1bc-8f9427b2c6c1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "sns.set_style('darkgrid')\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.countplot(x = 'malware', data = df)\n",
        "plt.title('Target Variable Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peDEO-sBdopU"
      },
      "source": [
        "There is a class imbalance in our dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "yQMxr6pUHEnE",
        "outputId": "792d2579-b0ee-4935-dc3f-29abae6a37e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       GetProcAddress  ExitProcess  WriteFile  GetLastError  CloseHandle  \\\n",
              "0                   1            1          1             1            1   \n",
              "1                   1            1          1             1            1   \n",
              "2                   1            1          1             1            1   \n",
              "3                   1            1          1             1            0   \n",
              "4                   1            1          1             1            1   \n",
              "...               ...          ...        ...           ...          ...   \n",
              "47575               1            1          1             1            1   \n",
              "47576               1            1          1             1            1   \n",
              "47577               1            1          1             1            1   \n",
              "47578               1            1          1             1            1   \n",
              "47579               1            0          0             1            1   \n",
              "\n",
              "       FreeLibrary  Sleep  GetStdHandle  MultiByteToWideChar  \\\n",
              "0                1      1             1                    1   \n",
              "1                1      1             1                    1   \n",
              "2                0      1             0                    1   \n",
              "3                0      1             1                    1   \n",
              "4                1      1             1                    1   \n",
              "...            ...    ...           ...                  ...   \n",
              "47575            1      1             1                    1   \n",
              "47576            1      1             1                    1   \n",
              "47577            1      1             1                    1   \n",
              "47578            1      1             1                    1   \n",
              "47579            0      1             0                    1   \n",
              "\n",
              "       GetCurrentThreadId  ...  DuplicateToken  bind  RegEnumKeyExA  \\\n",
              "0                       1  ...               0     0              0   \n",
              "1                       1  ...               0     0              0   \n",
              "2                       0  ...               0     0              1   \n",
              "3                       1  ...               0     0              0   \n",
              "4                       1  ...               0     0              0   \n",
              "...                   ...  ...             ...   ...            ...   \n",
              "47575                   1  ...               0     0              0   \n",
              "47576                   1  ...               0     0              0   \n",
              "47577                   1  ...               0     0              0   \n",
              "47578                   1  ...               0     0              0   \n",
              "47579                   1  ...               0     0              0   \n",
              "\n",
              "       WinHttpOpen  _controlfp  WinExec  GetSecurityDescriptorDacl  \\\n",
              "0                0           0        0                          0   \n",
              "1                0           0        0                          0   \n",
              "2                0           0        0                          0   \n",
              "3                0           0        0                          0   \n",
              "4                0           0        0                          0   \n",
              "...            ...         ...      ...                        ...   \n",
              "47575            0           0        0                          0   \n",
              "47576            0           0        0                          0   \n",
              "47577            0           0        0                          0   \n",
              "47578            0           0        0                          0   \n",
              "47579            0           0        0                          0   \n",
              "\n",
              "       FindFirstFreeAce  GetTimeFormatW  LookupAccountSidW  \n",
              "0                     0               0                  0  \n",
              "1                     0               0                  0  \n",
              "2                     0               0                  0  \n",
              "3                     0               0                  0  \n",
              "4                     0               0                  0  \n",
              "...                 ...             ...                ...  \n",
              "47575                 0               0                  0  \n",
              "47576                 0               0                  0  \n",
              "47577                 0               0                  0  \n",
              "47578                 0               0                  0  \n",
              "47579                 0               0                  0  \n",
              "\n",
              "[47553 rows x 1000 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d20fecc9-01a8-4899-9c00-72875c88509a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GetProcAddress</th>\n",
              "      <th>ExitProcess</th>\n",
              "      <th>WriteFile</th>\n",
              "      <th>GetLastError</th>\n",
              "      <th>CloseHandle</th>\n",
              "      <th>FreeLibrary</th>\n",
              "      <th>Sleep</th>\n",
              "      <th>GetStdHandle</th>\n",
              "      <th>MultiByteToWideChar</th>\n",
              "      <th>GetCurrentThreadId</th>\n",
              "      <th>...</th>\n",
              "      <th>DuplicateToken</th>\n",
              "      <th>bind</th>\n",
              "      <th>RegEnumKeyExA</th>\n",
              "      <th>WinHttpOpen</th>\n",
              "      <th>_controlfp</th>\n",
              "      <th>WinExec</th>\n",
              "      <th>GetSecurityDescriptorDacl</th>\n",
              "      <th>FindFirstFreeAce</th>\n",
              "      <th>GetTimeFormatW</th>\n",
              "      <th>LookupAccountSidW</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47575</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47576</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47577</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47578</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47579</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>47553 rows × 1000 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d20fecc9-01a8-4899-9c00-72875c88509a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d20fecc9-01a8-4899-9c00-72875c88509a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d20fecc9-01a8-4899-9c00-72875c88509a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "X = df.drop(columns = ['malware','hash'])\n",
        "y = df['malware']\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcOdKGZGdopV"
      },
      "source": [
        "# Balancing target variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "qNOnyWEFHEnF",
        "outputId": "2d8a6e34-30bb-4704-a7eb-98897fee5291"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       GetProcAddress  ExitProcess  WriteFile  GetLastError  CloseHandle  \\\n",
              "0                   1            1          1             1            1   \n",
              "1                   1            1          1             1            1   \n",
              "2                   1            1          1             1            1   \n",
              "3                   1            1          1             1            0   \n",
              "4                   1            1          1             1            1   \n",
              "...               ...          ...        ...           ...          ...   \n",
              "91297               1            0          0             1            1   \n",
              "91298               1            1          1             1            1   \n",
              "91299               1            1          1             1            1   \n",
              "91300               1            1          1             1            1   \n",
              "91301               1            1          1             1            1   \n",
              "\n",
              "       FreeLibrary  Sleep  GetStdHandle  MultiByteToWideChar  \\\n",
              "0                1      1             1                    1   \n",
              "1                1      1             1                    1   \n",
              "2                0      1             0                    1   \n",
              "3                0      1             1                    1   \n",
              "4                1      1             1                    1   \n",
              "...            ...    ...           ...                  ...   \n",
              "91297            1      1             0                    0   \n",
              "91298            1      1             0                    1   \n",
              "91299            1      1             0                    1   \n",
              "91300            1      0             1                    1   \n",
              "91301            1      0             1                    1   \n",
              "\n",
              "       GetCurrentThreadId  ...  bind  RegEnumKeyExA  WinHttpOpen  _controlfp  \\\n",
              "0                       1  ...     0              0            0           0   \n",
              "1                       1  ...     0              0            0           0   \n",
              "2                       0  ...     0              1            0           0   \n",
              "3                       1  ...     0              0            0           0   \n",
              "4                       1  ...     0              0            0           0   \n",
              "...                   ...  ...   ...            ...          ...         ...   \n",
              "91297                   1  ...     0              0            0           0   \n",
              "91298                   0  ...     0              0            0           0   \n",
              "91299                   0  ...     0              0            0           0   \n",
              "91300                   1  ...     0              0            0           0   \n",
              "91301                   1  ...     0              0            0           0   \n",
              "\n",
              "       WinExec  GetSecurityDescriptorDacl  FindFirstFreeAce  GetTimeFormatW  \\\n",
              "0            0                          0                 0               0   \n",
              "1            0                          0                 0               0   \n",
              "2            0                          0                 0               0   \n",
              "3            0                          0                 0               0   \n",
              "4            0                          0                 0               0   \n",
              "...        ...                        ...               ...             ...   \n",
              "91297        0                          0                 0               0   \n",
              "91298        0                          0                 0               0   \n",
              "91299        0                          0                 0               0   \n",
              "91300        0                          0                 0               0   \n",
              "91301        0                          0                 0               0   \n",
              "\n",
              "       LookupAccountSidW  malware  \n",
              "0                      0        1  \n",
              "1                      0        1  \n",
              "2                      0        1  \n",
              "3                      0        1  \n",
              "4                      0        1  \n",
              "...                  ...      ...  \n",
              "91297                  0        0  \n",
              "91298                  0        0  \n",
              "91299                  0        0  \n",
              "91300                  0        0  \n",
              "91301                  0        0  \n",
              "\n",
              "[91302 rows x 1001 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e973308a-ecbf-4fb6-9936-963e133ea4d9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GetProcAddress</th>\n",
              "      <th>ExitProcess</th>\n",
              "      <th>WriteFile</th>\n",
              "      <th>GetLastError</th>\n",
              "      <th>CloseHandle</th>\n",
              "      <th>FreeLibrary</th>\n",
              "      <th>Sleep</th>\n",
              "      <th>GetStdHandle</th>\n",
              "      <th>MultiByteToWideChar</th>\n",
              "      <th>GetCurrentThreadId</th>\n",
              "      <th>...</th>\n",
              "      <th>bind</th>\n",
              "      <th>RegEnumKeyExA</th>\n",
              "      <th>WinHttpOpen</th>\n",
              "      <th>_controlfp</th>\n",
              "      <th>WinExec</th>\n",
              "      <th>GetSecurityDescriptorDacl</th>\n",
              "      <th>FindFirstFreeAce</th>\n",
              "      <th>GetTimeFormatW</th>\n",
              "      <th>LookupAccountSidW</th>\n",
              "      <th>malware</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91297</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91298</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91299</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91300</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91301</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>91302 rows × 1001 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e973308a-ecbf-4fb6-9936-963e133ea4d9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e973308a-ecbf-4fb6-9936-963e133ea4d9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e973308a-ecbf-4fb6-9936-963e133ea4d9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
        "\n",
        "rus = SMOTE(random_state = 15)\n",
        "X_res,y_res = rus.fit_resample(X,y)\n",
        "x = pd.DataFrame(X_res)\n",
        "y = pd.DataFrame(y_res)\n",
        "\n",
        "df = pd.concat([x,y], axis = 1)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "id": "LJf5jxhfHEnG",
        "outputId": "1767e6af-84df-4e91-8258-106052aa322a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "sns.set_style('darkgrid')\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.countplot(x = 'malware', data = df)\n",
        "plt.title('Target Variable Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNVRNogQKfPD",
        "outputId": "96367057-be6d-46e4-f5b4-4ec2d5f6893a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After OverSampling, counts of label '1': 45651\n",
            "After OverSampling, counts of label '0': 45651\n"
          ]
        }
      ],
      "source": [
        "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_res == 1)))\n",
        "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_res == 0)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_80mPQrdopV"
      },
      "source": [
        "# creating test file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "manFs1rgdopV"
      },
      "outputs": [],
      "source": [
        "test = df.drop(columns = 'malware')\n",
        "test.to_csv('Test.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2xwVFEhdopW"
      },
      "source": [
        "# Modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPP_upTcHEnH"
      },
      "outputs": [],
      "source": [
        "#features = df.drop\n",
        "y = df['malware']\n",
        "Xd= df.drop(columns = corr_features)\n",
        "Xx = Xd.drop(columns=['malware'])\n",
        "#split train data into train and validation set\n",
        "X_train, X_test, y_train, y_test = train_test_split(Xx, \n",
        "                                                    y,\n",
        "                                                    stratify= y, #to account for class imbalance\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sk2PZuiboaoH"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNpRqwoV6_EE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTZmpwLXdopW"
      },
      "source": [
        "# Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eDYyMRGHEnI"
      },
      "outputs": [],
      "source": [
        "\n",
        "# from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV \n",
        "# from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "\n",
        "# # define models and parameters\n",
        "# model = LogisticRegression()\n",
        "# solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
        "# penalty = ['l2']\n",
        "# c_values = [100, 10, 1.0, 0.1, 0.01]\n",
        "\n",
        "# # define grid search\n",
        "# grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
        "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
        "# grid_result = grid_search.fit(X_train, y_train)\n",
        "# # summarize results\n",
        "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "\n",
        "\n",
        "# # #fit logistic regression model on train data\n",
        "# # model = LogisticRegression()\n",
        "# # model.fit(X_train, y_train)\n",
        "\n",
        "# # # #make predictions on validation set\n",
        "# # preds = model.predict(X_test)\n",
        "# # print (classification_report(y_test,preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2NgbTyENgqf",
        "outputId": "b99a7825-7222-468a-a10f-2d4730385375"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.94      0.94      9131\n",
            "           1       0.94      0.93      0.93      9130\n",
            "\n",
            "    accuracy                           0.93     18261\n",
            "   macro avg       0.93      0.93      0.93     18261\n",
            "weighted avg       0.93      0.93      0.93     18261\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = LogisticRegression(solver='newton-cg', C=100.00, penalty='l2')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# #make predictions on validation set\n",
        "preds = model.predict(X_test)\n",
        "print (classification_report(y_test,preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjOLOU9Zn7Cl"
      },
      "outputs": [],
      "source": [
        "# df_test['malware']\n",
        "# df['malware']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50iLVdVddopX",
        "outputId": "7ec0e91d-99f0-4f1c-da1a-38a1a83de52d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9346142547510059"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "from sklearn.metrics import balanced_accuracy_score\n",
        "#balanced_accuracy_score(df['malware'], df_test['malware'])\n",
        "balanced_accuracy_score(y_test, preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4la6ToIDdopX"
      },
      "source": [
        "# xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7XnXV4kHEnJ",
        "outputId": "54d7b308-0397-4c73-adc5-a2e9312c3a39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "640 fits failed out of a total of 2560.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "17 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 620, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py\", line 1490, in fit\n",
            "    self._Booster = train(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 620, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/training.py\", line 185, in train\n",
            "    bst.update(dtrain, i, obj)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 1918, in update\n",
            "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 279, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: [17:06:44] ../src/objective/./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x68eaf9) [0x7f87ec76eaf9]\n",
            "  [bt] (1) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x6928f4) [0x7f87ec7728f4]\n",
            "  [bt] (2) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2dbbab) [0x7f87ec3bbbab]\n",
            "  [bt] (3) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2e2d3d) [0x7f87ec3c2d3d]\n",
            "  [bt] (4) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2dc339) [0x7f87ec3bc339]\n",
            "  [bt] (5) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7f87ec20dbe0]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.7(+0x6ff5) [0x7f8810992ff5]\n",
            "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.7(+0x640a) [0x7f881099240a]\n",
            "  [bt] (8) /usr/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x12a55) [0x7f880d87fa55]\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "11 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 620, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py\", line 1490, in fit\n",
            "    self._Booster = train(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 620, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/training.py\", line 185, in train\n",
            "    bst.update(dtrain, i, obj)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 1918, in update\n",
            "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 279, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: [17:06:44] ../src/objective/./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x68eaf9) [0x7f45779caaf9]\n",
            "  [bt] (1) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x6928f4) [0x7f45779ce8f4]\n",
            "  [bt] (2) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2dbbab) [0x7f4577617bab]\n",
            "  [bt] (3) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2e2d3d) [0x7f457761ed3d]\n",
            "  [bt] (4) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2dc339) [0x7f4577618339]\n",
            "  [bt] (5) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7f4577469be0]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.7(+0x6ff5) [0x7f459aec7ff5]\n",
            "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.7(+0x640a) [0x7f459aec740a]\n",
            "  [bt] (8) /usr/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x12a55) [0x7f4597db4a55]\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "55 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 620, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py\", line 1490, in fit\n",
            "    self._Booster = train(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 620, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/training.py\", line 185, in train\n",
            "    bst.update(dtrain, i, obj)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 1918, in update\n",
            "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 279, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: [17:06:45] ../src/objective/./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x68eaf9) [0x7f87ec76eaf9]\n",
            "  [bt] (1) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x6928f4) [0x7f87ec7728f4]\n",
            "  [bt] (2) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2dbbab) [0x7f87ec3bbbab]\n",
            "  [bt] (3) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2e2d3d) [0x7f87ec3c2d3d]\n",
            "  [bt] (4) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2dc339) [0x7f87ec3bc339]\n",
            "  [bt] (5) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7f87ec20dbe0]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.7(+0x6ff5) [0x7f8810992ff5]\n",
            "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.7(+0x640a) [0x7f881099240a]\n",
            "  [bt] (8) /usr/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x12a55) [0x7f880d87fa55]\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "52 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 620, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py\", line 1490, in fit\n",
            "    self._Booster = train(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 620, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/training.py\", line 185, in train\n",
            "    bst.update(dtrain, i, obj)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 1918, in update\n",
            "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 279, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: [17:06:45] ../src/objective/./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x68eaf9) [0x7f45779caaf9]\n",
            "  [bt] (1) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x6928f4) [0x7f45779ce8f4]\n",
            "  [bt] (2) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2dbbab) [0x7f4577617bab]\n",
            "  [bt] (3) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2e2d3d) [0x7f457761ed3d]\n",
            "  [bt] (4) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2dc339) [0x7f4577618339]\n",
            "  [bt] (5) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7f4577469be0]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.7(+0x6ff5) [0x7f459aec7ff5]\n",
            "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.7(+0x640a) [0x7f459aec740a]\n",
            "  [bt] (8) /usr/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x12a55) [0x7f4597db4a55]\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "55 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 620, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py\", line 1490, in fit\n",
            "    self._Booster = train(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 620, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/training.py\", line 185, in train\n",
            "    bst.update(dtrain, i, obj)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 1918, in update\n",
            "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 279, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: [17:06:46] ../src/objective/./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x68eaf9) [0x7f87ec76eaf9]\n",
            "  [bt] (1) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x6928f4) [0x7f87ec7728f4]\n",
            "  [bt] (2) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2dbbab) [0x7f87ec3bbbab]\n",
            "  [bt] (3) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2e2d3d) [0x7f87ec3c2d3d]\n",
            "  [bt] (4) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2dc339) [0x7f87ec3bc339]\n",
            "  [bt] (5) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7f87ec20dbe0]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.7(+0x6ff5) [0x7f8810992ff5]\n",
            "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.7(+0x640a) [0x7f881099240a]\n",
            "  [bt] (8) /usr/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x12a55) [0x7f880d87fa55]\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "53 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 620, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py\", line 1490, in fit\n",
            "    self._Booster = train(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 620, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/training.py\", line 185, in train\n",
            "    bst.update(dtrain, i, obj)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 1918, in update\n",
            "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 279, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: [17:06:46] ../src/objective/./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x68eaf9) [0x7f45779caaf9]\n",
            "  [bt] (1) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x6928f4) [0x7f45779ce8f4]\n",
            "  [bt] (2) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2dbbab) [0x7f4577617bab]\n",
            "  [bt] (3) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2e2d3d) [0x7f457761ed3d]\n",
            "  [bt] (4) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2dc339) [0x7f4577618339]\n",
            "  [bt] (5) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7f4577469be0]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.7(+0x6ff5) [0x7f459aec7ff5]\n",
            "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.7(+0x640a) [0x7f459aec740a]\n",
            "  [bt] (8) /usr/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x12a55) [0x7f4597db4a55]\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "57 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 620, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py\", line 1490, in fit\n",
            "    self._Booster = train(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 620, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/training.py\", line 185, in train\n",
            "    bst.update(dtrain, i, obj)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 1918, in update\n",
            "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 279, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: [17:06:47] ../src/objective/./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x68eaf9) [0x7f45779caaf9]\n",
            "  [bt] (1) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x6928f4) [0x7f45779ce8f4]\n",
            "  [bt] (2) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2dbbab) [0x7f4577617bab]\n",
            "  [bt] (3) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2e2d3d) [0x7f457761ed3d]\n",
            "  [bt] (4) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2dc339) [0x7f4577618339]\n",
            "  [bt] (5) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7f4577469be0]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.7(+0x6ff5) [0x7f459aec7ff5]\n",
            "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.7(+0x640a) [0x7f459aec740a]\n",
            "  [bt] (8) /usr/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x12a55) [0x7f4597db4a55]\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "52 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 620, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py\", line 1490, in fit\n",
            "    self._Booster = train(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 620, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/training.py\", line 185, in train\n",
            "    bst.update(dtrain, i, obj)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 1918, in update\n",
            "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 279, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: [17:06:47] ../src/objective/./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x68eaf9) [0x7f87ec76eaf9]\n",
            "  [bt] (1) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x6928f4) [0x7f87ec7728f4]\n",
            "  [bt] (2) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2dbbab) [0x7f87ec3bbbab]\n",
            "  [bt] (3) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2e2d3d) [0x7f87ec3c2d3d]\n",
            "  [bt] (4) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2dc339) [0x7f87ec3bc339]\n",
            "  [bt] (5) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7f87ec20dbe0]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.7(+0x6ff5) [0x7f8810992ff5]\n",
            "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.7(+0x640a) [0x7f881099240a]\n",
            "  [bt] (8) /usr/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x12a55) [0x7f880d87fa55]\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "55 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 620, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py\", line 1490, in fit\n",
            "    self._Booster = train(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 620, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/training.py\", line 185, in train\n",
            "    bst.update(dtrain, i, obj)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 1918, in update\n",
            "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 279, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: [17:06:48] ../src/objective/./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x68eaf9) [0x7f45779caaf9]\n",
            "  [bt] (1) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x6928f4) [0x7f45779ce8f4]\n",
            "  [bt] (2) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2dbbab) [0x7f4577617bab]\n",
            "  [bt] (3) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2e2d3d) [0x7f457761ed3d]\n",
            "  [bt] (4) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2dc339) [0x7f4577618339]\n",
            "  [bt] (5) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7f4577469be0]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.7(+0x6ff5) [0x7f459aec7ff5]\n",
            "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.7(+0x640a) [0x7f459aec740a]\n",
            "  [bt] (8) /usr/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x12a55) [0x7f4597db4a55]\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "56 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 620, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py\", line 1490, in fit\n",
            "    self._Booster = train(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 620, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/training.py\", line 185, in train\n",
            "    bst.update(dtrain, i, obj)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 1918, in update\n",
            "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 279, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: [17:06:48] ../src/objective/./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x68eaf9) [0x7f87ec76eaf9]\n",
            "  [bt] (1) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x6928f4) [0x7f87ec7728f4]\n",
            "  [bt] (2) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2dbbab) [0x7f87ec3bbbab]\n",
            "  [bt] (3) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2e2d3d) [0x7f87ec3c2d3d]\n",
            "  [bt] (4) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2dc339) [0x7f87ec3bc339]\n",
            "  [bt] (5) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7f87ec20dbe0]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.7(+0x6ff5) [0x7f8810992ff5]\n",
            "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.7(+0x640a) [0x7f881099240a]\n",
            "  [bt] (8) /usr/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x12a55) [0x7f880d87fa55]\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "32 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 620, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py\", line 1490, in fit\n",
            "    self._Booster = train(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 620, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/training.py\", line 185, in train\n",
            "    bst.update(dtrain, i, obj)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 1918, in update\n",
            "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 279, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: [17:06:49] ../src/objective/./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x68eaf9) [0x7f45779caaf9]\n",
            "  [bt] (1) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x6928f4) [0x7f45779ce8f4]\n",
            "  [bt] (2) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2dbbab) [0x7f4577617bab]\n",
            "  [bt] (3) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2e2d3d) [0x7f457761ed3d]\n",
            "  [bt] (4) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2dc339) [0x7f4577618339]\n",
            "  [bt] (5) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7f4577469be0]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.7(+0x6ff5) [0x7f459aec7ff5]\n",
            "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.7(+0x640a) [0x7f459aec740a]\n",
            "  [bt] (8) /usr/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x12a55) [0x7f4597db4a55]\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "34 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 620, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py\", line 1490, in fit\n",
            "    self._Booster = train(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 620, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/training.py\", line 185, in train\n",
            "    bst.update(dtrain, i, obj)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 1918, in update\n",
            "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 279, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: [17:06:49] ../src/objective/./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x68eaf9) [0x7f87ec76eaf9]\n",
            "  [bt] (1) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x6928f4) [0x7f87ec7728f4]\n",
            "  [bt] (2) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2dbbab) [0x7f87ec3bbbab]\n",
            "  [bt] (3) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2e2d3d) [0x7f87ec3c2d3d]\n",
            "  [bt] (4) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2dc339) [0x7f87ec3bc339]\n",
            "  [bt] (5) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7f87ec20dbe0]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.7(+0x6ff5) [0x7f8810992ff5]\n",
            "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.7(+0x640a) [0x7f881099240a]\n",
            "  [bt] (8) /usr/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x12a55) [0x7f880d87fa55]\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "32 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 620, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py\", line 1490, in fit\n",
            "    self._Booster = train(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 620, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/training.py\", line 185, in train\n",
            "    bst.update(dtrain, i, obj)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 1918, in update\n",
            "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 279, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: [17:06:50] ../src/objective/./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x68eaf9) [0x7f45779caaf9]\n",
            "  [bt] (1) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x6928f4) [0x7f45779ce8f4]\n",
            "  [bt] (2) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2dbbab) [0x7f4577617bab]\n",
            "  [bt] (3) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2e2d3d) [0x7f457761ed3d]\n",
            "  [bt] (4) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2dc339) [0x7f4577618339]\n",
            "  [bt] (5) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7f4577469be0]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.7(+0x6ff5) [0x7f459aec7ff5]\n",
            "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.7(+0x640a) [0x7f459aec740a]\n",
            "  [bt] (8) /usr/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x12a55) [0x7f4597db4a55]\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "30 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 620, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py\", line 1490, in fit\n",
            "    self._Booster = train(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 620, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/training.py\", line 185, in train\n",
            "    bst.update(dtrain, i, obj)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 1918, in update\n",
            "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 279, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: [17:06:50] ../src/objective/./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x68eaf9) [0x7f87ec76eaf9]\n",
            "  [bt] (1) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x6928f4) [0x7f87ec7728f4]\n",
            "  [bt] (2) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2dbbab) [0x7f87ec3bbbab]\n",
            "  [bt] (3) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2e2d3d) [0x7f87ec3c2d3d]\n",
            "  [bt] (4) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2dc339) [0x7f87ec3bc339]\n",
            "  [bt] (5) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7f87ec20dbe0]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.7(+0x6ff5) [0x7f8810992ff5]\n",
            "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.7(+0x640a) [0x7f881099240a]\n",
            "  [bt] (8) /usr/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x12a55) [0x7f880d87fa55]\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "26 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 620, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py\", line 1490, in fit\n",
            "    self._Booster = train(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 620, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/training.py\", line 185, in train\n",
            "    bst.update(dtrain, i, obj)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 1918, in update\n",
            "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 279, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: [17:06:51] ../src/objective/./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x68eaf9) [0x7f45779caaf9]\n",
            "  [bt] (1) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x6928f4) [0x7f45779ce8f4]\n",
            "  [bt] (2) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2dbbab) [0x7f4577617bab]\n",
            "  [bt] (3) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2e2d3d) [0x7f457761ed3d]\n",
            "  [bt] (4) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2dc339) [0x7f4577618339]\n",
            "  [bt] (5) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7f4577469be0]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.7(+0x6ff5) [0x7f459aec7ff5]\n",
            "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.7(+0x640a) [0x7f459aec740a]\n",
            "  [bt] (8) /usr/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x12a55) [0x7f4597db4a55]\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "23 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 620, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/sklearn.py\", line 1490, in fit\n",
            "    self._Booster = train(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 620, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/training.py\", line 185, in train\n",
            "    bst.update(dtrain, i, obj)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 1918, in update\n",
            "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/xgboost/core.py\", line 279, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: [17:06:51] ../src/objective/./regression_loss.h:94: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 1\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x68eaf9) [0x7f87ec76eaf9]\n",
            "  [bt] (1) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x6928f4) [0x7f87ec7728f4]\n",
            "  [bt] (2) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2dbbab) [0x7f87ec3bbbab]\n",
            "  [bt] (3) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2e2d3d) [0x7f87ec3c2d3d]\n",
            "  [bt] (4) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2dc339) [0x7f87ec3bc339]\n",
            "  [bt] (5) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7f87ec20dbe0]\n",
            "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.7(+0x6ff5) [0x7f8810992ff5]\n",
            "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.7(+0x640a) [0x7f881099240a]\n",
            "  [bt] (8) /usr/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x12a55) [0x7f880d87fa55]\n",
            "\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.78728814 0.80751412 0.81090395 0.80073446 0.84124294 0.86135593\n",
            " 0.85468927 0.83440678 0.87824859 0.8579096  0.86141243 0.83435028\n",
            " 0.86129944 0.85463277 0.85468927 0.83096045 0.8380226  0.87146893\n",
            " 0.85468927 0.85474576 0.87146893 0.87824859 0.85463277 0.83779661\n",
            " 0.87824859 0.8579661  0.85463277 0.83774011 0.8579096  0.8580226\n",
            " 0.85124294 0.83779661 0.86141243 0.86468927 0.8580791  0.86485876\n",
            " 0.88163842 0.86813559 0.85463277 0.85124294 0.87146893 0.84785311\n",
            " 0.85129944 0.82762712 0.85457627 0.85468927 0.84451977 0.82084746\n",
            " 0.86819209 0.86146893 0.8580791  0.85474576 0.88502825 0.86146893\n",
            " 0.85129944 0.82768362 0.86468927 0.85463277 0.85129944 0.83785311\n",
            " 0.85451977 0.86485876 0.85468927 0.84457627 0.84785311 0.84785311\n",
            " 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311\n",
            " 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311\n",
            " 0.84785311 0.84785311 0.84457627 0.84457627 0.84457627 0.84457627\n",
            " 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627\n",
            " 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627\n",
            " 0.83785311 0.83785311 0.83785311 0.83785311 0.83785311 0.83785311\n",
            " 0.83785311 0.83785311 0.83785311 0.83785311 0.83785311 0.83785311\n",
            " 0.83785311 0.83785311 0.83785311 0.83785311 0.83107345 0.83107345\n",
            " 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345\n",
            " 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345\n",
            " 0.83107345 0.83107345 0.77378531 0.79745763 0.80073446 0.80751412\n",
            " 0.8480226  0.8580226  0.85468927 0.84107345 0.86813559 0.8579661\n",
            " 0.86141243 0.83774011 0.8680791  0.87491525 0.85463277 0.83435028\n",
            " 0.85124294 0.8579661  0.8580791  0.85474576 0.88163842 0.87152542\n",
            " 0.85129944 0.84446328 0.87485876 0.86813559 0.84785311 0.8479661\n",
            " 0.86129944 0.85468927 0.84446328 0.84457627 0.86480226 0.85474576\n",
            " 0.86485876 0.85129944 0.88169492 0.85463277 0.85129944 0.84112994\n",
            " 0.8680791  0.8579661  0.84107345 0.84112994 0.86129944 0.85468927\n",
            " 0.85124294 0.84118644 0.86474576 0.86485876 0.85468927 0.84118644\n",
            " 0.87824859 0.84457627 0.83774011 0.83101695 0.86813559 0.86135593\n",
            " 0.8479096  0.84457627 0.8680791  0.8580791  0.85129944 0.84457627\n",
            " 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311\n",
            " 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311\n",
            " 0.84785311 0.84785311 0.84785311 0.84785311 0.84457627 0.84457627\n",
            " 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627\n",
            " 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627\n",
            " 0.84457627 0.84457627 0.83446328 0.83446328 0.83446328 0.83446328\n",
            " 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328\n",
            " 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328\n",
            " 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345\n",
            " 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345\n",
            " 0.83107345 0.83107345 0.83107345 0.83107345 0.78389831 0.80418079\n",
            " 0.79062147 0.80757062 0.85146893 0.84480226 0.8580226  0.84107345\n",
            " 0.86819209 0.87158192 0.84779661 0.82751412 0.86474576 0.85457627\n",
            " 0.83774011 0.83090395 0.8380226  0.86468927 0.84451977 0.86485876\n",
            " 0.87158192 0.86141243 0.85124294 0.84446328 0.87830508 0.8580226\n",
            " 0.84785311 0.82412429 0.87152542 0.85124294 0.84112994 0.83429379\n",
            " 0.86819209 0.86480226 0.86146893 0.8580791  0.87158192 0.86146893\n",
            " 0.85124294 0.83768362 0.8579661  0.86480226 0.84785311 0.83096045\n",
            " 0.86474576 0.85124294 0.84118644 0.82757062 0.87158192 0.86474576\n",
            " 0.8580791  0.8580226  0.87824859 0.8479096  0.85118644 0.83435028\n",
            " 0.86135593 0.85124294 0.84785311 0.81745763 0.8680791  0.8580226\n",
            " 0.83435028 0.81745763 0.85124294 0.85124294 0.85124294 0.85124294\n",
            " 0.85124294 0.85124294 0.85124294 0.85124294 0.85124294 0.85124294\n",
            " 0.85124294 0.85124294 0.85124294 0.85124294 0.85124294 0.85124294\n",
            " 0.84124294 0.84124294 0.84124294 0.84124294 0.84124294 0.84124294\n",
            " 0.84124294 0.84124294 0.84124294 0.84124294 0.84124294 0.84124294\n",
            " 0.84124294 0.84124294 0.84124294 0.84124294 0.83446328 0.83446328\n",
            " 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328\n",
            " 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328\n",
            " 0.83446328 0.83446328 0.83107345 0.83107345 0.83107345 0.83107345\n",
            " 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345\n",
            " 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [0.88238145 0.87738145 0.87655858 0.86404463 0.93577406 0.92743375\n",
            " 0.91409693 0.90574965 0.96078801 0.94661088 0.93409693 0.9099198\n",
            " 0.9666318  0.95329498 0.93826709 0.90992678 0.9274198  0.93161088\n",
            " 0.92409693 0.91074965 0.95578801 0.95328801 0.9424477  0.92993026\n",
            " 0.96996862 0.96079498 0.95162134 0.93744073 0.97414575 0.96580195\n",
            " 0.95329149 0.93660739 0.94578452 0.9424477  0.93493724 0.9299198\n",
            " 0.9641318  0.95745816 0.95162831 0.93661088 0.97247211 0.96662831\n",
            " 0.95412831 0.94161088 0.97414575 0.96830195 0.95829847 0.9424477\n",
            " 0.95161785 0.94912134 0.93995119 0.93410739 0.96996862 0.9616318\n",
            " 0.95579498 0.94578452 0.97330893 0.96997211 0.95829498 0.9449477\n",
            " 0.97497908 0.96997211 0.95829498 0.94578103 0.97081939 0.97081939\n",
            " 0.97081939 0.97081939 0.97081939 0.97081939 0.97081939 0.97081939\n",
            " 0.97081939 0.97081939 0.97081939 0.97081939 0.97081939 0.97081939\n",
            " 0.97081939 0.97081939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.87987796 0.87488145 0.87322176 0.86904463\n",
            " 0.92491283 0.92743724 0.91826011 0.90908647 0.95745467 0.94660739\n",
            " 0.93409693 0.92326011 0.96830195 0.95162483 0.93827057 0.91992329\n",
            " 0.92993375 0.92827406 0.92243026 0.9115795  0.95078801 0.95078801\n",
            " 0.93827406 0.9307636  0.97080195 0.96162831 0.95079149 0.94160739\n",
            " 0.97330893 0.96246165 0.95078801 0.93994073 0.9449477  0.94328103\n",
            " 0.93744073 0.92241632 0.9641318  0.95745816 0.95245467 0.93911437\n",
            " 0.97247211 0.96663529 0.95579498 0.9449477  0.97330893 0.96746862\n",
            " 0.95662831 0.94661437 0.95495816 0.94745467 0.94161785 0.93326709\n",
            " 0.97080195 0.95912831 0.95662831 0.94578452 0.97414226 0.96913529\n",
            " 0.95996165 0.94828452 0.97497908 0.96997211 0.95829847 0.9474477\n",
            " 0.96998605 0.96998605 0.96998605 0.96998605 0.96998605 0.96998605\n",
            " 0.96998605 0.96998605 0.96998605 0.96998605 0.96998605 0.96998605\n",
            " 0.96998605 0.96998605 0.96998605 0.96998605 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.87988145 0.87487448\n",
            " 0.86988842 0.86821827 0.9274198  0.9190795  0.91742678 0.90992678\n",
            " 0.96079149 0.94911785 0.93243026 0.91908996 0.96996862 0.94661437\n",
            " 0.93493375 0.91908996 0.92741283 0.9257636  0.91743375 0.9115795\n",
            " 0.95245119 0.94995467 0.94161437 0.92743724 0.97163529 0.96079498\n",
            " 0.95329149 0.94078103 0.97247211 0.96246165 0.95078801 0.94078103\n",
            " 0.9474477  0.93994421 0.93327406 0.92659344 0.96328801 0.95829149\n",
            " 0.95079149 0.93660739 0.97330544 0.96496513 0.95579498 0.94578103\n",
            " 0.97414575 0.96997211 0.95579498 0.9449477  0.95328801 0.94745119\n",
            " 0.94161785 0.93075662 0.97247211 0.96329498 0.95579149 0.94244421\n",
            " 0.97414226 0.96830195 0.95912831 0.94745119 0.97497908 0.96997211\n",
            " 0.95996165 0.94661785 0.97247908 0.97247908 0.97247908 0.97247908\n",
            " 0.97247908 0.97247908 0.97247908 0.97247908 0.97247908 0.97247908\n",
            " 0.97247908 0.97247908 0.97247908 0.97247908 0.97247908 0.97247908\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.78728814 0.80751412 0.81090395 0.80073446 0.84124294 0.86135593\n",
            " 0.85468927 0.83440678 0.87824859 0.8579096  0.86141243 0.83435028\n",
            " 0.86129944 0.85463277 0.85468927 0.83096045 0.8380226  0.87146893\n",
            " 0.85468927 0.85474576 0.87146893 0.87824859 0.85463277 0.83779661\n",
            " 0.87824859 0.8579661  0.85463277 0.83774011 0.8579096  0.8580226\n",
            " 0.85124294 0.83779661 0.86141243 0.86468927 0.8580791  0.86485876\n",
            " 0.88163842 0.86813559 0.85463277 0.85124294 0.87146893 0.84785311\n",
            " 0.85129944 0.82762712 0.85457627 0.85468927 0.84451977 0.82084746\n",
            " 0.86819209 0.86146893 0.8580791  0.85474576 0.88502825 0.86146893\n",
            " 0.85129944 0.82768362 0.86468927 0.85463277 0.85129944 0.83785311\n",
            " 0.85451977 0.86485876 0.85468927 0.84457627 0.84785311 0.84785311\n",
            " 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311\n",
            " 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311\n",
            " 0.84785311 0.84785311 0.84457627 0.84457627 0.84457627 0.84457627\n",
            " 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627\n",
            " 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627\n",
            " 0.83785311 0.83785311 0.83785311 0.83785311 0.83785311 0.83785311\n",
            " 0.83785311 0.83785311 0.83785311 0.83785311 0.83785311 0.83785311\n",
            " 0.83785311 0.83785311 0.83785311 0.83785311 0.83107345 0.83107345\n",
            " 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345\n",
            " 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345\n",
            " 0.83107345 0.83107345 0.77378531 0.79745763 0.80073446 0.80751412\n",
            " 0.8480226  0.8580226  0.85468927 0.84107345 0.86813559 0.8579661\n",
            " 0.86141243 0.83774011 0.8680791  0.87491525 0.85463277 0.83435028\n",
            " 0.85124294 0.8579661  0.8580791  0.85474576 0.88163842 0.87152542\n",
            " 0.85129944 0.84446328 0.87485876 0.86813559 0.84785311 0.8479661\n",
            " 0.86129944 0.85468927 0.84446328 0.84457627 0.86480226 0.85474576\n",
            " 0.86485876 0.85129944 0.88169492 0.85463277 0.85129944 0.84112994\n",
            " 0.8680791  0.8579661  0.84107345 0.84112994 0.86129944 0.85468927\n",
            " 0.85124294 0.84118644 0.86474576 0.86485876 0.85468927 0.84118644\n",
            " 0.87824859 0.84457627 0.83774011 0.83101695 0.86813559 0.86135593\n",
            " 0.8479096  0.84457627 0.8680791  0.8580791  0.85129944 0.84457627\n",
            " 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311\n",
            " 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311\n",
            " 0.84785311 0.84785311 0.84785311 0.84785311 0.84457627 0.84457627\n",
            " 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627\n",
            " 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627\n",
            " 0.84457627 0.84457627 0.83446328 0.83446328 0.83446328 0.83446328\n",
            " 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328\n",
            " 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328\n",
            " 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345\n",
            " 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345\n",
            " 0.83107345 0.83107345 0.83107345 0.83107345 0.78389831 0.80418079\n",
            " 0.79062147 0.80757062 0.85146893 0.84480226 0.8580226  0.84107345\n",
            " 0.86819209 0.87158192 0.84779661 0.82751412 0.86474576 0.85457627\n",
            " 0.83774011 0.83090395 0.8380226  0.86468927 0.84451977 0.86485876\n",
            " 0.87158192 0.86141243 0.85124294 0.84446328 0.87830508 0.8580226\n",
            " 0.84785311 0.82412429 0.87152542 0.85124294 0.84112994 0.83429379\n",
            " 0.86819209 0.86480226 0.86146893 0.8580791  0.87158192 0.86146893\n",
            " 0.85124294 0.83768362 0.8579661  0.86480226 0.84785311 0.83096045\n",
            " 0.86474576 0.85124294 0.84118644 0.82757062 0.87158192 0.86474576\n",
            " 0.8580791  0.8580226  0.87824859 0.8479096  0.85118644 0.83435028\n",
            " 0.86135593 0.85124294 0.84785311 0.81745763 0.8680791  0.8580226\n",
            " 0.83435028 0.81745763 0.85124294 0.85124294 0.85124294 0.85124294\n",
            " 0.85124294 0.85124294 0.85124294 0.85124294 0.85124294 0.85124294\n",
            " 0.85124294 0.85124294 0.85124294 0.85124294 0.85124294 0.85124294\n",
            " 0.84124294 0.84124294 0.84124294 0.84124294 0.84124294 0.84124294\n",
            " 0.84124294 0.84124294 0.84124294 0.84124294 0.84124294 0.84124294\n",
            " 0.84124294 0.84124294 0.84124294 0.84124294 0.83446328 0.83446328\n",
            " 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328\n",
            " 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328\n",
            " 0.83446328 0.83446328 0.83107345 0.83107345 0.83107345 0.83107345\n",
            " 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345\n",
            " 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan 0.89733085 0.89733085 0.90067039 0.89733085\n",
            " 0.89733085 0.89733085 0.89733085 0.89733085 0.89733085 0.89733085\n",
            " 0.91292365 0.89733085 0.89733085 0.89733085 0.90067039 0.90067039\n",
            " 0.90067039 0.90067039 0.90067039 0.90067039 0.90067039 0.90067039\n",
            " 0.90067039 0.90067039 0.90067039 0.90067039 0.90067039 0.91404718\n",
            " 0.92073867 0.90958411 0.9151707  0.90513346 0.90511484 0.89171322\n",
            " 0.90734947 0.90178771 0.91849162 0.92407821 0.90512104 0.90178771\n",
            " 0.90178771 0.90178771 0.92520174 0.90178771 0.90178771 0.91962756\n",
            " 0.90178771 0.90178771 0.90178771 0.90178771 0.90178771 0.92630043\n",
            " 0.88725636 0.90178771 0.90846058 0.91068281 0.90178771 0.90178771\n",
            " 0.90178771 0.90178771 0.92299193 0.91292365 0.90404718 0.89954687\n",
            " 0.88950962 0.91515208 0.90175667 0.89283054 0.92072626 0.91180012\n",
            " 0.92184978 0.90512104 0.91071384 0.90734327 0.90957169 0.89841092\n",
            " 0.92631906 0.90958411 0.89731223 0.88725636 0.92072626 0.91403476\n",
            " 0.92518932 0.92630664 0.88837989 0.91405338 0.8883923  0.89285537\n",
            " 0.88504655 0.8816946  0.89620112 0.90288641 0.92183737 0.92520795\n",
            " 0.92407821 0.88725636 0.89507138 0.90624457 0.89170701 0.92184978\n",
            " 0.88949721 0.91180633 0.89729361 0.91962135 0.89844196 0.89732464\n",
            " 0.89841092 0.89285537 0.91180633 0.89509621 0.91179392 0.92073246\n",
            " 0.92184358 0.92741155 0.92297331 0.89171322 0.89283675 0.89395407\n",
            " 0.90065798 0.90065798 0.89844196 0.90623215 0.89730602 0.90181254\n",
            " 0.88612663 0.92852886 0.89509621 0.90177529 0.91626319 0.89954066\n",
            " 0.92408442 0.91404097 0.88950962 0.89731844 0.89510242 0.91740534\n",
            " 0.90402235 0.89620732 0.89172564 0.91739292 0.90623215 0.92183737\n",
            " 0.92072005 0.92073246 0.90849162 0.91293606 0.89731223 0.8905959\n",
            " 0.89955307 0.89731223 0.88837368 0.91851024 0.90065798 0.90176909\n",
            " 0.92408442 0.89729981 0.89842334 0.90959032 0.89954066 0.91515829\n",
            " 0.90846058 0.89842955 0.90177529 0.9140658  0.90736809 0.91628181\n",
            " 0.90959032 0.8961887  0.90625698 0.90847921 0.91183116]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [0.88238145 0.87738145 0.87655858 0.86404463 0.93577406 0.92743375\n",
            " 0.91409693 0.90574965 0.96078801 0.94661088 0.93409693 0.9099198\n",
            " 0.9666318  0.95329498 0.93826709 0.90992678 0.9274198  0.93161088\n",
            " 0.92409693 0.91074965 0.95578801 0.95328801 0.9424477  0.92993026\n",
            " 0.96996862 0.96079498 0.95162134 0.93744073 0.97414575 0.96580195\n",
            " 0.95329149 0.93660739 0.94578452 0.9424477  0.93493724 0.9299198\n",
            " 0.9641318  0.95745816 0.95162831 0.93661088 0.97247211 0.96662831\n",
            " 0.95412831 0.94161088 0.97414575 0.96830195 0.95829847 0.9424477\n",
            " 0.95161785 0.94912134 0.93995119 0.93410739 0.96996862 0.9616318\n",
            " 0.95579498 0.94578452 0.97330893 0.96997211 0.95829498 0.9449477\n",
            " 0.97497908 0.96997211 0.95829498 0.94578103 0.97081939 0.97081939\n",
            " 0.97081939 0.97081939 0.97081939 0.97081939 0.97081939 0.97081939\n",
            " 0.97081939 0.97081939 0.97081939 0.97081939 0.97081939 0.97081939\n",
            " 0.97081939 0.97081939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.87987796 0.87488145 0.87322176 0.86904463\n",
            " 0.92491283 0.92743724 0.91826011 0.90908647 0.95745467 0.94660739\n",
            " 0.93409693 0.92326011 0.96830195 0.95162483 0.93827057 0.91992329\n",
            " 0.92993375 0.92827406 0.92243026 0.9115795  0.95078801 0.95078801\n",
            " 0.93827406 0.9307636  0.97080195 0.96162831 0.95079149 0.94160739\n",
            " 0.97330893 0.96246165 0.95078801 0.93994073 0.9449477  0.94328103\n",
            " 0.93744073 0.92241632 0.9641318  0.95745816 0.95245467 0.93911437\n",
            " 0.97247211 0.96663529 0.95579498 0.9449477  0.97330893 0.96746862\n",
            " 0.95662831 0.94661437 0.95495816 0.94745467 0.94161785 0.93326709\n",
            " 0.97080195 0.95912831 0.95662831 0.94578452 0.97414226 0.96913529\n",
            " 0.95996165 0.94828452 0.97497908 0.96997211 0.95829847 0.9474477\n",
            " 0.96998605 0.96998605 0.96998605 0.96998605 0.96998605 0.96998605\n",
            " 0.96998605 0.96998605 0.96998605 0.96998605 0.96998605 0.96998605\n",
            " 0.96998605 0.96998605 0.96998605 0.96998605 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.87988145 0.87487448\n",
            " 0.86988842 0.86821827 0.9274198  0.9190795  0.91742678 0.90992678\n",
            " 0.96079149 0.94911785 0.93243026 0.91908996 0.96996862 0.94661437\n",
            " 0.93493375 0.91908996 0.92741283 0.9257636  0.91743375 0.9115795\n",
            " 0.95245119 0.94995467 0.94161437 0.92743724 0.97163529 0.96079498\n",
            " 0.95329149 0.94078103 0.97247211 0.96246165 0.95078801 0.94078103\n",
            " 0.9474477  0.93994421 0.93327406 0.92659344 0.96328801 0.95829149\n",
            " 0.95079149 0.93660739 0.97330544 0.96496513 0.95579498 0.94578103\n",
            " 0.97414575 0.96997211 0.95579498 0.9449477  0.95328801 0.94745119\n",
            " 0.94161785 0.93075662 0.97247211 0.96329498 0.95579149 0.94244421\n",
            " 0.97414226 0.96830195 0.95912831 0.94745119 0.97497908 0.96997211\n",
            " 0.95996165 0.94661785 0.97247908 0.97247908 0.97247908 0.97247908\n",
            " 0.97247908 0.97247908 0.97247908 0.97247908 0.97247908 0.97247908\n",
            " 0.97247908 0.97247908 0.97247908 0.97247908 0.97247908 0.97247908\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan 0.95665508 0.95665508 0.95776657 0.95665508\n",
            " 0.95665508 0.95665508 0.95665508 0.95665508 0.95665508 0.95665508\n",
            " 0.94970715 0.95665508 0.95665508 0.95665508 0.95776657 0.95776657\n",
            " 0.95776657 0.95776657 0.95776657 0.95776657 0.95776657 0.95776657\n",
            " 0.95776657 0.95776657 0.95776657 0.95776657 0.95776657 0.9569317\n",
            " 0.96193285 0.95081827 0.96026619 0.95026232 0.94442938 0.91942165\n",
            " 0.94692783 0.95776619 0.95748802 0.96443479 0.93275769 0.95776619\n",
            " 0.95776619 0.95776619 0.96499034 0.95776619 0.95776619 0.96110029\n",
            " 0.95776619 0.95776619 0.95776619 0.95776619 0.95776619 0.96721334\n",
            " 0.9155316  0.95776619 0.9380374  0.94081556 0.95776619 0.95776619\n",
            " 0.95776619 0.95776619 0.95887653 0.96304551 0.94776155 0.93164735\n",
            " 0.92025537 0.95581943 0.93914928 0.91525344 0.97499343 0.95387614\n",
            " 0.9741601  0.94693015 0.93942667 0.94387228 0.95387575 0.9324803\n",
            " 0.96332329 0.95054049 0.92970252 0.91330783 0.96415662 0.94609604\n",
            " 0.96721334 0.96693479 0.91664078 0.96360029 0.91386494 0.92636687\n",
            " 0.91164194 0.91358677 0.92942358 0.93720368 0.9722145  0.95998764\n",
            " 0.96637884 0.91469904 0.93470252 0.95276232 0.91747721 0.96304512\n",
            " 0.9119174  0.95248609 0.92720175 0.96832445 0.92303469 0.92720097\n",
            " 0.92747914 0.91747643 0.96971334 0.92275653 0.96332406 0.97165933\n",
            " 0.97388193 0.96999227 0.96526773 0.91830938 0.92859025 0.93192435\n",
            " 0.92997952 0.93025846 0.93525962 0.9435945  0.92358909 0.94859488\n",
            " 0.91330861 0.97026966 0.92581131 0.93025807 0.96554667 0.93164928\n",
            " 0.97360454 0.96026619 0.92720136 0.92636764 0.92275537 0.96832483\n",
            " 0.93414735 0.92108948 0.91219788 0.96554551 0.96304551 0.97471565\n",
            " 0.97499343 0.97027005 0.94220484 0.95165237 0.93748184 0.92636841\n",
            " 0.93831518 0.93442551 0.91469788 0.96610184 0.93248261 0.93331518\n",
            " 0.97138116 0.9344259  0.93164812 0.94359527 0.93248223 0.95776503\n",
            " 0.9535972  0.9391489  0.93275923 0.95443092 0.95804281 0.95498802\n",
            " 0.95498648 0.93359411 0.94415083 0.94637382 0.95415237]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.78728814 0.80751412 0.81090395 0.80073446 0.84124294 0.86135593\n",
            " 0.85468927 0.83440678 0.87824859 0.8579096  0.86141243 0.83435028\n",
            " 0.86129944 0.85463277 0.85468927 0.83096045 0.8380226  0.87146893\n",
            " 0.85468927 0.85474576 0.87146893 0.87824859 0.85463277 0.83779661\n",
            " 0.87824859 0.8579661  0.85463277 0.83774011 0.8579096  0.8580226\n",
            " 0.85124294 0.83779661 0.86141243 0.86468927 0.8580791  0.86485876\n",
            " 0.88163842 0.86813559 0.85463277 0.85124294 0.87146893 0.84785311\n",
            " 0.85129944 0.82762712 0.85457627 0.85468927 0.84451977 0.82084746\n",
            " 0.86819209 0.86146893 0.8580791  0.85474576 0.88502825 0.86146893\n",
            " 0.85129944 0.82768362 0.86468927 0.85463277 0.85129944 0.83785311\n",
            " 0.85451977 0.86485876 0.85468927 0.84457627 0.84785311 0.84785311\n",
            " 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311\n",
            " 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311\n",
            " 0.84785311 0.84785311 0.84457627 0.84457627 0.84457627 0.84457627\n",
            " 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627\n",
            " 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627\n",
            " 0.83785311 0.83785311 0.83785311 0.83785311 0.83785311 0.83785311\n",
            " 0.83785311 0.83785311 0.83785311 0.83785311 0.83785311 0.83785311\n",
            " 0.83785311 0.83785311 0.83785311 0.83785311 0.83107345 0.83107345\n",
            " 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345\n",
            " 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345\n",
            " 0.83107345 0.83107345 0.77378531 0.79745763 0.80073446 0.80751412\n",
            " 0.8480226  0.8580226  0.85468927 0.84107345 0.86813559 0.8579661\n",
            " 0.86141243 0.83774011 0.8680791  0.87491525 0.85463277 0.83435028\n",
            " 0.85124294 0.8579661  0.8580791  0.85474576 0.88163842 0.87152542\n",
            " 0.85129944 0.84446328 0.87485876 0.86813559 0.84785311 0.8479661\n",
            " 0.86129944 0.85468927 0.84446328 0.84457627 0.86480226 0.85474576\n",
            " 0.86485876 0.85129944 0.88169492 0.85463277 0.85129944 0.84112994\n",
            " 0.8680791  0.8579661  0.84107345 0.84112994 0.86129944 0.85468927\n",
            " 0.85124294 0.84118644 0.86474576 0.86485876 0.85468927 0.84118644\n",
            " 0.87824859 0.84457627 0.83774011 0.83101695 0.86813559 0.86135593\n",
            " 0.8479096  0.84457627 0.8680791  0.8580791  0.85129944 0.84457627\n",
            " 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311\n",
            " 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311\n",
            " 0.84785311 0.84785311 0.84785311 0.84785311 0.84457627 0.84457627\n",
            " 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627\n",
            " 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627\n",
            " 0.84457627 0.84457627 0.83446328 0.83446328 0.83446328 0.83446328\n",
            " 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328\n",
            " 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328\n",
            " 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345\n",
            " 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345\n",
            " 0.83107345 0.83107345 0.83107345 0.83107345 0.78389831 0.80418079\n",
            " 0.79062147 0.80757062 0.85146893 0.84480226 0.8580226  0.84107345\n",
            " 0.86819209 0.87158192 0.84779661 0.82751412 0.86474576 0.85457627\n",
            " 0.83774011 0.83090395 0.8380226  0.86468927 0.84451977 0.86485876\n",
            " 0.87158192 0.86141243 0.85124294 0.84446328 0.87830508 0.8580226\n",
            " 0.84785311 0.82412429 0.87152542 0.85124294 0.84112994 0.83429379\n",
            " 0.86819209 0.86480226 0.86146893 0.8580791  0.87158192 0.86146893\n",
            " 0.85124294 0.83768362 0.8579661  0.86480226 0.84785311 0.83096045\n",
            " 0.86474576 0.85124294 0.84118644 0.82757062 0.87158192 0.86474576\n",
            " 0.8580791  0.8580226  0.87824859 0.8479096  0.85118644 0.83435028\n",
            " 0.86135593 0.85124294 0.84785311 0.81745763 0.8680791  0.8580226\n",
            " 0.83435028 0.81745763 0.85124294 0.85124294 0.85124294 0.85124294\n",
            " 0.85124294 0.85124294 0.85124294 0.85124294 0.85124294 0.85124294\n",
            " 0.85124294 0.85124294 0.85124294 0.85124294 0.85124294 0.85124294\n",
            " 0.84124294 0.84124294 0.84124294 0.84124294 0.84124294 0.84124294\n",
            " 0.84124294 0.84124294 0.84124294 0.84124294 0.84124294 0.84124294\n",
            " 0.84124294 0.84124294 0.84124294 0.84124294 0.83446328 0.83446328\n",
            " 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328\n",
            " 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328\n",
            " 0.83446328 0.83446328 0.83107345 0.83107345 0.83107345 0.83107345\n",
            " 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345\n",
            " 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan 0.89733085 0.89733085 0.90067039 0.89733085\n",
            " 0.89733085 0.89733085 0.89733085 0.89733085 0.89733085 0.89733085\n",
            " 0.91292365 0.89733085 0.89733085 0.89733085 0.90067039 0.90067039\n",
            " 0.90067039 0.90067039 0.90067039 0.90067039 0.90067039 0.90067039\n",
            " 0.90067039 0.90067039 0.90067039 0.90067039 0.90067039 0.91404718\n",
            " 0.92073867 0.90958411 0.9151707  0.90513346 0.90511484 0.89171322\n",
            " 0.90734947 0.90178771 0.91849162 0.92407821 0.90512104 0.90178771\n",
            " 0.90178771 0.90178771 0.92520174 0.90178771 0.90178771 0.91962756\n",
            " 0.90178771 0.90178771 0.90178771 0.90178771 0.90178771 0.92630043\n",
            " 0.88725636 0.90178771 0.90846058 0.91068281 0.90178771 0.90178771\n",
            " 0.90178771 0.90178771 0.92299193 0.91292365 0.90404718 0.89954687\n",
            " 0.88950962 0.91515208 0.90175667 0.89283054 0.92072626 0.91180012\n",
            " 0.92184978 0.90512104 0.91071384 0.90734327 0.90957169 0.89841092\n",
            " 0.92631906 0.90958411 0.89731223 0.88725636 0.92072626 0.91403476\n",
            " 0.92518932 0.92630664 0.88837989 0.91405338 0.8883923  0.89285537\n",
            " 0.88504655 0.8816946  0.89620112 0.90288641 0.92183737 0.92520795\n",
            " 0.92407821 0.88725636 0.89507138 0.90624457 0.89170701 0.92184978\n",
            " 0.88949721 0.91180633 0.89729361 0.91962135 0.89844196 0.89732464\n",
            " 0.89841092 0.89285537 0.91180633 0.89509621 0.91179392 0.92073246\n",
            " 0.92184358 0.92741155 0.92297331 0.89171322 0.89283675 0.89395407\n",
            " 0.90065798 0.90065798 0.89844196 0.90623215 0.89730602 0.90181254\n",
            " 0.88612663 0.92852886 0.89509621 0.90177529 0.91626319 0.89954066\n",
            " 0.92408442 0.91404097 0.88950962 0.89731844 0.89510242 0.91740534\n",
            " 0.90402235 0.89620732 0.89172564 0.91739292 0.90623215 0.92183737\n",
            " 0.92072005 0.92073246 0.90849162 0.91293606 0.89731223 0.8905959\n",
            " 0.89955307 0.89731223 0.88837368 0.91851024 0.90065798 0.90176909\n",
            " 0.92408442 0.89729981 0.89842334 0.90959032 0.89954066 0.91515829\n",
            " 0.90846058 0.89842955 0.90177529 0.9140658  0.90736809 0.91628181\n",
            " 0.90959032 0.8961887  0.90625698 0.90847921 0.91183116 0.91914244\n",
            " 0.92915344 0.92396344 0.92507524 0.91468907 0.92507456 0.91654367\n",
            " 0.91728578 0.93360544 0.92655741 0.94139765 0.92396344 0.92211022\n",
            " 0.93954305 0.92396138 0.92581667 0.92729953 0.93249364 0.92804439\n",
            " 0.93880231 0.92322202 0.92952725 0.92359307 0.93323645 0.93063836\n",
            " 0.92099567 0.93138322 0.94065485 0.9336075  0.93063973 0.94065966\n",
            " 0.93546279 0.94399643 0.94102659 0.93509311 0.93620697 0.93916993\n",
            " 0.93026592 0.94436405 0.93954236 0.94176802 0.93954442 0.93583385\n",
            " 0.93323782 0.93101285 0.93397925 0.93398131 0.94139902 0.93731808\n",
            " 0.93991479 0.93397994 0.92915413 0.93991617 0.93954374 0.93249708\n",
            " 0.93917199 0.93805882]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [0.88238145 0.87738145 0.87655858 0.86404463 0.93577406 0.92743375\n",
            " 0.91409693 0.90574965 0.96078801 0.94661088 0.93409693 0.9099198\n",
            " 0.9666318  0.95329498 0.93826709 0.90992678 0.9274198  0.93161088\n",
            " 0.92409693 0.91074965 0.95578801 0.95328801 0.9424477  0.92993026\n",
            " 0.96996862 0.96079498 0.95162134 0.93744073 0.97414575 0.96580195\n",
            " 0.95329149 0.93660739 0.94578452 0.9424477  0.93493724 0.9299198\n",
            " 0.9641318  0.95745816 0.95162831 0.93661088 0.97247211 0.96662831\n",
            " 0.95412831 0.94161088 0.97414575 0.96830195 0.95829847 0.9424477\n",
            " 0.95161785 0.94912134 0.93995119 0.93410739 0.96996862 0.9616318\n",
            " 0.95579498 0.94578452 0.97330893 0.96997211 0.95829498 0.9449477\n",
            " 0.97497908 0.96997211 0.95829498 0.94578103 0.97081939 0.97081939\n",
            " 0.97081939 0.97081939 0.97081939 0.97081939 0.97081939 0.97081939\n",
            " 0.97081939 0.97081939 0.97081939 0.97081939 0.97081939 0.97081939\n",
            " 0.97081939 0.97081939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.87987796 0.87488145 0.87322176 0.86904463\n",
            " 0.92491283 0.92743724 0.91826011 0.90908647 0.95745467 0.94660739\n",
            " 0.93409693 0.92326011 0.96830195 0.95162483 0.93827057 0.91992329\n",
            " 0.92993375 0.92827406 0.92243026 0.9115795  0.95078801 0.95078801\n",
            " 0.93827406 0.9307636  0.97080195 0.96162831 0.95079149 0.94160739\n",
            " 0.97330893 0.96246165 0.95078801 0.93994073 0.9449477  0.94328103\n",
            " 0.93744073 0.92241632 0.9641318  0.95745816 0.95245467 0.93911437\n",
            " 0.97247211 0.96663529 0.95579498 0.9449477  0.97330893 0.96746862\n",
            " 0.95662831 0.94661437 0.95495816 0.94745467 0.94161785 0.93326709\n",
            " 0.97080195 0.95912831 0.95662831 0.94578452 0.97414226 0.96913529\n",
            " 0.95996165 0.94828452 0.97497908 0.96997211 0.95829847 0.9474477\n",
            " 0.96998605 0.96998605 0.96998605 0.96998605 0.96998605 0.96998605\n",
            " 0.96998605 0.96998605 0.96998605 0.96998605 0.96998605 0.96998605\n",
            " 0.96998605 0.96998605 0.96998605 0.96998605 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.87988145 0.87487448\n",
            " 0.86988842 0.86821827 0.9274198  0.9190795  0.91742678 0.90992678\n",
            " 0.96079149 0.94911785 0.93243026 0.91908996 0.96996862 0.94661437\n",
            " 0.93493375 0.91908996 0.92741283 0.9257636  0.91743375 0.9115795\n",
            " 0.95245119 0.94995467 0.94161437 0.92743724 0.97163529 0.96079498\n",
            " 0.95329149 0.94078103 0.97247211 0.96246165 0.95078801 0.94078103\n",
            " 0.9474477  0.93994421 0.93327406 0.92659344 0.96328801 0.95829149\n",
            " 0.95079149 0.93660739 0.97330544 0.96496513 0.95579498 0.94578103\n",
            " 0.97414575 0.96997211 0.95579498 0.9449477  0.95328801 0.94745119\n",
            " 0.94161785 0.93075662 0.97247211 0.96329498 0.95579149 0.94244421\n",
            " 0.97414226 0.96830195 0.95912831 0.94745119 0.97497908 0.96997211\n",
            " 0.95996165 0.94661785 0.97247908 0.97247908 0.97247908 0.97247908\n",
            " 0.97247908 0.97247908 0.97247908 0.97247908 0.97247908 0.97247908\n",
            " 0.97247908 0.97247908 0.97247908 0.97247908 0.97247908 0.97247908\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan 0.95665508 0.95665508 0.95776657 0.95665508\n",
            " 0.95665508 0.95665508 0.95665508 0.95665508 0.95665508 0.95665508\n",
            " 0.94970715 0.95665508 0.95665508 0.95665508 0.95776657 0.95776657\n",
            " 0.95776657 0.95776657 0.95776657 0.95776657 0.95776657 0.95776657\n",
            " 0.95776657 0.95776657 0.95776657 0.95776657 0.95776657 0.9569317\n",
            " 0.96193285 0.95081827 0.96026619 0.95026232 0.94442938 0.91942165\n",
            " 0.94692783 0.95776619 0.95748802 0.96443479 0.93275769 0.95776619\n",
            " 0.95776619 0.95776619 0.96499034 0.95776619 0.95776619 0.96110029\n",
            " 0.95776619 0.95776619 0.95776619 0.95776619 0.95776619 0.96721334\n",
            " 0.9155316  0.95776619 0.9380374  0.94081556 0.95776619 0.95776619\n",
            " 0.95776619 0.95776619 0.95887653 0.96304551 0.94776155 0.93164735\n",
            " 0.92025537 0.95581943 0.93914928 0.91525344 0.97499343 0.95387614\n",
            " 0.9741601  0.94693015 0.93942667 0.94387228 0.95387575 0.9324803\n",
            " 0.96332329 0.95054049 0.92970252 0.91330783 0.96415662 0.94609604\n",
            " 0.96721334 0.96693479 0.91664078 0.96360029 0.91386494 0.92636687\n",
            " 0.91164194 0.91358677 0.92942358 0.93720368 0.9722145  0.95998764\n",
            " 0.96637884 0.91469904 0.93470252 0.95276232 0.91747721 0.96304512\n",
            " 0.9119174  0.95248609 0.92720175 0.96832445 0.92303469 0.92720097\n",
            " 0.92747914 0.91747643 0.96971334 0.92275653 0.96332406 0.97165933\n",
            " 0.97388193 0.96999227 0.96526773 0.91830938 0.92859025 0.93192435\n",
            " 0.92997952 0.93025846 0.93525962 0.9435945  0.92358909 0.94859488\n",
            " 0.91330861 0.97026966 0.92581131 0.93025807 0.96554667 0.93164928\n",
            " 0.97360454 0.96026619 0.92720136 0.92636764 0.92275537 0.96832483\n",
            " 0.93414735 0.92108948 0.91219788 0.96554551 0.96304551 0.97471565\n",
            " 0.97499343 0.97027005 0.94220484 0.95165237 0.93748184 0.92636841\n",
            " 0.93831518 0.93442551 0.91469788 0.96610184 0.93248261 0.93331518\n",
            " 0.97138116 0.9344259  0.93164812 0.94359527 0.93248223 0.95776503\n",
            " 0.9535972  0.9391489  0.93275923 0.95443092 0.95804281 0.95498802\n",
            " 0.95498648 0.93359411 0.94415083 0.94637382 0.95415237 0.93480963\n",
            " 0.95490316 0.94295812 0.94119851 0.93369813 0.94555088 0.93221656\n",
            " 0.93323517 0.96249696 0.95379192 0.9698122  0.94490269 0.94286535\n",
            " 0.96731194 0.94184692 0.94360614 0.95138464 0.95573654 0.95286595\n",
            " 0.96694157 0.94110609 0.95231031 0.94610635 0.95925553 0.95990372\n",
            " 0.94082832 0.95592181 0.9698122  0.96203373 0.95619933 0.96999743\n",
            " 0.96527469 0.97249777 0.97268296 0.96425591 0.96258899 0.96786763\n",
            " 0.95916315 0.97249781 0.96805277 0.97157172 0.9717569  0.96555255\n",
            " 0.96092267 0.96008895 0.96481177 0.95555152 0.97166439 0.96814545\n",
            " 0.96870083 0.96129291 0.95305144 0.96805277 0.96860832 0.96101496\n",
            " 0.96342267 0.96231151]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.78728814 0.80751412 0.81090395 0.80073446 0.84124294 0.86135593\n",
            " 0.85468927 0.83440678 0.87824859 0.8579096  0.86141243 0.83435028\n",
            " 0.86129944 0.85463277 0.85468927 0.83096045 0.8380226  0.87146893\n",
            " 0.85468927 0.85474576 0.87146893 0.87824859 0.85463277 0.83779661\n",
            " 0.87824859 0.8579661  0.85463277 0.83774011 0.8579096  0.8580226\n",
            " 0.85124294 0.83779661 0.86141243 0.86468927 0.8580791  0.86485876\n",
            " 0.88163842 0.86813559 0.85463277 0.85124294 0.87146893 0.84785311\n",
            " 0.85129944 0.82762712 0.85457627 0.85468927 0.84451977 0.82084746\n",
            " 0.86819209 0.86146893 0.8580791  0.85474576 0.88502825 0.86146893\n",
            " 0.85129944 0.82768362 0.86468927 0.85463277 0.85129944 0.83785311\n",
            " 0.85451977 0.86485876 0.85468927 0.84457627 0.84785311 0.84785311\n",
            " 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311\n",
            " 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311\n",
            " 0.84785311 0.84785311 0.84457627 0.84457627 0.84457627 0.84457627\n",
            " 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627\n",
            " 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627\n",
            " 0.83785311 0.83785311 0.83785311 0.83785311 0.83785311 0.83785311\n",
            " 0.83785311 0.83785311 0.83785311 0.83785311 0.83785311 0.83785311\n",
            " 0.83785311 0.83785311 0.83785311 0.83785311 0.83107345 0.83107345\n",
            " 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345\n",
            " 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345\n",
            " 0.83107345 0.83107345 0.77378531 0.79745763 0.80073446 0.80751412\n",
            " 0.8480226  0.8580226  0.85468927 0.84107345 0.86813559 0.8579661\n",
            " 0.86141243 0.83774011 0.8680791  0.87491525 0.85463277 0.83435028\n",
            " 0.85124294 0.8579661  0.8580791  0.85474576 0.88163842 0.87152542\n",
            " 0.85129944 0.84446328 0.87485876 0.86813559 0.84785311 0.8479661\n",
            " 0.86129944 0.85468927 0.84446328 0.84457627 0.86480226 0.85474576\n",
            " 0.86485876 0.85129944 0.88169492 0.85463277 0.85129944 0.84112994\n",
            " 0.8680791  0.8579661  0.84107345 0.84112994 0.86129944 0.85468927\n",
            " 0.85124294 0.84118644 0.86474576 0.86485876 0.85468927 0.84118644\n",
            " 0.87824859 0.84457627 0.83774011 0.83101695 0.86813559 0.86135593\n",
            " 0.8479096  0.84457627 0.8680791  0.8580791  0.85129944 0.84457627\n",
            " 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311\n",
            " 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311\n",
            " 0.84785311 0.84785311 0.84785311 0.84785311 0.84457627 0.84457627\n",
            " 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627\n",
            " 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627\n",
            " 0.84457627 0.84457627 0.83446328 0.83446328 0.83446328 0.83446328\n",
            " 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328\n",
            " 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328\n",
            " 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345\n",
            " 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345\n",
            " 0.83107345 0.83107345 0.83107345 0.83107345 0.78389831 0.80418079\n",
            " 0.79062147 0.80757062 0.85146893 0.84480226 0.8580226  0.84107345\n",
            " 0.86819209 0.87158192 0.84779661 0.82751412 0.86474576 0.85457627\n",
            " 0.83774011 0.83090395 0.8380226  0.86468927 0.84451977 0.86485876\n",
            " 0.87158192 0.86141243 0.85124294 0.84446328 0.87830508 0.8580226\n",
            " 0.84785311 0.82412429 0.87152542 0.85124294 0.84112994 0.83429379\n",
            " 0.86819209 0.86480226 0.86146893 0.8580791  0.87158192 0.86146893\n",
            " 0.85124294 0.83768362 0.8579661  0.86480226 0.84785311 0.83096045\n",
            " 0.86474576 0.85124294 0.84118644 0.82757062 0.87158192 0.86474576\n",
            " 0.8580791  0.8580226  0.87824859 0.8479096  0.85118644 0.83435028\n",
            " 0.86135593 0.85124294 0.84785311 0.81745763 0.8680791  0.8580226\n",
            " 0.83435028 0.81745763 0.85124294 0.85124294 0.85124294 0.85124294\n",
            " 0.85124294 0.85124294 0.85124294 0.85124294 0.85124294 0.85124294\n",
            " 0.85124294 0.85124294 0.85124294 0.85124294 0.85124294 0.85124294\n",
            " 0.84124294 0.84124294 0.84124294 0.84124294 0.84124294 0.84124294\n",
            " 0.84124294 0.84124294 0.84124294 0.84124294 0.84124294 0.84124294\n",
            " 0.84124294 0.84124294 0.84124294 0.84124294 0.83446328 0.83446328\n",
            " 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328\n",
            " 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328\n",
            " 0.83446328 0.83446328 0.83107345 0.83107345 0.83107345 0.83107345\n",
            " 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345\n",
            " 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan 0.89733085 0.89733085 0.90067039 0.89733085\n",
            " 0.89733085 0.89733085 0.89733085 0.89733085 0.89733085 0.89733085\n",
            " 0.91292365 0.89733085 0.89733085 0.89733085 0.90067039 0.90067039\n",
            " 0.90067039 0.90067039 0.90067039 0.90067039 0.90067039 0.90067039\n",
            " 0.90067039 0.90067039 0.90067039 0.90067039 0.90067039 0.91404718\n",
            " 0.92073867 0.90958411 0.9151707  0.90513346 0.90511484 0.89171322\n",
            " 0.90734947 0.90178771 0.91849162 0.92407821 0.90512104 0.90178771\n",
            " 0.90178771 0.90178771 0.92520174 0.90178771 0.90178771 0.91962756\n",
            " 0.90178771 0.90178771 0.90178771 0.90178771 0.90178771 0.92630043\n",
            " 0.88725636 0.90178771 0.90846058 0.91068281 0.90178771 0.90178771\n",
            " 0.90178771 0.90178771 0.92299193 0.91292365 0.90404718 0.89954687\n",
            " 0.88950962 0.91515208 0.90175667 0.89283054 0.92072626 0.91180012\n",
            " 0.92184978 0.90512104 0.91071384 0.90734327 0.90957169 0.89841092\n",
            " 0.92631906 0.90958411 0.89731223 0.88725636 0.92072626 0.91403476\n",
            " 0.92518932 0.92630664 0.88837989 0.91405338 0.8883923  0.89285537\n",
            " 0.88504655 0.8816946  0.89620112 0.90288641 0.92183737 0.92520795\n",
            " 0.92407821 0.88725636 0.89507138 0.90624457 0.89170701 0.92184978\n",
            " 0.88949721 0.91180633 0.89729361 0.91962135 0.89844196 0.89732464\n",
            " 0.89841092 0.89285537 0.91180633 0.89509621 0.91179392 0.92073246\n",
            " 0.92184358 0.92741155 0.92297331 0.89171322 0.89283675 0.89395407\n",
            " 0.90065798 0.90065798 0.89844196 0.90623215 0.89730602 0.90181254\n",
            " 0.88612663 0.92852886 0.89509621 0.90177529 0.91626319 0.89954066\n",
            " 0.92408442 0.91404097 0.88950962 0.89731844 0.89510242 0.91740534\n",
            " 0.90402235 0.89620732 0.89172564 0.91739292 0.90623215 0.92183737\n",
            " 0.92072005 0.92073246 0.90849162 0.91293606 0.89731223 0.8905959\n",
            " 0.89955307 0.89731223 0.88837368 0.91851024 0.90065798 0.90176909\n",
            " 0.92408442 0.89729981 0.89842334 0.90959032 0.89954066 0.91515829\n",
            " 0.90846058 0.89842955 0.90177529 0.9140658  0.90736809 0.91628181\n",
            " 0.90959032 0.8961887  0.90625698 0.90847921 0.91183116 0.91914244\n",
            " 0.92915344 0.92396344 0.92507524 0.91468907 0.92507456 0.91654367\n",
            " 0.91728578 0.93360544 0.92655741 0.94139765 0.92396344 0.92211022\n",
            " 0.93954305 0.92396138 0.92581667 0.92729953 0.93249364 0.92804439\n",
            " 0.93880231 0.92322202 0.92952725 0.92359307 0.93323645 0.93063836\n",
            " 0.92099567 0.93138322 0.94065485 0.9336075  0.93063973 0.94065966\n",
            " 0.93546279 0.94399643 0.94102659 0.93509311 0.93620697 0.93916993\n",
            " 0.93026592 0.94436405 0.93954236 0.94176802 0.93954442 0.93583385\n",
            " 0.93323782 0.93101285 0.93397925 0.93398131 0.94139902 0.93731808\n",
            " 0.93991479 0.93397994 0.92915413 0.93991617 0.93954374 0.93249708\n",
            " 0.93917199 0.93805882 0.9508398  0.94417031 0.95293955 0.95108648\n",
            " 0.94701088 0.95059265 0.95244595 0.95207475 0.95256903 0.95232181\n",
            " 0.95331015 0.95244565 0.95392782 0.95331008 0.95306309 0.95306301\n",
            " 0.95392759 0.95454502 0.95503954]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [0.88238145 0.87738145 0.87655858 0.86404463 0.93577406 0.92743375\n",
            " 0.91409693 0.90574965 0.96078801 0.94661088 0.93409693 0.9099198\n",
            " 0.9666318  0.95329498 0.93826709 0.90992678 0.9274198  0.93161088\n",
            " 0.92409693 0.91074965 0.95578801 0.95328801 0.9424477  0.92993026\n",
            " 0.96996862 0.96079498 0.95162134 0.93744073 0.97414575 0.96580195\n",
            " 0.95329149 0.93660739 0.94578452 0.9424477  0.93493724 0.9299198\n",
            " 0.9641318  0.95745816 0.95162831 0.93661088 0.97247211 0.96662831\n",
            " 0.95412831 0.94161088 0.97414575 0.96830195 0.95829847 0.9424477\n",
            " 0.95161785 0.94912134 0.93995119 0.93410739 0.96996862 0.9616318\n",
            " 0.95579498 0.94578452 0.97330893 0.96997211 0.95829498 0.9449477\n",
            " 0.97497908 0.96997211 0.95829498 0.94578103 0.97081939 0.97081939\n",
            " 0.97081939 0.97081939 0.97081939 0.97081939 0.97081939 0.97081939\n",
            " 0.97081939 0.97081939 0.97081939 0.97081939 0.97081939 0.97081939\n",
            " 0.97081939 0.97081939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.87987796 0.87488145 0.87322176 0.86904463\n",
            " 0.92491283 0.92743724 0.91826011 0.90908647 0.95745467 0.94660739\n",
            " 0.93409693 0.92326011 0.96830195 0.95162483 0.93827057 0.91992329\n",
            " 0.92993375 0.92827406 0.92243026 0.9115795  0.95078801 0.95078801\n",
            " 0.93827406 0.9307636  0.97080195 0.96162831 0.95079149 0.94160739\n",
            " 0.97330893 0.96246165 0.95078801 0.93994073 0.9449477  0.94328103\n",
            " 0.93744073 0.92241632 0.9641318  0.95745816 0.95245467 0.93911437\n",
            " 0.97247211 0.96663529 0.95579498 0.9449477  0.97330893 0.96746862\n",
            " 0.95662831 0.94661437 0.95495816 0.94745467 0.94161785 0.93326709\n",
            " 0.97080195 0.95912831 0.95662831 0.94578452 0.97414226 0.96913529\n",
            " 0.95996165 0.94828452 0.97497908 0.96997211 0.95829847 0.9474477\n",
            " 0.96998605 0.96998605 0.96998605 0.96998605 0.96998605 0.96998605\n",
            " 0.96998605 0.96998605 0.96998605 0.96998605 0.96998605 0.96998605\n",
            " 0.96998605 0.96998605 0.96998605 0.96998605 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.87988145 0.87487448\n",
            " 0.86988842 0.86821827 0.9274198  0.9190795  0.91742678 0.90992678\n",
            " 0.96079149 0.94911785 0.93243026 0.91908996 0.96996862 0.94661437\n",
            " 0.93493375 0.91908996 0.92741283 0.9257636  0.91743375 0.9115795\n",
            " 0.95245119 0.94995467 0.94161437 0.92743724 0.97163529 0.96079498\n",
            " 0.95329149 0.94078103 0.97247211 0.96246165 0.95078801 0.94078103\n",
            " 0.9474477  0.93994421 0.93327406 0.92659344 0.96328801 0.95829149\n",
            " 0.95079149 0.93660739 0.97330544 0.96496513 0.95579498 0.94578103\n",
            " 0.97414575 0.96997211 0.95579498 0.9449477  0.95328801 0.94745119\n",
            " 0.94161785 0.93075662 0.97247211 0.96329498 0.95579149 0.94244421\n",
            " 0.97414226 0.96830195 0.95912831 0.94745119 0.97497908 0.96997211\n",
            " 0.95996165 0.94661785 0.97247908 0.97247908 0.97247908 0.97247908\n",
            " 0.97247908 0.97247908 0.97247908 0.97247908 0.97247908 0.97247908\n",
            " 0.97247908 0.97247908 0.97247908 0.97247908 0.97247908 0.97247908\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan 0.95665508 0.95665508 0.95776657 0.95665508\n",
            " 0.95665508 0.95665508 0.95665508 0.95665508 0.95665508 0.95665508\n",
            " 0.94970715 0.95665508 0.95665508 0.95665508 0.95776657 0.95776657\n",
            " 0.95776657 0.95776657 0.95776657 0.95776657 0.95776657 0.95776657\n",
            " 0.95776657 0.95776657 0.95776657 0.95776657 0.95776657 0.9569317\n",
            " 0.96193285 0.95081827 0.96026619 0.95026232 0.94442938 0.91942165\n",
            " 0.94692783 0.95776619 0.95748802 0.96443479 0.93275769 0.95776619\n",
            " 0.95776619 0.95776619 0.96499034 0.95776619 0.95776619 0.96110029\n",
            " 0.95776619 0.95776619 0.95776619 0.95776619 0.95776619 0.96721334\n",
            " 0.9155316  0.95776619 0.9380374  0.94081556 0.95776619 0.95776619\n",
            " 0.95776619 0.95776619 0.95887653 0.96304551 0.94776155 0.93164735\n",
            " 0.92025537 0.95581943 0.93914928 0.91525344 0.97499343 0.95387614\n",
            " 0.9741601  0.94693015 0.93942667 0.94387228 0.95387575 0.9324803\n",
            " 0.96332329 0.95054049 0.92970252 0.91330783 0.96415662 0.94609604\n",
            " 0.96721334 0.96693479 0.91664078 0.96360029 0.91386494 0.92636687\n",
            " 0.91164194 0.91358677 0.92942358 0.93720368 0.9722145  0.95998764\n",
            " 0.96637884 0.91469904 0.93470252 0.95276232 0.91747721 0.96304512\n",
            " 0.9119174  0.95248609 0.92720175 0.96832445 0.92303469 0.92720097\n",
            " 0.92747914 0.91747643 0.96971334 0.92275653 0.96332406 0.97165933\n",
            " 0.97388193 0.96999227 0.96526773 0.91830938 0.92859025 0.93192435\n",
            " 0.92997952 0.93025846 0.93525962 0.9435945  0.92358909 0.94859488\n",
            " 0.91330861 0.97026966 0.92581131 0.93025807 0.96554667 0.93164928\n",
            " 0.97360454 0.96026619 0.92720136 0.92636764 0.92275537 0.96832483\n",
            " 0.93414735 0.92108948 0.91219788 0.96554551 0.96304551 0.97471565\n",
            " 0.97499343 0.97027005 0.94220484 0.95165237 0.93748184 0.92636841\n",
            " 0.93831518 0.93442551 0.91469788 0.96610184 0.93248261 0.93331518\n",
            " 0.97138116 0.9344259  0.93164812 0.94359527 0.93248223 0.95776503\n",
            " 0.9535972  0.9391489  0.93275923 0.95443092 0.95804281 0.95498802\n",
            " 0.95498648 0.93359411 0.94415083 0.94637382 0.95415237 0.93480963\n",
            " 0.95490316 0.94295812 0.94119851 0.93369813 0.94555088 0.93221656\n",
            " 0.93323517 0.96249696 0.95379192 0.9698122  0.94490269 0.94286535\n",
            " 0.96731194 0.94184692 0.94360614 0.95138464 0.95573654 0.95286595\n",
            " 0.96694157 0.94110609 0.95231031 0.94610635 0.95925553 0.95990372\n",
            " 0.94082832 0.95592181 0.9698122  0.96203373 0.95619933 0.96999743\n",
            " 0.96527469 0.97249777 0.97268296 0.96425591 0.96258899 0.96786763\n",
            " 0.95916315 0.97249781 0.96805277 0.97157172 0.9717569  0.96555255\n",
            " 0.96092267 0.96008895 0.96481177 0.95555152 0.97166439 0.96814545\n",
            " 0.96870083 0.96129291 0.95305144 0.96805277 0.96860832 0.96101496\n",
            " 0.96342267 0.96231151 0.96663477 0.95975173 0.96759164 0.96675822\n",
            " 0.96052337 0.96644963 0.96719037 0.96762247 0.96944354 0.96734473\n",
            " 0.96737558 0.96913487 0.96928923 0.9715424  0.96910402 0.96996824\n",
            " 0.96996824 0.9710794  0.97120288]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.78728814 0.80751412 0.81090395 0.80073446 0.84124294 0.86135593\n",
            " 0.85468927 0.83440678 0.87824859 0.8579096  0.86141243 0.83435028\n",
            " 0.86129944 0.85463277 0.85468927 0.83096045 0.8380226  0.87146893\n",
            " 0.85468927 0.85474576 0.87146893 0.87824859 0.85463277 0.83779661\n",
            " 0.87824859 0.8579661  0.85463277 0.83774011 0.8579096  0.8580226\n",
            " 0.85124294 0.83779661 0.86141243 0.86468927 0.8580791  0.86485876\n",
            " 0.88163842 0.86813559 0.85463277 0.85124294 0.87146893 0.84785311\n",
            " 0.85129944 0.82762712 0.85457627 0.85468927 0.84451977 0.82084746\n",
            " 0.86819209 0.86146893 0.8580791  0.85474576 0.88502825 0.86146893\n",
            " 0.85129944 0.82768362 0.86468927 0.85463277 0.85129944 0.83785311\n",
            " 0.85451977 0.86485876 0.85468927 0.84457627 0.84785311 0.84785311\n",
            " 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311\n",
            " 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311\n",
            " 0.84785311 0.84785311 0.84457627 0.84457627 0.84457627 0.84457627\n",
            " 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627\n",
            " 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627\n",
            " 0.83785311 0.83785311 0.83785311 0.83785311 0.83785311 0.83785311\n",
            " 0.83785311 0.83785311 0.83785311 0.83785311 0.83785311 0.83785311\n",
            " 0.83785311 0.83785311 0.83785311 0.83785311 0.83107345 0.83107345\n",
            " 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345\n",
            " 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345\n",
            " 0.83107345 0.83107345 0.77378531 0.79745763 0.80073446 0.80751412\n",
            " 0.8480226  0.8580226  0.85468927 0.84107345 0.86813559 0.8579661\n",
            " 0.86141243 0.83774011 0.8680791  0.87491525 0.85463277 0.83435028\n",
            " 0.85124294 0.8579661  0.8580791  0.85474576 0.88163842 0.87152542\n",
            " 0.85129944 0.84446328 0.87485876 0.86813559 0.84785311 0.8479661\n",
            " 0.86129944 0.85468927 0.84446328 0.84457627 0.86480226 0.85474576\n",
            " 0.86485876 0.85129944 0.88169492 0.85463277 0.85129944 0.84112994\n",
            " 0.8680791  0.8579661  0.84107345 0.84112994 0.86129944 0.85468927\n",
            " 0.85124294 0.84118644 0.86474576 0.86485876 0.85468927 0.84118644\n",
            " 0.87824859 0.84457627 0.83774011 0.83101695 0.86813559 0.86135593\n",
            " 0.8479096  0.84457627 0.8680791  0.8580791  0.85129944 0.84457627\n",
            " 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311\n",
            " 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311 0.84785311\n",
            " 0.84785311 0.84785311 0.84785311 0.84785311 0.84457627 0.84457627\n",
            " 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627\n",
            " 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627 0.84457627\n",
            " 0.84457627 0.84457627 0.83446328 0.83446328 0.83446328 0.83446328\n",
            " 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328\n",
            " 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328\n",
            " 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345\n",
            " 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345\n",
            " 0.83107345 0.83107345 0.83107345 0.83107345 0.78389831 0.80418079\n",
            " 0.79062147 0.80757062 0.85146893 0.84480226 0.8580226  0.84107345\n",
            " 0.86819209 0.87158192 0.84779661 0.82751412 0.86474576 0.85457627\n",
            " 0.83774011 0.83090395 0.8380226  0.86468927 0.84451977 0.86485876\n",
            " 0.87158192 0.86141243 0.85124294 0.84446328 0.87830508 0.8580226\n",
            " 0.84785311 0.82412429 0.87152542 0.85124294 0.84112994 0.83429379\n",
            " 0.86819209 0.86480226 0.86146893 0.8580791  0.87158192 0.86146893\n",
            " 0.85124294 0.83768362 0.8579661  0.86480226 0.84785311 0.83096045\n",
            " 0.86474576 0.85124294 0.84118644 0.82757062 0.87158192 0.86474576\n",
            " 0.8580791  0.8580226  0.87824859 0.8479096  0.85118644 0.83435028\n",
            " 0.86135593 0.85124294 0.84785311 0.81745763 0.8680791  0.8580226\n",
            " 0.83435028 0.81745763 0.85124294 0.85124294 0.85124294 0.85124294\n",
            " 0.85124294 0.85124294 0.85124294 0.85124294 0.85124294 0.85124294\n",
            " 0.85124294 0.85124294 0.85124294 0.85124294 0.85124294 0.85124294\n",
            " 0.84124294 0.84124294 0.84124294 0.84124294 0.84124294 0.84124294\n",
            " 0.84124294 0.84124294 0.84124294 0.84124294 0.84124294 0.84124294\n",
            " 0.84124294 0.84124294 0.84124294 0.84124294 0.83446328 0.83446328\n",
            " 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328\n",
            " 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328 0.83446328\n",
            " 0.83446328 0.83446328 0.83107345 0.83107345 0.83107345 0.83107345\n",
            " 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345\n",
            " 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345 0.83107345\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan 0.89733085 0.89733085 0.90067039 0.89733085\n",
            " 0.89733085 0.89733085 0.89733085 0.89733085 0.89733085 0.89733085\n",
            " 0.91292365 0.89733085 0.89733085 0.89733085 0.90067039 0.90067039\n",
            " 0.90067039 0.90067039 0.90067039 0.90067039 0.90067039 0.90067039\n",
            " 0.90067039 0.90067039 0.90067039 0.90067039 0.90067039 0.91404718\n",
            " 0.92073867 0.90958411 0.9151707  0.90513346 0.90511484 0.89171322\n",
            " 0.90734947 0.90178771 0.91849162 0.92407821 0.90512104 0.90178771\n",
            " 0.90178771 0.90178771 0.92520174 0.90178771 0.90178771 0.91962756\n",
            " 0.90178771 0.90178771 0.90178771 0.90178771 0.90178771 0.92630043\n",
            " 0.88725636 0.90178771 0.90846058 0.91068281 0.90178771 0.90178771\n",
            " 0.90178771 0.90178771 0.92299193 0.91292365 0.90404718 0.89954687\n",
            " 0.88950962 0.91515208 0.90175667 0.89283054 0.92072626 0.91180012\n",
            " 0.92184978 0.90512104 0.91071384 0.90734327 0.90957169 0.89841092\n",
            " 0.92631906 0.90958411 0.89731223 0.88725636 0.92072626 0.91403476\n",
            " 0.92518932 0.92630664 0.88837989 0.91405338 0.8883923  0.89285537\n",
            " 0.88504655 0.8816946  0.89620112 0.90288641 0.92183737 0.92520795\n",
            " 0.92407821 0.88725636 0.89507138 0.90624457 0.89170701 0.92184978\n",
            " 0.88949721 0.91180633 0.89729361 0.91962135 0.89844196 0.89732464\n",
            " 0.89841092 0.89285537 0.91180633 0.89509621 0.91179392 0.92073246\n",
            " 0.92184358 0.92741155 0.92297331 0.89171322 0.89283675 0.89395407\n",
            " 0.90065798 0.90065798 0.89844196 0.90623215 0.89730602 0.90181254\n",
            " 0.88612663 0.92852886 0.89509621 0.90177529 0.91626319 0.89954066\n",
            " 0.92408442 0.91404097 0.88950962 0.89731844 0.89510242 0.91740534\n",
            " 0.90402235 0.89620732 0.89172564 0.91739292 0.90623215 0.92183737\n",
            " 0.92072005 0.92073246 0.90849162 0.91293606 0.89731223 0.8905959\n",
            " 0.89955307 0.89731223 0.88837368 0.91851024 0.90065798 0.90176909\n",
            " 0.92408442 0.89729981 0.89842334 0.90959032 0.89954066 0.91515829\n",
            " 0.90846058 0.89842955 0.90177529 0.9140658  0.90736809 0.91628181\n",
            " 0.90959032 0.8961887  0.90625698 0.90847921 0.91183116 0.91914244\n",
            " 0.92915344 0.92396344 0.92507524 0.91468907 0.92507456 0.91654367\n",
            " 0.91728578 0.93360544 0.92655741 0.94139765 0.92396344 0.92211022\n",
            " 0.93954305 0.92396138 0.92581667 0.92729953 0.93249364 0.92804439\n",
            " 0.93880231 0.92322202 0.92952725 0.92359307 0.93323645 0.93063836\n",
            " 0.92099567 0.93138322 0.94065485 0.9336075  0.93063973 0.94065966\n",
            " 0.93546279 0.94399643 0.94102659 0.93509311 0.93620697 0.93916993\n",
            " 0.93026592 0.94436405 0.93954236 0.94176802 0.93954442 0.93583385\n",
            " 0.93323782 0.93101285 0.93397925 0.93398131 0.94139902 0.93731808\n",
            " 0.93991479 0.93397994 0.92915413 0.93991617 0.93954374 0.93249708\n",
            " 0.93917199 0.93805882 0.9508398  0.94417031 0.95293955 0.95108648\n",
            " 0.94701088 0.95059265 0.95244595 0.95207475 0.95256903 0.95232181\n",
            " 0.95331015 0.95244565 0.95392782 0.95331008 0.95306309 0.95306301\n",
            " 0.95392759 0.95454502 0.95503954 0.96102248 0.961434   0.95995228\n",
            " 0.96040505 0.96032273 0.96122827 0.96172217]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [0.88238145 0.87738145 0.87655858 0.86404463 0.93577406 0.92743375\n",
            " 0.91409693 0.90574965 0.96078801 0.94661088 0.93409693 0.9099198\n",
            " 0.9666318  0.95329498 0.93826709 0.90992678 0.9274198  0.93161088\n",
            " 0.92409693 0.91074965 0.95578801 0.95328801 0.9424477  0.92993026\n",
            " 0.96996862 0.96079498 0.95162134 0.93744073 0.97414575 0.96580195\n",
            " 0.95329149 0.93660739 0.94578452 0.9424477  0.93493724 0.9299198\n",
            " 0.9641318  0.95745816 0.95162831 0.93661088 0.97247211 0.96662831\n",
            " 0.95412831 0.94161088 0.97414575 0.96830195 0.95829847 0.9424477\n",
            " 0.95161785 0.94912134 0.93995119 0.93410739 0.96996862 0.9616318\n",
            " 0.95579498 0.94578452 0.97330893 0.96997211 0.95829498 0.9449477\n",
            " 0.97497908 0.96997211 0.95829498 0.94578103 0.97081939 0.97081939\n",
            " 0.97081939 0.97081939 0.97081939 0.97081939 0.97081939 0.97081939\n",
            " 0.97081939 0.97081939 0.97081939 0.97081939 0.97081939 0.97081939\n",
            " 0.97081939 0.97081939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.87987796 0.87488145 0.87322176 0.86904463\n",
            " 0.92491283 0.92743724 0.91826011 0.90908647 0.95745467 0.94660739\n",
            " 0.93409693 0.92326011 0.96830195 0.95162483 0.93827057 0.91992329\n",
            " 0.92993375 0.92827406 0.92243026 0.9115795  0.95078801 0.95078801\n",
            " 0.93827406 0.9307636  0.97080195 0.96162831 0.95079149 0.94160739\n",
            " 0.97330893 0.96246165 0.95078801 0.93994073 0.9449477  0.94328103\n",
            " 0.93744073 0.92241632 0.9641318  0.95745816 0.95245467 0.93911437\n",
            " 0.97247211 0.96663529 0.95579498 0.9449477  0.97330893 0.96746862\n",
            " 0.95662831 0.94661437 0.95495816 0.94745467 0.94161785 0.93326709\n",
            " 0.97080195 0.95912831 0.95662831 0.94578452 0.97414226 0.96913529\n",
            " 0.95996165 0.94828452 0.97497908 0.96997211 0.95829847 0.9474477\n",
            " 0.96998605 0.96998605 0.96998605 0.96998605 0.96998605 0.96998605\n",
            " 0.96998605 0.96998605 0.96998605 0.96998605 0.96998605 0.96998605\n",
            " 0.96998605 0.96998605 0.96998605 0.96998605 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939 0.97581939\n",
            " 0.97581939 0.97581939 0.97581939 0.97581939 0.87988145 0.87487448\n",
            " 0.86988842 0.86821827 0.9274198  0.9190795  0.91742678 0.90992678\n",
            " 0.96079149 0.94911785 0.93243026 0.91908996 0.96996862 0.94661437\n",
            " 0.93493375 0.91908996 0.92741283 0.9257636  0.91743375 0.9115795\n",
            " 0.95245119 0.94995467 0.94161437 0.92743724 0.97163529 0.96079498\n",
            " 0.95329149 0.94078103 0.97247211 0.96246165 0.95078801 0.94078103\n",
            " 0.9474477  0.93994421 0.93327406 0.92659344 0.96328801 0.95829149\n",
            " 0.95079149 0.93660739 0.97330544 0.96496513 0.95579498 0.94578103\n",
            " 0.97414575 0.96997211 0.95579498 0.9449477  0.95328801 0.94745119\n",
            " 0.94161785 0.93075662 0.97247211 0.96329498 0.95579149 0.94244421\n",
            " 0.97414226 0.96830195 0.95912831 0.94745119 0.97497908 0.96997211\n",
            " 0.95996165 0.94661785 0.97247908 0.97247908 0.97247908 0.97247908\n",
            " 0.97247908 0.97247908 0.97247908 0.97247908 0.97247908 0.97247908\n",
            " 0.97247908 0.97247908 0.97247908 0.97247908 0.97247908 0.97247908\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            " 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272 0.97665272\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan 0.95665508 0.95665508 0.95776657 0.95665508\n",
            " 0.95665508 0.95665508 0.95665508 0.95665508 0.95665508 0.95665508\n",
            " 0.94970715 0.95665508 0.95665508 0.95665508 0.95776657 0.95776657\n",
            " 0.95776657 0.95776657 0.95776657 0.95776657 0.95776657 0.95776657\n",
            " 0.95776657 0.95776657 0.95776657 0.95776657 0.95776657 0.9569317\n",
            " 0.96193285 0.95081827 0.96026619 0.95026232 0.94442938 0.91942165\n",
            " 0.94692783 0.95776619 0.95748802 0.96443479 0.93275769 0.95776619\n",
            " 0.95776619 0.95776619 0.96499034 0.95776619 0.95776619 0.96110029\n",
            " 0.95776619 0.95776619 0.95776619 0.95776619 0.95776619 0.96721334\n",
            " 0.9155316  0.95776619 0.9380374  0.94081556 0.95776619 0.95776619\n",
            " 0.95776619 0.95776619 0.95887653 0.96304551 0.94776155 0.93164735\n",
            " 0.92025537 0.95581943 0.93914928 0.91525344 0.97499343 0.95387614\n",
            " 0.9741601  0.94693015 0.93942667 0.94387228 0.95387575 0.9324803\n",
            " 0.96332329 0.95054049 0.92970252 0.91330783 0.96415662 0.94609604\n",
            " 0.96721334 0.96693479 0.91664078 0.96360029 0.91386494 0.92636687\n",
            " 0.91164194 0.91358677 0.92942358 0.93720368 0.9722145  0.95998764\n",
            " 0.96637884 0.91469904 0.93470252 0.95276232 0.91747721 0.96304512\n",
            " 0.9119174  0.95248609 0.92720175 0.96832445 0.92303469 0.92720097\n",
            " 0.92747914 0.91747643 0.96971334 0.92275653 0.96332406 0.97165933\n",
            " 0.97388193 0.96999227 0.96526773 0.91830938 0.92859025 0.93192435\n",
            " 0.92997952 0.93025846 0.93525962 0.9435945  0.92358909 0.94859488\n",
            " 0.91330861 0.97026966 0.92581131 0.93025807 0.96554667 0.93164928\n",
            " 0.97360454 0.96026619 0.92720136 0.92636764 0.92275537 0.96832483\n",
            " 0.93414735 0.92108948 0.91219788 0.96554551 0.96304551 0.97471565\n",
            " 0.97499343 0.97027005 0.94220484 0.95165237 0.93748184 0.92636841\n",
            " 0.93831518 0.93442551 0.91469788 0.96610184 0.93248261 0.93331518\n",
            " 0.97138116 0.9344259  0.93164812 0.94359527 0.93248223 0.95776503\n",
            " 0.9535972  0.9391489  0.93275923 0.95443092 0.95804281 0.95498802\n",
            " 0.95498648 0.93359411 0.94415083 0.94637382 0.95415237 0.93480963\n",
            " 0.95490316 0.94295812 0.94119851 0.93369813 0.94555088 0.93221656\n",
            " 0.93323517 0.96249696 0.95379192 0.9698122  0.94490269 0.94286535\n",
            " 0.96731194 0.94184692 0.94360614 0.95138464 0.95573654 0.95286595\n",
            " 0.96694157 0.94110609 0.95231031 0.94610635 0.95925553 0.95990372\n",
            " 0.94082832 0.95592181 0.9698122  0.96203373 0.95619933 0.96999743\n",
            " 0.96527469 0.97249777 0.97268296 0.96425591 0.96258899 0.96786763\n",
            " 0.95916315 0.97249781 0.96805277 0.97157172 0.9717569  0.96555255\n",
            " 0.96092267 0.96008895 0.96481177 0.95555152 0.97166439 0.96814545\n",
            " 0.96870083 0.96129291 0.95305144 0.96805277 0.96860832 0.96101496\n",
            " 0.96342267 0.96231151 0.96663477 0.95975173 0.96759164 0.96675822\n",
            " 0.96052337 0.96644963 0.96719037 0.96762247 0.96944354 0.96734473\n",
            " 0.96737558 0.96913487 0.96928923 0.9715424  0.96910402 0.96996824\n",
            " 0.96996824 0.9710794  0.97120288 0.97040092 0.97123427 0.96906346\n",
            " 0.97005112 0.9702466  0.97121369 0.97121369]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9617221701361099\n",
            "XGBClassifier(base_score=0.75, booster='gbtree', callbacks=None,\n",
            "              colsample_bylevel=None, colsample_bynode=None,\n",
            "              colsample_bytree=None, early_stopping_rounds=None,\n",
            "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
            "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
            "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
            "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
            "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
            "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
            "              predictor=None, random_state=None, ...)\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import RandomizedSearchCV \n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.experimental import enable_halving_search_cv \n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "\n",
        "XGB = xgb.XGBClassifier(objective=\"binary:logistic\")\n",
        "\n",
        "#booster=['gbtree','gblinear']\n",
        "base_score=[0.25,0.5,0.75,1]\n",
        "\n",
        "## Hyper Parameter Optimization\n",
        "max_depth = [2, 3, 5, 10]\n",
        "booster=['gbtree','gblinear']\n",
        "learning_rate=[0.05,0.1,0.15,0.20]\n",
        "min_child_weight=[1,2,3,4]\n",
        "\n",
        "strat_kfold = StratifiedKFold(shuffle=True,random_state = 1)\n",
        "\n",
        "# Define the grid of hyperparameters to search\n",
        "hyperparameter_grid = {\n",
        "    'max_depth':max_depth,\n",
        "    'learning_rate':learning_rate,\n",
        "    'min_child_weight':min_child_weight,\n",
        "    'booster':booster,\n",
        "    'base_score':base_score\n",
        "    }\n",
        "\n",
        "# Set up the random search with 4-fold cross validation\n",
        "halving_cv = HalvingGridSearchCV(estimator=XGB,\n",
        "            param_grid=hyperparameter_grid,\n",
        "            cv=strat_kfold,\n",
        "            scoring = 'accuracy',n_jobs = -1,min_resources=\"exhaust\",\n",
        "            return_train_score = True,\n",
        "            random_state=42)\n",
        "\n",
        "halving_cv.fit(X_train,y_train)\n",
        "\n",
        "print(halving_cv.best_score_)\n",
        "print(halving_cv.best_estimator_)\n",
        "#print(\"Best: %f using %s\" % (gb.best_score_, gb.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "jXbL9_dDU1N-",
        "outputId": "c220c8d5-e750-4f23-e2a8-ac6c08be6b98"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.75, booster='gbtree', callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.75, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.75, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "#gb = halving.fit(X_train,y_train)\n",
        "# # summarize results\n",
        "#print(\"Best: %f using %s\" % (gb.best_score_, gb.best_params_))\n",
        "halving_cv.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6p9kbD14Dyz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c11e5047-8a56-4d6e-a8bc-8ab17c59cdbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97      9131\n",
            "           1       0.97      0.97      0.97      9130\n",
            "\n",
            "    accuracy                           0.97     18261\n",
            "   macro avg       0.97      0.97      0.97     18261\n",
            "weighted avg       0.97      0.97      0.97     18261\n",
            "\n"
          ]
        }
      ],
      "source": [
        "xgb_classifier = xgb.XGBClassifier(base_score=0.75, booster='gbtree', learning_rate=0.15, max_depth=10,\n",
        "              min_child_weight=2, n_estimators=100)\n",
        "xgb_classifier.fit(X_train,y_train)\n",
        "predictions = xgb_classifier.predict(X_test)\n",
        "print (classification_report(y_test,predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hzLzSxMdopY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba09ff6f-263d-4719-dd14-16ccb41b3053"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9663216300452355"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "#balanced_accuracy_score(df['malware'], xg_test['malware'])\n",
        "balanced_accuracy_score(y_test, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3PrsblgdopY"
      },
      "source": [
        "# catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bo4xXhvoOUd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b383f899-f9aa-4a75-d433-8f2d41ba51ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.1.1-cp39-none-manylinux1_x86_64.whl (76.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from catboost) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.9/dist-packages (from catboost) (1.22.4)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.9/dist-packages (from catboost) (1.4.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.9/dist-packages (from catboost) (5.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.9/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.24.0->catboost) (2022.7.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (3.0.9)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (5.12.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (4.39.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (23.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (1.0.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (8.4.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from plotly->catboost) (8.2.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->catboost) (3.15.0)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost\n",
        "from catboost import CatBoostClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPVJ88AqRya_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "49b9db0b-7bd7-4225-f7cf-d62e933d9c3c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-492503d9d4a9>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m                         \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                         random_state=15)\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mGrid_CBC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mGrid_CBC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search_successive_halving.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_samples_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;31m# Set best_score_: BaseSearchCV does not set it, as refit is a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search_successive_halving.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m    376\u001b[0m             }\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m             results = evaluate_candidates(\n\u001b[0m\u001b[1;32m    379\u001b[0m                 \u001b[0mcandidate_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmore_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmore_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "CB = CatBoostClassifier()\n",
        "parameters = {'depth'         : [4,5,6,7,8,9, 10],\n",
        "              'learning_rate' : [0.01,0.02,0.03,0.04],\n",
        "              'iterations'    : [10, 20,30,40,50,60,70,80,90, 100],\n",
        "              'l2_leaf_reg'   : [1, 3, 5, 7, 9],\n",
        "            }\n",
        "\n",
        "Grid_CBC = HalvingGridSearchCV(estimator= CB ,\n",
        "                        param_grid = parameters,\n",
        "                        scoring = 'accuracy',\n",
        "                        cv = strat_kfold,\n",
        "                        n_jobs=-1,\n",
        "                        random_state=15)\n",
        "Grid_CBC.fit(X_train, y_train)\n",
        "\n",
        "Grid_CBC.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bpe9hg8HCWnV"
      },
      "outputs": [],
      "source": [
        "print(Grid_CBC.best_score_)\n",
        "Grid_CBC.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1-U0PErHEnK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17a71446-749e-466c-f7ea-729ffbbacb4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate set to 0.064369\n",
            "0:\tlearn: 0.6308243\ttotal: 76.3ms\tremaining: 1m 16s\n",
            "1:\tlearn: 0.5810269\ttotal: 103ms\tremaining: 51.3s\n",
            "2:\tlearn: 0.5359098\ttotal: 130ms\tremaining: 43.3s\n",
            "3:\tlearn: 0.5041706\ttotal: 154ms\tremaining: 38.4s\n",
            "4:\tlearn: 0.4756019\ttotal: 182ms\tremaining: 36.3s\n",
            "5:\tlearn: 0.4493463\ttotal: 208ms\tremaining: 34.5s\n",
            "6:\tlearn: 0.4260050\ttotal: 243ms\tremaining: 34.4s\n",
            "7:\tlearn: 0.4047255\ttotal: 274ms\tremaining: 33.9s\n",
            "8:\tlearn: 0.3917571\ttotal: 298ms\tremaining: 32.8s\n",
            "9:\tlearn: 0.3777949\ttotal: 324ms\tremaining: 32.1s\n",
            "10:\tlearn: 0.3623220\ttotal: 352ms\tremaining: 31.6s\n",
            "11:\tlearn: 0.3529262\ttotal: 376ms\tremaining: 30.9s\n",
            "12:\tlearn: 0.3410026\ttotal: 407ms\tremaining: 30.9s\n",
            "13:\tlearn: 0.3259005\ttotal: 435ms\tremaining: 30.6s\n",
            "14:\tlearn: 0.3174242\ttotal: 462ms\tremaining: 30.3s\n",
            "15:\tlearn: 0.3094217\ttotal: 490ms\tremaining: 30.1s\n",
            "16:\tlearn: 0.3037917\ttotal: 519ms\tremaining: 30s\n",
            "17:\tlearn: 0.2985157\ttotal: 543ms\tremaining: 29.6s\n",
            "18:\tlearn: 0.2930401\ttotal: 569ms\tremaining: 29.4s\n",
            "19:\tlearn: 0.2893123\ttotal: 593ms\tremaining: 29.1s\n",
            "20:\tlearn: 0.2825008\ttotal: 622ms\tremaining: 29s\n",
            "21:\tlearn: 0.2772673\ttotal: 648ms\tremaining: 28.8s\n",
            "22:\tlearn: 0.2728489\ttotal: 672ms\tremaining: 28.5s\n",
            "23:\tlearn: 0.2672581\ttotal: 699ms\tremaining: 28.4s\n",
            "24:\tlearn: 0.2631091\ttotal: 722ms\tremaining: 28.1s\n",
            "25:\tlearn: 0.2606566\ttotal: 746ms\tremaining: 28s\n",
            "26:\tlearn: 0.2569403\ttotal: 777ms\tremaining: 28s\n",
            "27:\tlearn: 0.2544809\ttotal: 801ms\tremaining: 27.8s\n",
            "28:\tlearn: 0.2528401\ttotal: 827ms\tremaining: 27.7s\n",
            "29:\tlearn: 0.2508019\ttotal: 853ms\tremaining: 27.6s\n",
            "30:\tlearn: 0.2471088\ttotal: 883ms\tremaining: 27.6s\n",
            "31:\tlearn: 0.2431015\ttotal: 912ms\tremaining: 27.6s\n",
            "32:\tlearn: 0.2400737\ttotal: 943ms\tremaining: 27.6s\n",
            "33:\tlearn: 0.2379355\ttotal: 968ms\tremaining: 27.5s\n",
            "34:\tlearn: 0.2363443\ttotal: 994ms\tremaining: 27.4s\n",
            "35:\tlearn: 0.2339436\ttotal: 1.02s\tremaining: 27.3s\n",
            "36:\tlearn: 0.2322040\ttotal: 1.05s\tremaining: 27.2s\n",
            "37:\tlearn: 0.2300809\ttotal: 1.07s\tremaining: 27.1s\n",
            "38:\tlearn: 0.2284834\ttotal: 1.09s\tremaining: 27s\n",
            "39:\tlearn: 0.2267090\ttotal: 1.12s\tremaining: 26.9s\n",
            "40:\tlearn: 0.2250963\ttotal: 1.14s\tremaining: 26.7s\n",
            "41:\tlearn: 0.2230742\ttotal: 1.17s\tremaining: 26.6s\n",
            "42:\tlearn: 0.2215806\ttotal: 1.19s\tremaining: 26.5s\n",
            "43:\tlearn: 0.2206552\ttotal: 1.21s\tremaining: 26.4s\n",
            "44:\tlearn: 0.2191503\ttotal: 1.25s\tremaining: 26.5s\n",
            "45:\tlearn: 0.2178832\ttotal: 1.27s\tremaining: 26.5s\n",
            "46:\tlearn: 0.2142105\ttotal: 1.3s\tremaining: 26.5s\n",
            "47:\tlearn: 0.2131240\ttotal: 1.33s\tremaining: 26.3s\n",
            "48:\tlearn: 0.2112525\ttotal: 1.35s\tremaining: 26.3s\n",
            "49:\tlearn: 0.2099112\ttotal: 1.38s\tremaining: 26.2s\n",
            "50:\tlearn: 0.2089078\ttotal: 1.4s\tremaining: 26.1s\n",
            "51:\tlearn: 0.2073195\ttotal: 1.44s\tremaining: 26.2s\n",
            "52:\tlearn: 0.2063349\ttotal: 1.46s\tremaining: 26.2s\n",
            "53:\tlearn: 0.2055148\ttotal: 1.49s\tremaining: 26.1s\n",
            "54:\tlearn: 0.2046830\ttotal: 1.51s\tremaining: 26s\n",
            "55:\tlearn: 0.2035522\ttotal: 1.54s\tremaining: 25.9s\n",
            "56:\tlearn: 0.2023226\ttotal: 1.56s\tremaining: 25.8s\n",
            "57:\tlearn: 0.2014904\ttotal: 1.58s\tremaining: 25.7s\n",
            "58:\tlearn: 0.1995138\ttotal: 1.61s\tremaining: 25.7s\n",
            "59:\tlearn: 0.1984219\ttotal: 1.64s\tremaining: 25.6s\n",
            "60:\tlearn: 0.1975810\ttotal: 1.66s\tremaining: 25.5s\n",
            "61:\tlearn: 0.1962446\ttotal: 1.69s\tremaining: 25.5s\n",
            "62:\tlearn: 0.1951121\ttotal: 1.71s\tremaining: 25.5s\n",
            "63:\tlearn: 0.1942205\ttotal: 1.74s\tremaining: 25.4s\n",
            "64:\tlearn: 0.1930494\ttotal: 1.76s\tremaining: 25.3s\n",
            "65:\tlearn: 0.1924235\ttotal: 1.78s\tremaining: 25.2s\n",
            "66:\tlearn: 0.1918245\ttotal: 1.81s\tremaining: 25.2s\n",
            "67:\tlearn: 0.1910944\ttotal: 1.83s\tremaining: 25.1s\n",
            "68:\tlearn: 0.1903306\ttotal: 1.86s\tremaining: 25.1s\n",
            "69:\tlearn: 0.1895534\ttotal: 1.88s\tremaining: 25s\n",
            "70:\tlearn: 0.1887794\ttotal: 1.91s\tremaining: 25s\n",
            "71:\tlearn: 0.1881267\ttotal: 1.93s\tremaining: 24.9s\n",
            "72:\tlearn: 0.1874729\ttotal: 1.96s\tremaining: 24.9s\n",
            "73:\tlearn: 0.1870981\ttotal: 1.98s\tremaining: 24.8s\n",
            "74:\tlearn: 0.1863095\ttotal: 2.01s\tremaining: 24.8s\n",
            "75:\tlearn: 0.1852464\ttotal: 2.03s\tremaining: 24.7s\n",
            "76:\tlearn: 0.1844487\ttotal: 2.06s\tremaining: 24.6s\n",
            "77:\tlearn: 0.1836214\ttotal: 2.08s\tremaining: 24.6s\n",
            "78:\tlearn: 0.1822349\ttotal: 2.12s\tremaining: 24.7s\n",
            "79:\tlearn: 0.1813160\ttotal: 2.14s\tremaining: 24.6s\n",
            "80:\tlearn: 0.1808184\ttotal: 2.16s\tremaining: 24.6s\n",
            "81:\tlearn: 0.1802554\ttotal: 2.19s\tremaining: 24.5s\n",
            "82:\tlearn: 0.1796895\ttotal: 2.21s\tremaining: 24.4s\n",
            "83:\tlearn: 0.1790461\ttotal: 2.24s\tremaining: 24.4s\n",
            "84:\tlearn: 0.1783616\ttotal: 2.28s\tremaining: 24.5s\n",
            "85:\tlearn: 0.1771056\ttotal: 2.3s\tremaining: 24.5s\n",
            "86:\tlearn: 0.1763615\ttotal: 2.33s\tremaining: 24.5s\n",
            "87:\tlearn: 0.1756077\ttotal: 2.36s\tremaining: 24.4s\n",
            "88:\tlearn: 0.1747477\ttotal: 2.38s\tremaining: 24.4s\n",
            "89:\tlearn: 0.1739877\ttotal: 2.41s\tremaining: 24.4s\n",
            "90:\tlearn: 0.1734722\ttotal: 2.43s\tremaining: 24.3s\n",
            "91:\tlearn: 0.1730094\ttotal: 2.45s\tremaining: 24.2s\n",
            "92:\tlearn: 0.1722908\ttotal: 2.48s\tremaining: 24.2s\n",
            "93:\tlearn: 0.1714295\ttotal: 2.51s\tremaining: 24.2s\n",
            "94:\tlearn: 0.1708905\ttotal: 2.53s\tremaining: 24.1s\n",
            "95:\tlearn: 0.1702454\ttotal: 2.56s\tremaining: 24.1s\n",
            "96:\tlearn: 0.1696845\ttotal: 2.58s\tremaining: 24.1s\n",
            "97:\tlearn: 0.1690486\ttotal: 2.61s\tremaining: 24s\n",
            "98:\tlearn: 0.1687117\ttotal: 2.63s\tremaining: 24s\n",
            "99:\tlearn: 0.1679678\ttotal: 2.66s\tremaining: 23.9s\n",
            "100:\tlearn: 0.1674358\ttotal: 2.68s\tremaining: 23.9s\n",
            "101:\tlearn: 0.1670843\ttotal: 2.71s\tremaining: 23.8s\n",
            "102:\tlearn: 0.1665049\ttotal: 2.73s\tremaining: 23.8s\n",
            "103:\tlearn: 0.1660995\ttotal: 2.78s\tremaining: 23.9s\n",
            "104:\tlearn: 0.1657240\ttotal: 2.8s\tremaining: 23.9s\n",
            "105:\tlearn: 0.1653317\ttotal: 2.83s\tremaining: 23.8s\n",
            "106:\tlearn: 0.1648201\ttotal: 2.85s\tremaining: 23.8s\n",
            "107:\tlearn: 0.1644654\ttotal: 2.88s\tremaining: 23.8s\n",
            "108:\tlearn: 0.1640591\ttotal: 2.9s\tremaining: 23.7s\n",
            "109:\tlearn: 0.1635176\ttotal: 2.92s\tremaining: 23.7s\n",
            "110:\tlearn: 0.1628331\ttotal: 2.95s\tremaining: 23.6s\n",
            "111:\tlearn: 0.1621855\ttotal: 2.98s\tremaining: 23.6s\n",
            "112:\tlearn: 0.1617860\ttotal: 3.01s\tremaining: 23.6s\n",
            "113:\tlearn: 0.1611618\ttotal: 3.04s\tremaining: 23.6s\n",
            "114:\tlearn: 0.1605504\ttotal: 3.06s\tremaining: 23.6s\n",
            "115:\tlearn: 0.1601728\ttotal: 3.09s\tremaining: 23.5s\n",
            "116:\tlearn: 0.1595818\ttotal: 3.11s\tremaining: 23.5s\n",
            "117:\tlearn: 0.1590333\ttotal: 3.14s\tremaining: 23.5s\n",
            "118:\tlearn: 0.1586786\ttotal: 3.16s\tremaining: 23.4s\n",
            "119:\tlearn: 0.1583479\ttotal: 3.19s\tremaining: 23.4s\n",
            "120:\tlearn: 0.1579593\ttotal: 3.21s\tremaining: 23.3s\n",
            "121:\tlearn: 0.1572960\ttotal: 3.24s\tremaining: 23.3s\n",
            "122:\tlearn: 0.1568890\ttotal: 3.27s\tremaining: 23.3s\n",
            "123:\tlearn: 0.1565062\ttotal: 3.29s\tremaining: 23.3s\n",
            "124:\tlearn: 0.1559982\ttotal: 3.32s\tremaining: 23.2s\n",
            "125:\tlearn: 0.1556512\ttotal: 3.34s\tremaining: 23.2s\n",
            "126:\tlearn: 0.1551454\ttotal: 3.37s\tremaining: 23.2s\n",
            "127:\tlearn: 0.1547286\ttotal: 3.4s\tremaining: 23.1s\n",
            "128:\tlearn: 0.1541535\ttotal: 3.42s\tremaining: 23.1s\n",
            "129:\tlearn: 0.1536184\ttotal: 3.45s\tremaining: 23.1s\n",
            "130:\tlearn: 0.1533175\ttotal: 3.47s\tremaining: 23s\n",
            "131:\tlearn: 0.1529587\ttotal: 3.5s\tremaining: 23s\n",
            "132:\tlearn: 0.1527418\ttotal: 3.52s\tremaining: 22.9s\n",
            "133:\tlearn: 0.1525583\ttotal: 3.54s\tremaining: 22.9s\n",
            "134:\tlearn: 0.1522289\ttotal: 3.57s\tremaining: 22.8s\n",
            "135:\tlearn: 0.1518769\ttotal: 3.59s\tremaining: 22.8s\n",
            "136:\tlearn: 0.1516126\ttotal: 3.62s\tremaining: 22.8s\n",
            "137:\tlearn: 0.1513166\ttotal: 3.65s\tremaining: 22.8s\n",
            "138:\tlearn: 0.1507851\ttotal: 3.67s\tremaining: 22.7s\n",
            "139:\tlearn: 0.1504192\ttotal: 3.7s\tremaining: 22.7s\n",
            "140:\tlearn: 0.1501193\ttotal: 3.72s\tremaining: 22.7s\n",
            "141:\tlearn: 0.1496028\ttotal: 3.75s\tremaining: 22.6s\n",
            "142:\tlearn: 0.1491685\ttotal: 3.77s\tremaining: 22.6s\n",
            "143:\tlearn: 0.1490154\ttotal: 3.79s\tremaining: 22.6s\n",
            "144:\tlearn: 0.1487202\ttotal: 3.82s\tremaining: 22.5s\n",
            "145:\tlearn: 0.1484471\ttotal: 3.85s\tremaining: 22.5s\n",
            "146:\tlearn: 0.1480068\ttotal: 3.88s\tremaining: 22.5s\n",
            "147:\tlearn: 0.1472951\ttotal: 3.91s\tremaining: 22.5s\n",
            "148:\tlearn: 0.1469031\ttotal: 3.93s\tremaining: 22.5s\n",
            "149:\tlearn: 0.1464621\ttotal: 3.96s\tremaining: 22.4s\n",
            "150:\tlearn: 0.1461867\ttotal: 3.98s\tremaining: 22.4s\n",
            "151:\tlearn: 0.1459746\ttotal: 4.01s\tremaining: 22.4s\n",
            "152:\tlearn: 0.1456772\ttotal: 4.04s\tremaining: 22.3s\n",
            "153:\tlearn: 0.1454506\ttotal: 4.06s\tremaining: 22.3s\n",
            "154:\tlearn: 0.1451348\ttotal: 4.09s\tremaining: 22.3s\n",
            "155:\tlearn: 0.1448361\ttotal: 4.11s\tremaining: 22.2s\n",
            "156:\tlearn: 0.1443087\ttotal: 4.14s\tremaining: 22.2s\n",
            "157:\tlearn: 0.1439481\ttotal: 4.16s\tremaining: 22.2s\n",
            "158:\tlearn: 0.1435649\ttotal: 4.19s\tremaining: 22.2s\n",
            "159:\tlearn: 0.1432628\ttotal: 4.22s\tremaining: 22.2s\n",
            "160:\tlearn: 0.1431067\ttotal: 4.24s\tremaining: 22.1s\n",
            "161:\tlearn: 0.1427120\ttotal: 4.28s\tremaining: 22.2s\n",
            "162:\tlearn: 0.1425419\ttotal: 4.31s\tremaining: 22.1s\n",
            "163:\tlearn: 0.1423253\ttotal: 4.33s\tremaining: 22.1s\n",
            "164:\tlearn: 0.1422021\ttotal: 4.35s\tremaining: 22s\n",
            "165:\tlearn: 0.1419004\ttotal: 4.38s\tremaining: 22s\n",
            "166:\tlearn: 0.1415705\ttotal: 4.4s\tremaining: 22s\n",
            "167:\tlearn: 0.1413265\ttotal: 4.43s\tremaining: 21.9s\n",
            "168:\tlearn: 0.1411146\ttotal: 4.45s\tremaining: 21.9s\n",
            "169:\tlearn: 0.1409094\ttotal: 4.48s\tremaining: 21.9s\n",
            "170:\tlearn: 0.1407642\ttotal: 4.5s\tremaining: 21.8s\n",
            "171:\tlearn: 0.1404198\ttotal: 4.53s\tremaining: 21.8s\n",
            "172:\tlearn: 0.1401437\ttotal: 4.55s\tremaining: 21.8s\n",
            "173:\tlearn: 0.1398067\ttotal: 4.58s\tremaining: 21.7s\n",
            "174:\tlearn: 0.1395118\ttotal: 4.6s\tremaining: 21.7s\n",
            "175:\tlearn: 0.1392141\ttotal: 4.63s\tremaining: 21.7s\n",
            "176:\tlearn: 0.1388552\ttotal: 4.66s\tremaining: 21.7s\n",
            "177:\tlearn: 0.1387212\ttotal: 4.68s\tremaining: 21.6s\n",
            "178:\tlearn: 0.1384614\ttotal: 4.71s\tremaining: 21.6s\n",
            "179:\tlearn: 0.1382389\ttotal: 4.73s\tremaining: 21.6s\n",
            "180:\tlearn: 0.1379931\ttotal: 4.76s\tremaining: 21.5s\n",
            "181:\tlearn: 0.1376534\ttotal: 4.79s\tremaining: 21.5s\n",
            "182:\tlearn: 0.1373900\ttotal: 4.82s\tremaining: 21.5s\n",
            "183:\tlearn: 0.1372022\ttotal: 4.84s\tremaining: 21.5s\n",
            "184:\tlearn: 0.1369957\ttotal: 4.87s\tremaining: 21.5s\n",
            "185:\tlearn: 0.1367533\ttotal: 4.89s\tremaining: 21.4s\n",
            "186:\tlearn: 0.1364568\ttotal: 4.92s\tremaining: 21.4s\n",
            "187:\tlearn: 0.1362098\ttotal: 4.95s\tremaining: 21.4s\n",
            "188:\tlearn: 0.1360392\ttotal: 4.97s\tremaining: 21.3s\n",
            "189:\tlearn: 0.1358715\ttotal: 5s\tremaining: 21.3s\n",
            "190:\tlearn: 0.1356702\ttotal: 5.02s\tremaining: 21.3s\n",
            "191:\tlearn: 0.1353730\ttotal: 5.05s\tremaining: 21.3s\n",
            "192:\tlearn: 0.1350870\ttotal: 5.08s\tremaining: 21.3s\n",
            "193:\tlearn: 0.1347639\ttotal: 5.11s\tremaining: 21.2s\n",
            "194:\tlearn: 0.1344956\ttotal: 5.13s\tremaining: 21.2s\n",
            "195:\tlearn: 0.1342636\ttotal: 5.16s\tremaining: 21.2s\n",
            "196:\tlearn: 0.1340222\ttotal: 5.18s\tremaining: 21.1s\n",
            "197:\tlearn: 0.1338236\ttotal: 5.21s\tremaining: 21.1s\n",
            "198:\tlearn: 0.1335225\ttotal: 5.24s\tremaining: 21.1s\n",
            "199:\tlearn: 0.1333584\ttotal: 5.27s\tremaining: 21.1s\n",
            "200:\tlearn: 0.1331061\ttotal: 5.3s\tremaining: 21.1s\n",
            "201:\tlearn: 0.1329759\ttotal: 5.32s\tremaining: 21s\n",
            "202:\tlearn: 0.1328488\ttotal: 5.34s\tremaining: 21s\n",
            "203:\tlearn: 0.1326205\ttotal: 5.37s\tremaining: 21s\n",
            "204:\tlearn: 0.1324727\ttotal: 5.39s\tremaining: 20.9s\n",
            "205:\tlearn: 0.1322881\ttotal: 5.42s\tremaining: 20.9s\n",
            "206:\tlearn: 0.1320744\ttotal: 5.45s\tremaining: 20.9s\n",
            "207:\tlearn: 0.1318404\ttotal: 5.47s\tremaining: 20.8s\n",
            "208:\tlearn: 0.1317054\ttotal: 5.5s\tremaining: 20.8s\n",
            "209:\tlearn: 0.1315044\ttotal: 5.52s\tremaining: 20.8s\n",
            "210:\tlearn: 0.1313361\ttotal: 5.55s\tremaining: 20.7s\n",
            "211:\tlearn: 0.1311131\ttotal: 5.57s\tremaining: 20.7s\n",
            "212:\tlearn: 0.1309381\ttotal: 5.59s\tremaining: 20.7s\n",
            "213:\tlearn: 0.1307193\ttotal: 5.62s\tremaining: 20.6s\n",
            "214:\tlearn: 0.1305870\ttotal: 5.64s\tremaining: 20.6s\n",
            "215:\tlearn: 0.1303221\ttotal: 5.67s\tremaining: 20.6s\n",
            "216:\tlearn: 0.1300960\ttotal: 5.7s\tremaining: 20.6s\n",
            "217:\tlearn: 0.1298749\ttotal: 5.72s\tremaining: 20.5s\n",
            "218:\tlearn: 0.1295849\ttotal: 5.75s\tremaining: 20.5s\n",
            "219:\tlearn: 0.1293942\ttotal: 5.78s\tremaining: 20.5s\n",
            "220:\tlearn: 0.1292283\ttotal: 5.8s\tremaining: 20.4s\n",
            "221:\tlearn: 0.1290803\ttotal: 5.82s\tremaining: 20.4s\n",
            "222:\tlearn: 0.1287661\ttotal: 5.85s\tremaining: 20.4s\n",
            "223:\tlearn: 0.1285332\ttotal: 5.88s\tremaining: 20.4s\n",
            "224:\tlearn: 0.1282867\ttotal: 5.92s\tremaining: 20.4s\n",
            "225:\tlearn: 0.1280709\ttotal: 5.94s\tremaining: 20.4s\n",
            "226:\tlearn: 0.1279218\ttotal: 5.97s\tremaining: 20.3s\n",
            "227:\tlearn: 0.1277684\ttotal: 6s\tremaining: 20.3s\n",
            "228:\tlearn: 0.1275794\ttotal: 6.02s\tremaining: 20.3s\n",
            "229:\tlearn: 0.1273380\ttotal: 6.05s\tremaining: 20.2s\n",
            "230:\tlearn: 0.1271879\ttotal: 6.07s\tremaining: 20.2s\n",
            "231:\tlearn: 0.1270300\ttotal: 6.1s\tremaining: 20.2s\n",
            "232:\tlearn: 0.1268920\ttotal: 6.13s\tremaining: 20.2s\n",
            "233:\tlearn: 0.1266518\ttotal: 6.15s\tremaining: 20.1s\n",
            "234:\tlearn: 0.1264823\ttotal: 6.18s\tremaining: 20.1s\n",
            "235:\tlearn: 0.1263746\ttotal: 6.2s\tremaining: 20.1s\n",
            "236:\tlearn: 0.1262372\ttotal: 6.23s\tremaining: 20s\n",
            "237:\tlearn: 0.1260224\ttotal: 6.25s\tremaining: 20s\n",
            "238:\tlearn: 0.1259219\ttotal: 6.29s\tremaining: 20s\n",
            "239:\tlearn: 0.1258201\ttotal: 6.31s\tremaining: 20s\n",
            "240:\tlearn: 0.1256396\ttotal: 6.34s\tremaining: 20s\n",
            "241:\tlearn: 0.1254341\ttotal: 6.37s\tremaining: 19.9s\n",
            "242:\tlearn: 0.1252808\ttotal: 6.39s\tremaining: 19.9s\n",
            "243:\tlearn: 0.1250168\ttotal: 6.42s\tremaining: 19.9s\n",
            "244:\tlearn: 0.1248139\ttotal: 6.44s\tremaining: 19.9s\n",
            "245:\tlearn: 0.1246762\ttotal: 6.47s\tremaining: 19.8s\n",
            "246:\tlearn: 0.1245021\ttotal: 6.49s\tremaining: 19.8s\n",
            "247:\tlearn: 0.1242966\ttotal: 6.52s\tremaining: 19.8s\n",
            "248:\tlearn: 0.1241430\ttotal: 6.55s\tremaining: 19.8s\n",
            "249:\tlearn: 0.1240169\ttotal: 6.57s\tremaining: 19.7s\n",
            "250:\tlearn: 0.1238860\ttotal: 6.6s\tremaining: 19.7s\n",
            "251:\tlearn: 0.1237707\ttotal: 6.62s\tremaining: 19.7s\n",
            "252:\tlearn: 0.1236290\ttotal: 6.65s\tremaining: 19.6s\n",
            "253:\tlearn: 0.1235103\ttotal: 6.67s\tremaining: 19.6s\n",
            "254:\tlearn: 0.1233036\ttotal: 6.7s\tremaining: 19.6s\n",
            "255:\tlearn: 0.1231555\ttotal: 6.73s\tremaining: 19.6s\n",
            "256:\tlearn: 0.1230102\ttotal: 6.75s\tremaining: 19.5s\n",
            "257:\tlearn: 0.1228366\ttotal: 6.78s\tremaining: 19.5s\n",
            "258:\tlearn: 0.1226642\ttotal: 6.8s\tremaining: 19.5s\n",
            "259:\tlearn: 0.1225379\ttotal: 6.83s\tremaining: 19.4s\n",
            "260:\tlearn: 0.1224245\ttotal: 6.86s\tremaining: 19.4s\n",
            "261:\tlearn: 0.1223148\ttotal: 6.88s\tremaining: 19.4s\n",
            "262:\tlearn: 0.1220304\ttotal: 6.91s\tremaining: 19.4s\n",
            "263:\tlearn: 0.1219363\ttotal: 6.93s\tremaining: 19.3s\n",
            "264:\tlearn: 0.1218361\ttotal: 6.96s\tremaining: 19.3s\n",
            "265:\tlearn: 0.1217534\ttotal: 6.99s\tremaining: 19.3s\n",
            "266:\tlearn: 0.1216613\ttotal: 7.01s\tremaining: 19.2s\n",
            "267:\tlearn: 0.1215410\ttotal: 7.03s\tremaining: 19.2s\n",
            "268:\tlearn: 0.1214099\ttotal: 7.06s\tremaining: 19.2s\n",
            "269:\tlearn: 0.1212763\ttotal: 7.08s\tremaining: 19.1s\n",
            "270:\tlearn: 0.1211794\ttotal: 7.1s\tremaining: 19.1s\n",
            "271:\tlearn: 0.1210452\ttotal: 7.13s\tremaining: 19.1s\n",
            "272:\tlearn: 0.1209086\ttotal: 7.16s\tremaining: 19.1s\n",
            "273:\tlearn: 0.1207987\ttotal: 7.19s\tremaining: 19s\n",
            "274:\tlearn: 0.1206603\ttotal: 7.21s\tremaining: 19s\n",
            "275:\tlearn: 0.1205658\ttotal: 7.23s\tremaining: 19s\n",
            "276:\tlearn: 0.1204617\ttotal: 7.26s\tremaining: 19s\n",
            "277:\tlearn: 0.1202957\ttotal: 7.3s\tremaining: 19s\n",
            "278:\tlearn: 0.1202046\ttotal: 7.33s\tremaining: 18.9s\n",
            "279:\tlearn: 0.1201048\ttotal: 7.35s\tremaining: 18.9s\n",
            "280:\tlearn: 0.1200289\ttotal: 7.38s\tremaining: 18.9s\n",
            "281:\tlearn: 0.1198869\ttotal: 7.41s\tremaining: 18.9s\n",
            "282:\tlearn: 0.1197341\ttotal: 7.43s\tremaining: 18.8s\n",
            "283:\tlearn: 0.1195633\ttotal: 7.46s\tremaining: 18.8s\n",
            "284:\tlearn: 0.1194097\ttotal: 7.49s\tremaining: 18.8s\n",
            "285:\tlearn: 0.1192962\ttotal: 7.51s\tremaining: 18.8s\n",
            "286:\tlearn: 0.1191979\ttotal: 7.54s\tremaining: 18.7s\n",
            "287:\tlearn: 0.1190459\ttotal: 7.56s\tremaining: 18.7s\n",
            "288:\tlearn: 0.1188566\ttotal: 7.6s\tremaining: 18.7s\n",
            "289:\tlearn: 0.1187085\ttotal: 7.62s\tremaining: 18.7s\n",
            "290:\tlearn: 0.1185268\ttotal: 7.65s\tremaining: 18.6s\n",
            "291:\tlearn: 0.1184264\ttotal: 7.68s\tremaining: 18.6s\n",
            "292:\tlearn: 0.1181764\ttotal: 7.7s\tremaining: 18.6s\n",
            "293:\tlearn: 0.1180696\ttotal: 7.73s\tremaining: 18.6s\n",
            "294:\tlearn: 0.1179258\ttotal: 7.77s\tremaining: 18.6s\n",
            "295:\tlearn: 0.1178420\ttotal: 7.8s\tremaining: 18.5s\n",
            "296:\tlearn: 0.1177394\ttotal: 7.82s\tremaining: 18.5s\n",
            "297:\tlearn: 0.1176486\ttotal: 7.85s\tremaining: 18.5s\n",
            "298:\tlearn: 0.1175634\ttotal: 7.88s\tremaining: 18.5s\n",
            "299:\tlearn: 0.1173526\ttotal: 7.9s\tremaining: 18.4s\n",
            "300:\tlearn: 0.1172941\ttotal: 7.93s\tremaining: 18.4s\n",
            "301:\tlearn: 0.1172295\ttotal: 7.95s\tremaining: 18.4s\n",
            "302:\tlearn: 0.1171606\ttotal: 7.97s\tremaining: 18.3s\n",
            "303:\tlearn: 0.1170585\ttotal: 8.01s\tremaining: 18.3s\n",
            "304:\tlearn: 0.1169446\ttotal: 8.03s\tremaining: 18.3s\n",
            "305:\tlearn: 0.1168064\ttotal: 8.06s\tremaining: 18.3s\n",
            "306:\tlearn: 0.1166580\ttotal: 8.08s\tremaining: 18.2s\n",
            "307:\tlearn: 0.1165858\ttotal: 8.11s\tremaining: 18.2s\n",
            "308:\tlearn: 0.1165089\ttotal: 8.13s\tremaining: 18.2s\n",
            "309:\tlearn: 0.1164220\ttotal: 8.15s\tremaining: 18.1s\n",
            "310:\tlearn: 0.1163536\ttotal: 8.18s\tremaining: 18.1s\n",
            "311:\tlearn: 0.1162526\ttotal: 8.2s\tremaining: 18.1s\n",
            "312:\tlearn: 0.1161652\ttotal: 8.23s\tremaining: 18.1s\n",
            "313:\tlearn: 0.1161154\ttotal: 8.25s\tremaining: 18s\n",
            "314:\tlearn: 0.1160322\ttotal: 8.29s\tremaining: 18s\n",
            "315:\tlearn: 0.1159599\ttotal: 8.31s\tremaining: 18s\n",
            "316:\tlearn: 0.1158291\ttotal: 8.33s\tremaining: 18s\n",
            "317:\tlearn: 0.1156857\ttotal: 8.36s\tremaining: 17.9s\n",
            "318:\tlearn: 0.1155139\ttotal: 8.38s\tremaining: 17.9s\n",
            "319:\tlearn: 0.1154229\ttotal: 8.41s\tremaining: 17.9s\n",
            "320:\tlearn: 0.1151955\ttotal: 8.44s\tremaining: 17.9s\n",
            "321:\tlearn: 0.1151189\ttotal: 8.46s\tremaining: 17.8s\n",
            "322:\tlearn: 0.1150262\ttotal: 8.49s\tremaining: 17.8s\n",
            "323:\tlearn: 0.1149309\ttotal: 8.52s\tremaining: 17.8s\n",
            "324:\tlearn: 0.1148482\ttotal: 8.55s\tremaining: 17.8s\n",
            "325:\tlearn: 0.1147198\ttotal: 8.57s\tremaining: 17.7s\n",
            "326:\tlearn: 0.1146416\ttotal: 8.6s\tremaining: 17.7s\n",
            "327:\tlearn: 0.1144898\ttotal: 8.62s\tremaining: 17.7s\n",
            "328:\tlearn: 0.1142943\ttotal: 8.65s\tremaining: 17.6s\n",
            "329:\tlearn: 0.1141670\ttotal: 8.67s\tremaining: 17.6s\n",
            "330:\tlearn: 0.1140273\ttotal: 8.7s\tremaining: 17.6s\n",
            "331:\tlearn: 0.1137884\ttotal: 8.73s\tremaining: 17.6s\n",
            "332:\tlearn: 0.1137378\ttotal: 8.76s\tremaining: 17.5s\n",
            "333:\tlearn: 0.1135370\ttotal: 8.78s\tremaining: 17.5s\n",
            "334:\tlearn: 0.1133715\ttotal: 8.81s\tremaining: 17.5s\n",
            "335:\tlearn: 0.1132065\ttotal: 8.85s\tremaining: 17.5s\n",
            "336:\tlearn: 0.1130808\ttotal: 8.87s\tremaining: 17.4s\n",
            "337:\tlearn: 0.1129604\ttotal: 8.89s\tremaining: 17.4s\n",
            "338:\tlearn: 0.1128602\ttotal: 8.93s\tremaining: 17.4s\n",
            "339:\tlearn: 0.1127081\ttotal: 8.95s\tremaining: 17.4s\n",
            "340:\tlearn: 0.1125632\ttotal: 8.98s\tremaining: 17.3s\n",
            "341:\tlearn: 0.1124605\ttotal: 9s\tremaining: 17.3s\n",
            "342:\tlearn: 0.1123710\ttotal: 9.03s\tremaining: 17.3s\n",
            "343:\tlearn: 0.1122815\ttotal: 9.05s\tremaining: 17.3s\n",
            "344:\tlearn: 0.1121811\ttotal: 9.08s\tremaining: 17.2s\n",
            "345:\tlearn: 0.1120987\ttotal: 9.1s\tremaining: 17.2s\n",
            "346:\tlearn: 0.1120468\ttotal: 9.13s\tremaining: 17.2s\n",
            "347:\tlearn: 0.1120025\ttotal: 9.16s\tremaining: 17.2s\n",
            "348:\tlearn: 0.1119439\ttotal: 9.18s\tremaining: 17.1s\n",
            "349:\tlearn: 0.1119131\ttotal: 9.21s\tremaining: 17.1s\n",
            "350:\tlearn: 0.1118467\ttotal: 9.24s\tremaining: 17.1s\n",
            "351:\tlearn: 0.1116387\ttotal: 9.27s\tremaining: 17.1s\n",
            "352:\tlearn: 0.1115615\ttotal: 9.3s\tremaining: 17s\n",
            "353:\tlearn: 0.1114672\ttotal: 9.32s\tremaining: 17s\n",
            "354:\tlearn: 0.1113590\ttotal: 9.35s\tremaining: 17s\n",
            "355:\tlearn: 0.1112708\ttotal: 9.38s\tremaining: 17s\n",
            "356:\tlearn: 0.1111287\ttotal: 9.4s\tremaining: 16.9s\n",
            "357:\tlearn: 0.1110661\ttotal: 9.43s\tremaining: 16.9s\n",
            "358:\tlearn: 0.1109987\ttotal: 9.45s\tremaining: 16.9s\n",
            "359:\tlearn: 0.1109015\ttotal: 9.48s\tremaining: 16.8s\n",
            "360:\tlearn: 0.1108321\ttotal: 9.5s\tremaining: 16.8s\n",
            "361:\tlearn: 0.1107354\ttotal: 9.54s\tremaining: 16.8s\n",
            "362:\tlearn: 0.1106868\ttotal: 9.6s\tremaining: 16.8s\n",
            "363:\tlearn: 0.1106089\ttotal: 9.67s\tremaining: 16.9s\n",
            "364:\tlearn: 0.1105232\ttotal: 9.73s\tremaining: 16.9s\n",
            "365:\tlearn: 0.1103564\ttotal: 9.79s\tremaining: 17s\n",
            "366:\tlearn: 0.1102785\ttotal: 9.86s\tremaining: 17s\n",
            "367:\tlearn: 0.1102290\ttotal: 9.9s\tremaining: 17s\n",
            "368:\tlearn: 0.1101407\ttotal: 9.96s\tremaining: 17s\n",
            "369:\tlearn: 0.1100105\ttotal: 10s\tremaining: 17.1s\n",
            "370:\tlearn: 0.1099377\ttotal: 10.1s\tremaining: 17.1s\n",
            "371:\tlearn: 0.1098562\ttotal: 10.1s\tremaining: 17.1s\n",
            "372:\tlearn: 0.1097839\ttotal: 10.2s\tremaining: 17.1s\n",
            "373:\tlearn: 0.1096986\ttotal: 10.3s\tremaining: 17.2s\n",
            "374:\tlearn: 0.1095867\ttotal: 10.3s\tremaining: 17.2s\n",
            "375:\tlearn: 0.1094062\ttotal: 10.4s\tremaining: 17.2s\n",
            "376:\tlearn: 0.1092907\ttotal: 10.5s\tremaining: 17.3s\n",
            "377:\tlearn: 0.1092059\ttotal: 10.5s\tremaining: 17.3s\n",
            "378:\tlearn: 0.1091637\ttotal: 10.6s\tremaining: 17.3s\n",
            "379:\tlearn: 0.1090573\ttotal: 10.6s\tremaining: 17.4s\n",
            "380:\tlearn: 0.1089937\ttotal: 10.7s\tremaining: 17.4s\n",
            "381:\tlearn: 0.1089347\ttotal: 10.7s\tremaining: 17.4s\n",
            "382:\tlearn: 0.1088292\ttotal: 10.8s\tremaining: 17.4s\n",
            "383:\tlearn: 0.1086557\ttotal: 10.9s\tremaining: 17.4s\n",
            "384:\tlearn: 0.1084933\ttotal: 10.9s\tremaining: 17.5s\n",
            "385:\tlearn: 0.1084043\ttotal: 11s\tremaining: 17.5s\n",
            "386:\tlearn: 0.1082989\ttotal: 11.1s\tremaining: 17.5s\n",
            "387:\tlearn: 0.1081833\ttotal: 11.1s\tremaining: 17.5s\n",
            "388:\tlearn: 0.1081328\ttotal: 11.1s\tremaining: 17.5s\n",
            "389:\tlearn: 0.1080961\ttotal: 11.2s\tremaining: 17.5s\n",
            "390:\tlearn: 0.1080366\ttotal: 11.2s\tremaining: 17.5s\n",
            "391:\tlearn: 0.1079775\ttotal: 11.3s\tremaining: 17.5s\n",
            "392:\tlearn: 0.1079307\ttotal: 11.4s\tremaining: 17.6s\n",
            "393:\tlearn: 0.1078412\ttotal: 11.4s\tremaining: 17.6s\n",
            "394:\tlearn: 0.1077819\ttotal: 11.5s\tremaining: 17.6s\n",
            "395:\tlearn: 0.1077001\ttotal: 11.6s\tremaining: 17.6s\n",
            "396:\tlearn: 0.1076479\ttotal: 11.6s\tremaining: 17.6s\n",
            "397:\tlearn: 0.1076065\ttotal: 11.7s\tremaining: 17.6s\n",
            "398:\tlearn: 0.1075557\ttotal: 11.7s\tremaining: 17.7s\n",
            "399:\tlearn: 0.1075263\ttotal: 11.8s\tremaining: 17.7s\n",
            "400:\tlearn: 0.1074282\ttotal: 11.9s\tremaining: 17.7s\n",
            "401:\tlearn: 0.1073803\ttotal: 11.9s\tremaining: 17.7s\n",
            "402:\tlearn: 0.1072842\ttotal: 12s\tremaining: 17.8s\n",
            "403:\tlearn: 0.1071829\ttotal: 12s\tremaining: 17.8s\n",
            "404:\tlearn: 0.1071237\ttotal: 12.1s\tremaining: 17.8s\n",
            "405:\tlearn: 0.1070228\ttotal: 12.2s\tremaining: 17.8s\n",
            "406:\tlearn: 0.1068686\ttotal: 12.2s\tremaining: 17.8s\n",
            "407:\tlearn: 0.1067760\ttotal: 12.3s\tremaining: 17.8s\n",
            "408:\tlearn: 0.1067218\ttotal: 12.3s\tremaining: 17.8s\n",
            "409:\tlearn: 0.1066593\ttotal: 12.4s\tremaining: 17.9s\n",
            "410:\tlearn: 0.1065395\ttotal: 12.5s\tremaining: 17.9s\n",
            "411:\tlearn: 0.1064856\ttotal: 12.5s\tremaining: 17.9s\n",
            "412:\tlearn: 0.1063868\ttotal: 12.6s\tremaining: 17.9s\n",
            "413:\tlearn: 0.1062945\ttotal: 12.6s\tremaining: 17.8s\n",
            "414:\tlearn: 0.1061899\ttotal: 12.6s\tremaining: 17.8s\n",
            "415:\tlearn: 0.1061472\ttotal: 12.6s\tremaining: 17.7s\n",
            "416:\tlearn: 0.1060727\ttotal: 12.7s\tremaining: 17.7s\n",
            "417:\tlearn: 0.1059869\ttotal: 12.7s\tremaining: 17.7s\n",
            "418:\tlearn: 0.1059026\ttotal: 12.7s\tremaining: 17.6s\n",
            "419:\tlearn: 0.1058529\ttotal: 12.7s\tremaining: 17.6s\n",
            "420:\tlearn: 0.1058155\ttotal: 12.8s\tremaining: 17.5s\n",
            "421:\tlearn: 0.1057308\ttotal: 12.8s\tremaining: 17.5s\n",
            "422:\tlearn: 0.1056543\ttotal: 12.8s\tremaining: 17.5s\n",
            "423:\tlearn: 0.1055888\ttotal: 12.8s\tremaining: 17.4s\n",
            "424:\tlearn: 0.1055524\ttotal: 12.9s\tremaining: 17.4s\n",
            "425:\tlearn: 0.1054762\ttotal: 12.9s\tremaining: 17.4s\n",
            "426:\tlearn: 0.1054119\ttotal: 12.9s\tremaining: 17.3s\n",
            "427:\tlearn: 0.1053212\ttotal: 12.9s\tremaining: 17.3s\n",
            "428:\tlearn: 0.1052664\ttotal: 13s\tremaining: 17.3s\n",
            "429:\tlearn: 0.1051919\ttotal: 13s\tremaining: 17.2s\n",
            "430:\tlearn: 0.1051444\ttotal: 13s\tremaining: 17.2s\n",
            "431:\tlearn: 0.1050674\ttotal: 13s\tremaining: 17.2s\n",
            "432:\tlearn: 0.1049770\ttotal: 13.1s\tremaining: 17.1s\n",
            "433:\tlearn: 0.1049599\ttotal: 13.1s\tremaining: 17.1s\n",
            "434:\tlearn: 0.1049051\ttotal: 13.1s\tremaining: 17s\n",
            "435:\tlearn: 0.1048419\ttotal: 13.1s\tremaining: 17s\n",
            "436:\tlearn: 0.1047951\ttotal: 13.2s\tremaining: 17s\n",
            "437:\tlearn: 0.1046803\ttotal: 13.2s\tremaining: 16.9s\n",
            "438:\tlearn: 0.1046035\ttotal: 13.2s\tremaining: 16.9s\n",
            "439:\tlearn: 0.1045732\ttotal: 13.3s\tremaining: 16.9s\n",
            "440:\tlearn: 0.1045220\ttotal: 13.3s\tremaining: 16.8s\n",
            "441:\tlearn: 0.1044842\ttotal: 13.3s\tremaining: 16.8s\n",
            "442:\tlearn: 0.1044275\ttotal: 13.3s\tremaining: 16.8s\n",
            "443:\tlearn: 0.1043919\ttotal: 13.4s\tremaining: 16.7s\n",
            "444:\tlearn: 0.1043025\ttotal: 13.4s\tremaining: 16.7s\n",
            "445:\tlearn: 0.1041936\ttotal: 13.4s\tremaining: 16.7s\n",
            "446:\tlearn: 0.1041209\ttotal: 13.4s\tremaining: 16.6s\n",
            "447:\tlearn: 0.1040650\ttotal: 13.5s\tremaining: 16.6s\n",
            "448:\tlearn: 0.1040188\ttotal: 13.5s\tremaining: 16.5s\n",
            "449:\tlearn: 0.1039682\ttotal: 13.5s\tremaining: 16.5s\n",
            "450:\tlearn: 0.1038985\ttotal: 13.5s\tremaining: 16.5s\n",
            "451:\tlearn: 0.1038300\ttotal: 13.6s\tremaining: 16.4s\n",
            "452:\tlearn: 0.1037814\ttotal: 13.6s\tremaining: 16.4s\n",
            "453:\tlearn: 0.1037014\ttotal: 13.6s\tremaining: 16.4s\n",
            "454:\tlearn: 0.1036596\ttotal: 13.6s\tremaining: 16.3s\n",
            "455:\tlearn: 0.1036269\ttotal: 13.7s\tremaining: 16.3s\n",
            "456:\tlearn: 0.1035005\ttotal: 13.7s\tremaining: 16.3s\n",
            "457:\tlearn: 0.1034655\ttotal: 13.7s\tremaining: 16.2s\n",
            "458:\tlearn: 0.1033900\ttotal: 13.8s\tremaining: 16.2s\n",
            "459:\tlearn: 0.1033256\ttotal: 13.8s\tremaining: 16.2s\n",
            "460:\tlearn: 0.1032756\ttotal: 13.8s\tremaining: 16.1s\n",
            "461:\tlearn: 0.1032139\ttotal: 13.8s\tremaining: 16.1s\n",
            "462:\tlearn: 0.1031181\ttotal: 13.9s\tremaining: 16.1s\n",
            "463:\tlearn: 0.1030600\ttotal: 13.9s\tremaining: 16s\n",
            "464:\tlearn: 0.1030260\ttotal: 13.9s\tremaining: 16s\n",
            "465:\tlearn: 0.1029618\ttotal: 13.9s\tremaining: 16s\n",
            "466:\tlearn: 0.1029189\ttotal: 14s\tremaining: 15.9s\n",
            "467:\tlearn: 0.1028660\ttotal: 14s\tremaining: 15.9s\n",
            "468:\tlearn: 0.1028268\ttotal: 14s\tremaining: 15.9s\n",
            "469:\tlearn: 0.1028007\ttotal: 14s\tremaining: 15.8s\n",
            "470:\tlearn: 0.1027542\ttotal: 14.1s\tremaining: 15.8s\n",
            "471:\tlearn: 0.1027305\ttotal: 14.1s\tremaining: 15.7s\n",
            "472:\tlearn: 0.1026606\ttotal: 14.1s\tremaining: 15.7s\n",
            "473:\tlearn: 0.1026180\ttotal: 14.1s\tremaining: 15.7s\n",
            "474:\tlearn: 0.1025765\ttotal: 14.2s\tremaining: 15.6s\n",
            "475:\tlearn: 0.1025573\ttotal: 14.2s\tremaining: 15.6s\n",
            "476:\tlearn: 0.1024999\ttotal: 14.2s\tremaining: 15.6s\n",
            "477:\tlearn: 0.1024385\ttotal: 14.2s\tremaining: 15.5s\n",
            "478:\tlearn: 0.1023999\ttotal: 14.3s\tremaining: 15.5s\n",
            "479:\tlearn: 0.1023518\ttotal: 14.3s\tremaining: 15.5s\n",
            "480:\tlearn: 0.1023160\ttotal: 14.3s\tremaining: 15.4s\n",
            "481:\tlearn: 0.1022639\ttotal: 14.3s\tremaining: 15.4s\n",
            "482:\tlearn: 0.1022096\ttotal: 14.4s\tremaining: 15.4s\n",
            "483:\tlearn: 0.1021702\ttotal: 14.4s\tremaining: 15.3s\n",
            "484:\tlearn: 0.1021069\ttotal: 14.4s\tremaining: 15.3s\n",
            "485:\tlearn: 0.1020424\ttotal: 14.4s\tremaining: 15.3s\n",
            "486:\tlearn: 0.1019950\ttotal: 14.5s\tremaining: 15.2s\n",
            "487:\tlearn: 0.1019722\ttotal: 14.5s\tremaining: 15.2s\n",
            "488:\tlearn: 0.1019320\ttotal: 14.5s\tremaining: 15.2s\n",
            "489:\tlearn: 0.1018924\ttotal: 14.5s\tremaining: 15.1s\n",
            "490:\tlearn: 0.1018514\ttotal: 14.6s\tremaining: 15.1s\n",
            "491:\tlearn: 0.1018135\ttotal: 14.6s\tremaining: 15.1s\n",
            "492:\tlearn: 0.1017532\ttotal: 14.6s\tremaining: 15s\n",
            "493:\tlearn: 0.1017036\ttotal: 14.7s\tremaining: 15s\n",
            "494:\tlearn: 0.1016523\ttotal: 14.7s\tremaining: 15s\n",
            "495:\tlearn: 0.1016124\ttotal: 14.7s\tremaining: 15s\n",
            "496:\tlearn: 0.1015556\ttotal: 14.7s\tremaining: 14.9s\n",
            "497:\tlearn: 0.1015120\ttotal: 14.8s\tremaining: 14.9s\n",
            "498:\tlearn: 0.1014494\ttotal: 14.8s\tremaining: 14.9s\n",
            "499:\tlearn: 0.1014043\ttotal: 14.8s\tremaining: 14.8s\n",
            "500:\tlearn: 0.1013722\ttotal: 14.8s\tremaining: 14.8s\n",
            "501:\tlearn: 0.1013205\ttotal: 14.9s\tremaining: 14.8s\n",
            "502:\tlearn: 0.1012655\ttotal: 14.9s\tremaining: 14.7s\n",
            "503:\tlearn: 0.1012074\ttotal: 14.9s\tremaining: 14.7s\n",
            "504:\tlearn: 0.1011520\ttotal: 14.9s\tremaining: 14.7s\n",
            "505:\tlearn: 0.1010928\ttotal: 15s\tremaining: 14.6s\n",
            "506:\tlearn: 0.1010613\ttotal: 15s\tremaining: 14.6s\n",
            "507:\tlearn: 0.1010241\ttotal: 15s\tremaining: 14.5s\n",
            "508:\tlearn: 0.1009868\ttotal: 15s\tremaining: 14.5s\n",
            "509:\tlearn: 0.1009377\ttotal: 15.1s\tremaining: 14.5s\n",
            "510:\tlearn: 0.1008956\ttotal: 15.1s\tremaining: 14.4s\n",
            "511:\tlearn: 0.1008410\ttotal: 15.1s\tremaining: 14.4s\n",
            "512:\tlearn: 0.1008035\ttotal: 15.1s\tremaining: 14.4s\n",
            "513:\tlearn: 0.1007488\ttotal: 15.2s\tremaining: 14.3s\n",
            "514:\tlearn: 0.1006786\ttotal: 15.2s\tremaining: 14.3s\n",
            "515:\tlearn: 0.1006146\ttotal: 15.2s\tremaining: 14.3s\n",
            "516:\tlearn: 0.1005660\ttotal: 15.3s\tremaining: 14.2s\n",
            "517:\tlearn: 0.1005019\ttotal: 15.3s\tremaining: 14.2s\n",
            "518:\tlearn: 0.1004316\ttotal: 15.3s\tremaining: 14.2s\n",
            "519:\tlearn: 0.1004187\ttotal: 15.3s\tremaining: 14.1s\n",
            "520:\tlearn: 0.1003891\ttotal: 15.4s\tremaining: 14.1s\n",
            "521:\tlearn: 0.1003316\ttotal: 15.4s\tremaining: 14.1s\n",
            "522:\tlearn: 0.1002899\ttotal: 15.4s\tremaining: 14.1s\n",
            "523:\tlearn: 0.1002045\ttotal: 15.4s\tremaining: 14s\n",
            "524:\tlearn: 0.1001335\ttotal: 15.5s\tremaining: 14s\n",
            "525:\tlearn: 0.1000901\ttotal: 15.5s\tremaining: 13.9s\n",
            "526:\tlearn: 0.1000664\ttotal: 15.5s\tremaining: 13.9s\n",
            "527:\tlearn: 0.1000108\ttotal: 15.5s\tremaining: 13.9s\n",
            "528:\tlearn: 0.0999400\ttotal: 15.6s\tremaining: 13.9s\n",
            "529:\tlearn: 0.0999061\ttotal: 15.6s\tremaining: 13.8s\n",
            "530:\tlearn: 0.0998714\ttotal: 15.6s\tremaining: 13.8s\n",
            "531:\tlearn: 0.0998265\ttotal: 15.6s\tremaining: 13.8s\n",
            "532:\tlearn: 0.0997817\ttotal: 15.7s\tremaining: 13.7s\n",
            "533:\tlearn: 0.0997190\ttotal: 15.7s\tremaining: 13.7s\n",
            "534:\tlearn: 0.0997021\ttotal: 15.7s\tremaining: 13.7s\n",
            "535:\tlearn: 0.0996591\ttotal: 15.7s\tremaining: 13.6s\n",
            "536:\tlearn: 0.0996377\ttotal: 15.8s\tremaining: 13.6s\n",
            "537:\tlearn: 0.0995956\ttotal: 15.8s\tremaining: 13.6s\n",
            "538:\tlearn: 0.0995653\ttotal: 15.8s\tremaining: 13.5s\n",
            "539:\tlearn: 0.0995326\ttotal: 15.8s\tremaining: 13.5s\n",
            "540:\tlearn: 0.0994782\ttotal: 15.9s\tremaining: 13.5s\n",
            "541:\tlearn: 0.0994358\ttotal: 15.9s\tremaining: 13.4s\n",
            "542:\tlearn: 0.0993445\ttotal: 15.9s\tremaining: 13.4s\n",
            "543:\tlearn: 0.0992927\ttotal: 15.9s\tremaining: 13.4s\n",
            "544:\tlearn: 0.0992375\ttotal: 16s\tremaining: 13.3s\n",
            "545:\tlearn: 0.0992197\ttotal: 16s\tremaining: 13.3s\n",
            "546:\tlearn: 0.0991225\ttotal: 16s\tremaining: 13.3s\n",
            "547:\tlearn: 0.0990653\ttotal: 16s\tremaining: 13.2s\n",
            "548:\tlearn: 0.0990510\ttotal: 16.1s\tremaining: 13.2s\n",
            "549:\tlearn: 0.0990056\ttotal: 16.1s\tremaining: 13.2s\n",
            "550:\tlearn: 0.0989684\ttotal: 16.1s\tremaining: 13.1s\n",
            "551:\tlearn: 0.0989469\ttotal: 16.1s\tremaining: 13.1s\n",
            "552:\tlearn: 0.0989109\ttotal: 16.2s\tremaining: 13.1s\n",
            "553:\tlearn: 0.0988809\ttotal: 16.2s\tremaining: 13s\n",
            "554:\tlearn: 0.0988620\ttotal: 16.2s\tremaining: 13s\n",
            "555:\tlearn: 0.0988095\ttotal: 16.2s\tremaining: 13s\n",
            "556:\tlearn: 0.0987513\ttotal: 16.3s\tremaining: 12.9s\n",
            "557:\tlearn: 0.0986940\ttotal: 16.3s\tremaining: 12.9s\n",
            "558:\tlearn: 0.0986625\ttotal: 16.3s\tremaining: 12.9s\n",
            "559:\tlearn: 0.0986128\ttotal: 16.4s\tremaining: 12.9s\n",
            "560:\tlearn: 0.0985683\ttotal: 16.4s\tremaining: 12.8s\n",
            "561:\tlearn: 0.0985285\ttotal: 16.4s\tremaining: 12.8s\n",
            "562:\tlearn: 0.0984688\ttotal: 16.4s\tremaining: 12.8s\n",
            "563:\tlearn: 0.0984364\ttotal: 16.5s\tremaining: 12.7s\n",
            "564:\tlearn: 0.0983716\ttotal: 16.5s\tremaining: 12.7s\n",
            "565:\tlearn: 0.0983367\ttotal: 16.5s\tremaining: 12.7s\n",
            "566:\tlearn: 0.0982342\ttotal: 16.5s\tremaining: 12.6s\n",
            "567:\tlearn: 0.0982199\ttotal: 16.6s\tremaining: 12.6s\n",
            "568:\tlearn: 0.0981846\ttotal: 16.6s\tremaining: 12.6s\n",
            "569:\tlearn: 0.0981752\ttotal: 16.6s\tremaining: 12.5s\n",
            "570:\tlearn: 0.0981415\ttotal: 16.6s\tremaining: 12.5s\n",
            "571:\tlearn: 0.0981033\ttotal: 16.7s\tremaining: 12.5s\n",
            "572:\tlearn: 0.0980186\ttotal: 16.7s\tremaining: 12.4s\n",
            "573:\tlearn: 0.0979853\ttotal: 16.7s\tremaining: 12.4s\n",
            "574:\tlearn: 0.0979576\ttotal: 16.7s\tremaining: 12.4s\n",
            "575:\tlearn: 0.0979187\ttotal: 16.8s\tremaining: 12.3s\n",
            "576:\tlearn: 0.0978809\ttotal: 16.8s\tremaining: 12.3s\n",
            "577:\tlearn: 0.0978286\ttotal: 16.8s\tremaining: 12.3s\n",
            "578:\tlearn: 0.0978022\ttotal: 16.9s\tremaining: 12.3s\n",
            "579:\tlearn: 0.0977791\ttotal: 16.9s\tremaining: 12.2s\n",
            "580:\tlearn: 0.0977308\ttotal: 16.9s\tremaining: 12.2s\n",
            "581:\tlearn: 0.0976637\ttotal: 16.9s\tremaining: 12.2s\n",
            "582:\tlearn: 0.0976307\ttotal: 17s\tremaining: 12.1s\n",
            "583:\tlearn: 0.0975759\ttotal: 17s\tremaining: 12.1s\n",
            "584:\tlearn: 0.0975377\ttotal: 17s\tremaining: 12.1s\n",
            "585:\tlearn: 0.0975044\ttotal: 17s\tremaining: 12s\n",
            "586:\tlearn: 0.0974805\ttotal: 17.1s\tremaining: 12s\n",
            "587:\tlearn: 0.0974261\ttotal: 17.1s\tremaining: 12s\n",
            "588:\tlearn: 0.0973997\ttotal: 17.1s\tremaining: 11.9s\n",
            "589:\tlearn: 0.0973759\ttotal: 17.1s\tremaining: 11.9s\n",
            "590:\tlearn: 0.0973200\ttotal: 17.2s\tremaining: 11.9s\n",
            "591:\tlearn: 0.0972525\ttotal: 17.2s\tremaining: 11.8s\n",
            "592:\tlearn: 0.0972313\ttotal: 17.2s\tremaining: 11.8s\n",
            "593:\tlearn: 0.0971884\ttotal: 17.2s\tremaining: 11.8s\n",
            "594:\tlearn: 0.0971170\ttotal: 17.3s\tremaining: 11.8s\n",
            "595:\tlearn: 0.0970889\ttotal: 17.3s\tremaining: 11.7s\n",
            "596:\tlearn: 0.0970591\ttotal: 17.3s\tremaining: 11.7s\n",
            "597:\tlearn: 0.0970212\ttotal: 17.3s\tremaining: 11.7s\n",
            "598:\tlearn: 0.0969724\ttotal: 17.4s\tremaining: 11.6s\n",
            "599:\tlearn: 0.0969494\ttotal: 17.4s\tremaining: 11.6s\n",
            "600:\tlearn: 0.0969376\ttotal: 17.4s\tremaining: 11.6s\n",
            "601:\tlearn: 0.0968985\ttotal: 17.5s\tremaining: 11.5s\n",
            "602:\tlearn: 0.0968138\ttotal: 17.5s\tremaining: 11.5s\n",
            "603:\tlearn: 0.0967955\ttotal: 17.5s\tremaining: 11.5s\n",
            "604:\tlearn: 0.0967584\ttotal: 17.5s\tremaining: 11.4s\n",
            "605:\tlearn: 0.0967353\ttotal: 17.6s\tremaining: 11.4s\n",
            "606:\tlearn: 0.0966917\ttotal: 17.6s\tremaining: 11.4s\n",
            "607:\tlearn: 0.0966391\ttotal: 17.6s\tremaining: 11.4s\n",
            "608:\tlearn: 0.0966111\ttotal: 17.6s\tremaining: 11.3s\n",
            "609:\tlearn: 0.0965567\ttotal: 17.7s\tremaining: 11.3s\n",
            "610:\tlearn: 0.0964941\ttotal: 17.7s\tremaining: 11.3s\n",
            "611:\tlearn: 0.0964327\ttotal: 17.7s\tremaining: 11.2s\n",
            "612:\tlearn: 0.0964052\ttotal: 17.7s\tremaining: 11.2s\n",
            "613:\tlearn: 0.0963597\ttotal: 17.8s\tremaining: 11.2s\n",
            "614:\tlearn: 0.0963279\ttotal: 17.8s\tremaining: 11.1s\n",
            "615:\tlearn: 0.0963029\ttotal: 17.8s\tremaining: 11.1s\n",
            "616:\tlearn: 0.0962649\ttotal: 17.9s\tremaining: 11.1s\n",
            "617:\tlearn: 0.0962011\ttotal: 17.9s\tremaining: 11.1s\n",
            "618:\tlearn: 0.0961803\ttotal: 17.9s\tremaining: 11s\n",
            "619:\tlearn: 0.0961530\ttotal: 17.9s\tremaining: 11s\n",
            "620:\tlearn: 0.0960855\ttotal: 18s\tremaining: 11s\n",
            "621:\tlearn: 0.0960590\ttotal: 18s\tremaining: 10.9s\n",
            "622:\tlearn: 0.0960146\ttotal: 18s\tremaining: 10.9s\n",
            "623:\tlearn: 0.0960003\ttotal: 18s\tremaining: 10.9s\n",
            "624:\tlearn: 0.0959611\ttotal: 18.1s\tremaining: 10.8s\n",
            "625:\tlearn: 0.0959226\ttotal: 18.1s\tremaining: 10.8s\n",
            "626:\tlearn: 0.0958989\ttotal: 18.1s\tremaining: 10.8s\n",
            "627:\tlearn: 0.0958737\ttotal: 18.2s\tremaining: 10.8s\n",
            "628:\tlearn: 0.0958404\ttotal: 18.2s\tremaining: 10.7s\n",
            "629:\tlearn: 0.0958060\ttotal: 18.2s\tremaining: 10.7s\n",
            "630:\tlearn: 0.0957898\ttotal: 18.2s\tremaining: 10.7s\n",
            "631:\tlearn: 0.0957484\ttotal: 18.3s\tremaining: 10.6s\n",
            "632:\tlearn: 0.0957243\ttotal: 18.3s\tremaining: 10.6s\n",
            "633:\tlearn: 0.0956570\ttotal: 18.3s\tremaining: 10.6s\n",
            "634:\tlearn: 0.0956251\ttotal: 18.3s\tremaining: 10.5s\n",
            "635:\tlearn: 0.0955847\ttotal: 18.4s\tremaining: 10.5s\n",
            "636:\tlearn: 0.0955352\ttotal: 18.4s\tremaining: 10.5s\n",
            "637:\tlearn: 0.0954905\ttotal: 18.4s\tremaining: 10.5s\n",
            "638:\tlearn: 0.0954565\ttotal: 18.5s\tremaining: 10.4s\n",
            "639:\tlearn: 0.0954257\ttotal: 18.5s\tremaining: 10.4s\n",
            "640:\tlearn: 0.0953636\ttotal: 18.5s\tremaining: 10.4s\n",
            "641:\tlearn: 0.0953253\ttotal: 18.5s\tremaining: 10.3s\n",
            "642:\tlearn: 0.0953110\ttotal: 18.6s\tremaining: 10.3s\n",
            "643:\tlearn: 0.0952824\ttotal: 18.6s\tremaining: 10.3s\n",
            "644:\tlearn: 0.0952631\ttotal: 18.6s\tremaining: 10.2s\n",
            "645:\tlearn: 0.0952294\ttotal: 18.6s\tremaining: 10.2s\n",
            "646:\tlearn: 0.0952083\ttotal: 18.7s\tremaining: 10.2s\n",
            "647:\tlearn: 0.0951948\ttotal: 18.7s\tremaining: 10.1s\n",
            "648:\tlearn: 0.0951513\ttotal: 18.7s\tremaining: 10.1s\n",
            "649:\tlearn: 0.0950727\ttotal: 18.7s\tremaining: 10.1s\n",
            "650:\tlearn: 0.0950328\ttotal: 18.8s\tremaining: 10.1s\n",
            "651:\tlearn: 0.0949998\ttotal: 18.8s\tremaining: 10s\n",
            "652:\tlearn: 0.0949660\ttotal: 18.8s\tremaining: 10s\n",
            "653:\tlearn: 0.0949430\ttotal: 18.8s\tremaining: 9.96s\n",
            "654:\tlearn: 0.0949033\ttotal: 18.9s\tremaining: 9.93s\n",
            "655:\tlearn: 0.0948875\ttotal: 18.9s\tremaining: 9.9s\n",
            "656:\tlearn: 0.0948565\ttotal: 18.9s\tremaining: 9.87s\n",
            "657:\tlearn: 0.0948254\ttotal: 18.9s\tremaining: 9.84s\n",
            "658:\tlearn: 0.0947851\ttotal: 19s\tremaining: 9.81s\n",
            "659:\tlearn: 0.0947400\ttotal: 19s\tremaining: 9.78s\n",
            "660:\tlearn: 0.0947001\ttotal: 19s\tremaining: 9.75s\n",
            "661:\tlearn: 0.0946529\ttotal: 19s\tremaining: 9.72s\n",
            "662:\tlearn: 0.0946075\ttotal: 19.1s\tremaining: 9.7s\n",
            "663:\tlearn: 0.0945671\ttotal: 19.1s\tremaining: 9.67s\n",
            "664:\tlearn: 0.0945360\ttotal: 19.1s\tremaining: 9.64s\n",
            "665:\tlearn: 0.0944901\ttotal: 19.2s\tremaining: 9.61s\n",
            "666:\tlearn: 0.0944357\ttotal: 19.2s\tremaining: 9.57s\n",
            "667:\tlearn: 0.0944050\ttotal: 19.2s\tremaining: 9.54s\n",
            "668:\tlearn: 0.0943628\ttotal: 19.2s\tremaining: 9.51s\n",
            "669:\tlearn: 0.0943340\ttotal: 19.3s\tremaining: 9.48s\n",
            "670:\tlearn: 0.0942940\ttotal: 19.3s\tremaining: 9.45s\n",
            "671:\tlearn: 0.0942505\ttotal: 19.3s\tremaining: 9.42s\n",
            "672:\tlearn: 0.0942264\ttotal: 19.3s\tremaining: 9.39s\n",
            "673:\tlearn: 0.0941831\ttotal: 19.4s\tremaining: 9.36s\n",
            "674:\tlearn: 0.0941228\ttotal: 19.4s\tremaining: 9.34s\n",
            "675:\tlearn: 0.0940997\ttotal: 19.4s\tremaining: 9.31s\n",
            "676:\tlearn: 0.0940857\ttotal: 19.4s\tremaining: 9.28s\n",
            "677:\tlearn: 0.0940619\ttotal: 19.5s\tremaining: 9.25s\n",
            "678:\tlearn: 0.0940403\ttotal: 19.5s\tremaining: 9.21s\n",
            "679:\tlearn: 0.0940085\ttotal: 19.5s\tremaining: 9.19s\n",
            "680:\tlearn: 0.0939758\ttotal: 19.5s\tremaining: 9.15s\n",
            "681:\tlearn: 0.0939559\ttotal: 19.6s\tremaining: 9.12s\n",
            "682:\tlearn: 0.0939388\ttotal: 19.6s\tremaining: 9.09s\n",
            "683:\tlearn: 0.0939260\ttotal: 19.6s\tremaining: 9.06s\n",
            "684:\tlearn: 0.0938950\ttotal: 19.6s\tremaining: 9.03s\n",
            "685:\tlearn: 0.0938788\ttotal: 19.7s\tremaining: 9s\n",
            "686:\tlearn: 0.0938119\ttotal: 19.7s\tremaining: 8.97s\n",
            "687:\tlearn: 0.0937995\ttotal: 19.7s\tremaining: 8.94s\n",
            "688:\tlearn: 0.0937888\ttotal: 19.8s\tremaining: 8.91s\n",
            "689:\tlearn: 0.0937491\ttotal: 19.8s\tremaining: 8.88s\n",
            "690:\tlearn: 0.0937186\ttotal: 19.8s\tremaining: 8.85s\n",
            "691:\tlearn: 0.0936897\ttotal: 19.8s\tremaining: 8.82s\n",
            "692:\tlearn: 0.0936609\ttotal: 19.8s\tremaining: 8.79s\n",
            "693:\tlearn: 0.0936429\ttotal: 19.9s\tremaining: 8.76s\n",
            "694:\tlearn: 0.0936051\ttotal: 19.9s\tremaining: 8.73s\n",
            "695:\tlearn: 0.0935520\ttotal: 19.9s\tremaining: 8.7s\n",
            "696:\tlearn: 0.0935132\ttotal: 20s\tremaining: 8.67s\n",
            "697:\tlearn: 0.0934721\ttotal: 20s\tremaining: 8.64s\n",
            "698:\tlearn: 0.0934505\ttotal: 20s\tremaining: 8.61s\n",
            "699:\tlearn: 0.0934318\ttotal: 20s\tremaining: 8.58s\n",
            "700:\tlearn: 0.0933872\ttotal: 20.1s\tremaining: 8.55s\n",
            "701:\tlearn: 0.0933576\ttotal: 20.1s\tremaining: 8.53s\n",
            "702:\tlearn: 0.0933353\ttotal: 20.1s\tremaining: 8.5s\n",
            "703:\tlearn: 0.0933123\ttotal: 20.1s\tremaining: 8.47s\n",
            "704:\tlearn: 0.0933069\ttotal: 20.2s\tremaining: 8.44s\n",
            "705:\tlearn: 0.0932804\ttotal: 20.2s\tremaining: 8.41s\n",
            "706:\tlearn: 0.0932579\ttotal: 20.2s\tremaining: 8.38s\n",
            "707:\tlearn: 0.0932066\ttotal: 20.2s\tremaining: 8.35s\n",
            "708:\tlearn: 0.0931862\ttotal: 20.3s\tremaining: 8.31s\n",
            "709:\tlearn: 0.0931003\ttotal: 20.3s\tremaining: 8.29s\n",
            "710:\tlearn: 0.0930872\ttotal: 20.3s\tremaining: 8.26s\n",
            "711:\tlearn: 0.0930697\ttotal: 20.3s\tremaining: 8.23s\n",
            "712:\tlearn: 0.0930454\ttotal: 20.4s\tremaining: 8.2s\n",
            "713:\tlearn: 0.0930191\ttotal: 20.4s\tremaining: 8.17s\n",
            "714:\tlearn: 0.0929626\ttotal: 20.4s\tremaining: 8.14s\n",
            "715:\tlearn: 0.0929204\ttotal: 20.4s\tremaining: 8.11s\n",
            "716:\tlearn: 0.0928920\ttotal: 20.5s\tremaining: 8.08s\n",
            "717:\tlearn: 0.0928291\ttotal: 20.5s\tremaining: 8.05s\n",
            "718:\tlearn: 0.0928046\ttotal: 20.5s\tremaining: 8.03s\n",
            "719:\tlearn: 0.0927423\ttotal: 20.6s\tremaining: 8s\n",
            "720:\tlearn: 0.0927210\ttotal: 20.6s\tremaining: 7.96s\n",
            "721:\tlearn: 0.0927026\ttotal: 20.6s\tremaining: 7.94s\n",
            "722:\tlearn: 0.0926743\ttotal: 20.6s\tremaining: 7.91s\n",
            "723:\tlearn: 0.0926537\ttotal: 20.7s\tremaining: 7.88s\n",
            "724:\tlearn: 0.0926286\ttotal: 20.7s\tremaining: 7.85s\n",
            "725:\tlearn: 0.0926222\ttotal: 20.7s\tremaining: 7.82s\n",
            "726:\tlearn: 0.0926017\ttotal: 20.7s\tremaining: 7.79s\n",
            "727:\tlearn: 0.0925706\ttotal: 20.8s\tremaining: 7.76s\n",
            "728:\tlearn: 0.0925290\ttotal: 20.8s\tremaining: 7.73s\n",
            "729:\tlearn: 0.0925086\ttotal: 20.8s\tremaining: 7.7s\n",
            "730:\tlearn: 0.0924872\ttotal: 20.8s\tremaining: 7.67s\n",
            "731:\tlearn: 0.0924678\ttotal: 20.9s\tremaining: 7.64s\n",
            "732:\tlearn: 0.0924319\ttotal: 20.9s\tremaining: 7.61s\n",
            "733:\tlearn: 0.0924059\ttotal: 20.9s\tremaining: 7.58s\n",
            "734:\tlearn: 0.0923949\ttotal: 20.9s\tremaining: 7.55s\n",
            "735:\tlearn: 0.0923569\ttotal: 21s\tremaining: 7.52s\n",
            "736:\tlearn: 0.0923152\ttotal: 21s\tremaining: 7.49s\n",
            "737:\tlearn: 0.0922792\ttotal: 21s\tremaining: 7.46s\n",
            "738:\tlearn: 0.0922523\ttotal: 21.1s\tremaining: 7.44s\n",
            "739:\tlearn: 0.0922294\ttotal: 21.1s\tremaining: 7.41s\n",
            "740:\tlearn: 0.0921978\ttotal: 21.1s\tremaining: 7.38s\n",
            "741:\tlearn: 0.0921737\ttotal: 21.1s\tremaining: 7.35s\n",
            "742:\tlearn: 0.0921633\ttotal: 21.2s\tremaining: 7.32s\n",
            "743:\tlearn: 0.0921399\ttotal: 21.2s\tremaining: 7.29s\n",
            "744:\tlearn: 0.0921159\ttotal: 21.2s\tremaining: 7.26s\n",
            "745:\tlearn: 0.0920931\ttotal: 21.2s\tremaining: 7.23s\n",
            "746:\tlearn: 0.0920696\ttotal: 21.3s\tremaining: 7.2s\n",
            "747:\tlearn: 0.0920556\ttotal: 21.3s\tremaining: 7.17s\n",
            "748:\tlearn: 0.0920316\ttotal: 21.3s\tremaining: 7.14s\n",
            "749:\tlearn: 0.0919989\ttotal: 21.3s\tremaining: 7.11s\n",
            "750:\tlearn: 0.0919886\ttotal: 21.4s\tremaining: 7.08s\n",
            "751:\tlearn: 0.0919519\ttotal: 21.4s\tremaining: 7.05s\n",
            "752:\tlearn: 0.0919198\ttotal: 21.4s\tremaining: 7.02s\n",
            "753:\tlearn: 0.0919117\ttotal: 21.4s\tremaining: 7s\n",
            "754:\tlearn: 0.0918773\ttotal: 21.5s\tremaining: 6.97s\n",
            "755:\tlearn: 0.0918507\ttotal: 21.5s\tremaining: 6.94s\n",
            "756:\tlearn: 0.0918427\ttotal: 21.5s\tremaining: 6.91s\n",
            "757:\tlearn: 0.0918297\ttotal: 21.5s\tremaining: 6.88s\n",
            "758:\tlearn: 0.0918109\ttotal: 21.6s\tremaining: 6.85s\n",
            "759:\tlearn: 0.0917904\ttotal: 21.6s\tremaining: 6.82s\n",
            "760:\tlearn: 0.0917683\ttotal: 21.6s\tremaining: 6.79s\n",
            "761:\tlearn: 0.0917376\ttotal: 21.6s\tremaining: 6.76s\n",
            "762:\tlearn: 0.0917189\ttotal: 21.7s\tremaining: 6.73s\n",
            "763:\tlearn: 0.0917058\ttotal: 21.7s\tremaining: 6.7s\n",
            "764:\tlearn: 0.0916917\ttotal: 21.7s\tremaining: 6.67s\n",
            "765:\tlearn: 0.0916575\ttotal: 21.7s\tremaining: 6.64s\n",
            "766:\tlearn: 0.0916159\ttotal: 21.8s\tremaining: 6.61s\n",
            "767:\tlearn: 0.0915937\ttotal: 21.8s\tremaining: 6.58s\n",
            "768:\tlearn: 0.0915681\ttotal: 21.8s\tremaining: 6.55s\n",
            "769:\tlearn: 0.0915590\ttotal: 21.9s\tremaining: 6.53s\n",
            "770:\tlearn: 0.0915204\ttotal: 21.9s\tremaining: 6.5s\n",
            "771:\tlearn: 0.0914979\ttotal: 21.9s\tremaining: 6.47s\n",
            "772:\tlearn: 0.0914774\ttotal: 21.9s\tremaining: 6.44s\n",
            "773:\tlearn: 0.0914581\ttotal: 22s\tremaining: 6.41s\n",
            "774:\tlearn: 0.0914437\ttotal: 22s\tremaining: 6.38s\n",
            "775:\tlearn: 0.0913936\ttotal: 22s\tremaining: 6.35s\n",
            "776:\tlearn: 0.0913529\ttotal: 22s\tremaining: 6.32s\n",
            "777:\tlearn: 0.0913337\ttotal: 22.1s\tremaining: 6.29s\n",
            "778:\tlearn: 0.0913085\ttotal: 22.1s\tremaining: 6.27s\n",
            "779:\tlearn: 0.0912555\ttotal: 22.1s\tremaining: 6.24s\n",
            "780:\tlearn: 0.0912361\ttotal: 22.1s\tremaining: 6.21s\n",
            "781:\tlearn: 0.0911898\ttotal: 22.2s\tremaining: 6.18s\n",
            "782:\tlearn: 0.0911747\ttotal: 22.2s\tremaining: 6.15s\n",
            "783:\tlearn: 0.0911483\ttotal: 22.2s\tremaining: 6.12s\n",
            "784:\tlearn: 0.0911145\ttotal: 22.2s\tremaining: 6.09s\n",
            "785:\tlearn: 0.0911073\ttotal: 22.3s\tremaining: 6.06s\n",
            "786:\tlearn: 0.0910976\ttotal: 22.3s\tremaining: 6.03s\n",
            "787:\tlearn: 0.0910661\ttotal: 22.3s\tremaining: 6s\n",
            "788:\tlearn: 0.0910439\ttotal: 22.3s\tremaining: 5.97s\n",
            "789:\tlearn: 0.0910219\ttotal: 22.4s\tremaining: 5.95s\n",
            "790:\tlearn: 0.0910167\ttotal: 22.4s\tremaining: 5.92s\n",
            "791:\tlearn: 0.0909876\ttotal: 22.4s\tremaining: 5.89s\n",
            "792:\tlearn: 0.0909631\ttotal: 22.5s\tremaining: 5.87s\n",
            "793:\tlearn: 0.0909402\ttotal: 22.5s\tremaining: 5.85s\n",
            "794:\tlearn: 0.0909153\ttotal: 22.6s\tremaining: 5.83s\n",
            "795:\tlearn: 0.0908931\ttotal: 22.7s\tremaining: 5.81s\n",
            "796:\tlearn: 0.0908808\ttotal: 22.7s\tremaining: 5.79s\n",
            "797:\tlearn: 0.0908622\ttotal: 22.8s\tremaining: 5.78s\n",
            "798:\tlearn: 0.0908509\ttotal: 22.9s\tremaining: 5.75s\n",
            "799:\tlearn: 0.0908358\ttotal: 22.9s\tremaining: 5.73s\n",
            "800:\tlearn: 0.0908197\ttotal: 23s\tremaining: 5.71s\n",
            "801:\tlearn: 0.0907884\ttotal: 23.1s\tremaining: 5.69s\n",
            "802:\tlearn: 0.0907699\ttotal: 23.1s\tremaining: 5.67s\n",
            "803:\tlearn: 0.0907469\ttotal: 23.2s\tremaining: 5.65s\n",
            "804:\tlearn: 0.0907244\ttotal: 23.3s\tremaining: 5.63s\n",
            "805:\tlearn: 0.0906901\ttotal: 23.3s\tremaining: 5.61s\n",
            "806:\tlearn: 0.0906832\ttotal: 23.4s\tremaining: 5.59s\n",
            "807:\tlearn: 0.0906595\ttotal: 23.4s\tremaining: 5.57s\n",
            "808:\tlearn: 0.0906435\ttotal: 23.5s\tremaining: 5.55s\n",
            "809:\tlearn: 0.0906192\ttotal: 23.6s\tremaining: 5.53s\n",
            "810:\tlearn: 0.0905551\ttotal: 23.6s\tremaining: 5.51s\n",
            "811:\tlearn: 0.0905462\ttotal: 23.7s\tremaining: 5.49s\n",
            "812:\tlearn: 0.0905329\ttotal: 23.8s\tremaining: 5.47s\n",
            "813:\tlearn: 0.0905173\ttotal: 23.8s\tremaining: 5.45s\n",
            "814:\tlearn: 0.0904875\ttotal: 23.9s\tremaining: 5.42s\n",
            "815:\tlearn: 0.0904685\ttotal: 24s\tremaining: 5.4s\n",
            "816:\tlearn: 0.0904504\ttotal: 24s\tremaining: 5.38s\n",
            "817:\tlearn: 0.0904417\ttotal: 24.1s\tremaining: 5.36s\n",
            "818:\tlearn: 0.0904223\ttotal: 24.2s\tremaining: 5.34s\n",
            "819:\tlearn: 0.0904097\ttotal: 24.2s\tremaining: 5.32s\n",
            "820:\tlearn: 0.0903804\ttotal: 24.3s\tremaining: 5.29s\n",
            "821:\tlearn: 0.0903391\ttotal: 24.3s\tremaining: 5.27s\n",
            "822:\tlearn: 0.0903185\ttotal: 24.4s\tremaining: 5.24s\n",
            "823:\tlearn: 0.0902971\ttotal: 24.4s\tremaining: 5.22s\n",
            "824:\tlearn: 0.0902810\ttotal: 24.5s\tremaining: 5.19s\n",
            "825:\tlearn: 0.0902572\ttotal: 24.6s\tremaining: 5.17s\n",
            "826:\tlearn: 0.0902288\ttotal: 24.6s\tremaining: 5.15s\n",
            "827:\tlearn: 0.0902039\ttotal: 24.7s\tremaining: 5.13s\n",
            "828:\tlearn: 0.0901873\ttotal: 24.7s\tremaining: 5.1s\n",
            "829:\tlearn: 0.0901776\ttotal: 24.8s\tremaining: 5.07s\n",
            "830:\tlearn: 0.0901651\ttotal: 24.8s\tremaining: 5.04s\n",
            "831:\tlearn: 0.0901482\ttotal: 24.8s\tremaining: 5.02s\n",
            "832:\tlearn: 0.0901056\ttotal: 24.9s\tremaining: 4.99s\n",
            "833:\tlearn: 0.0900856\ttotal: 25s\tremaining: 4.97s\n",
            "834:\tlearn: 0.0900773\ttotal: 25s\tremaining: 4.95s\n",
            "835:\tlearn: 0.0900421\ttotal: 25.1s\tremaining: 4.93s\n",
            "836:\tlearn: 0.0900266\ttotal: 25.2s\tremaining: 4.9s\n",
            "837:\tlearn: 0.0900058\ttotal: 25.2s\tremaining: 4.88s\n",
            "838:\tlearn: 0.0899891\ttotal: 25.3s\tremaining: 4.85s\n",
            "839:\tlearn: 0.0899713\ttotal: 25.4s\tremaining: 4.83s\n",
            "840:\tlearn: 0.0899620\ttotal: 25.4s\tremaining: 4.8s\n",
            "841:\tlearn: 0.0899570\ttotal: 25.5s\tremaining: 4.78s\n",
            "842:\tlearn: 0.0899241\ttotal: 25.5s\tremaining: 4.75s\n",
            "843:\tlearn: 0.0899143\ttotal: 25.5s\tremaining: 4.72s\n",
            "844:\tlearn: 0.0898928\ttotal: 25.6s\tremaining: 4.69s\n",
            "845:\tlearn: 0.0898743\ttotal: 25.6s\tremaining: 4.66s\n",
            "846:\tlearn: 0.0898579\ttotal: 25.6s\tremaining: 4.63s\n",
            "847:\tlearn: 0.0898292\ttotal: 25.6s\tremaining: 4.6s\n",
            "848:\tlearn: 0.0898042\ttotal: 25.7s\tremaining: 4.56s\n",
            "849:\tlearn: 0.0897888\ttotal: 25.7s\tremaining: 4.53s\n",
            "850:\tlearn: 0.0897716\ttotal: 25.7s\tremaining: 4.5s\n",
            "851:\tlearn: 0.0897532\ttotal: 25.7s\tremaining: 4.47s\n",
            "852:\tlearn: 0.0897158\ttotal: 25.8s\tremaining: 4.44s\n",
            "853:\tlearn: 0.0896654\ttotal: 25.8s\tremaining: 4.41s\n",
            "854:\tlearn: 0.0896506\ttotal: 25.8s\tremaining: 4.38s\n",
            "855:\tlearn: 0.0896333\ttotal: 25.9s\tremaining: 4.35s\n",
            "856:\tlearn: 0.0896098\ttotal: 25.9s\tremaining: 4.32s\n",
            "857:\tlearn: 0.0895963\ttotal: 25.9s\tremaining: 4.29s\n",
            "858:\tlearn: 0.0895887\ttotal: 25.9s\tremaining: 4.26s\n",
            "859:\tlearn: 0.0895814\ttotal: 26s\tremaining: 4.22s\n",
            "860:\tlearn: 0.0895578\ttotal: 26s\tremaining: 4.19s\n",
            "861:\tlearn: 0.0895458\ttotal: 26s\tremaining: 4.16s\n",
            "862:\tlearn: 0.0895312\ttotal: 26s\tremaining: 4.13s\n",
            "863:\tlearn: 0.0895112\ttotal: 26.1s\tremaining: 4.1s\n",
            "864:\tlearn: 0.0895080\ttotal: 26.1s\tremaining: 4.07s\n",
            "865:\tlearn: 0.0894330\ttotal: 26.1s\tremaining: 4.04s\n",
            "866:\tlearn: 0.0894237\ttotal: 26.1s\tremaining: 4.01s\n",
            "867:\tlearn: 0.0893886\ttotal: 26.2s\tremaining: 3.98s\n",
            "868:\tlearn: 0.0893826\ttotal: 26.2s\tremaining: 3.95s\n",
            "869:\tlearn: 0.0893394\ttotal: 26.2s\tremaining: 3.92s\n",
            "870:\tlearn: 0.0893263\ttotal: 26.2s\tremaining: 3.88s\n",
            "871:\tlearn: 0.0893025\ttotal: 26.3s\tremaining: 3.85s\n",
            "872:\tlearn: 0.0892904\ttotal: 26.3s\tremaining: 3.82s\n",
            "873:\tlearn: 0.0892832\ttotal: 26.3s\tremaining: 3.79s\n",
            "874:\tlearn: 0.0892745\ttotal: 26.3s\tremaining: 3.76s\n",
            "875:\tlearn: 0.0892612\ttotal: 26.4s\tremaining: 3.73s\n",
            "876:\tlearn: 0.0892419\ttotal: 26.4s\tremaining: 3.7s\n",
            "877:\tlearn: 0.0892347\ttotal: 26.4s\tremaining: 3.67s\n",
            "878:\tlearn: 0.0892161\ttotal: 26.4s\tremaining: 3.64s\n",
            "879:\tlearn: 0.0891948\ttotal: 26.5s\tremaining: 3.61s\n",
            "880:\tlearn: 0.0891903\ttotal: 26.5s\tremaining: 3.58s\n",
            "881:\tlearn: 0.0891781\ttotal: 26.5s\tremaining: 3.55s\n",
            "882:\tlearn: 0.0891665\ttotal: 26.5s\tremaining: 3.52s\n",
            "883:\tlearn: 0.0891401\ttotal: 26.6s\tremaining: 3.49s\n",
            "884:\tlearn: 0.0891242\ttotal: 26.6s\tremaining: 3.46s\n",
            "885:\tlearn: 0.0890993\ttotal: 26.6s\tremaining: 3.42s\n",
            "886:\tlearn: 0.0890749\ttotal: 26.6s\tremaining: 3.39s\n",
            "887:\tlearn: 0.0890561\ttotal: 26.7s\tremaining: 3.36s\n",
            "888:\tlearn: 0.0890392\ttotal: 26.7s\tremaining: 3.33s\n",
            "889:\tlearn: 0.0890238\ttotal: 26.7s\tremaining: 3.3s\n",
            "890:\tlearn: 0.0890049\ttotal: 26.8s\tremaining: 3.27s\n",
            "891:\tlearn: 0.0889739\ttotal: 26.8s\tremaining: 3.24s\n",
            "892:\tlearn: 0.0889599\ttotal: 26.8s\tremaining: 3.21s\n",
            "893:\tlearn: 0.0889390\ttotal: 26.8s\tremaining: 3.18s\n",
            "894:\tlearn: 0.0889190\ttotal: 26.9s\tremaining: 3.15s\n",
            "895:\tlearn: 0.0888938\ttotal: 26.9s\tremaining: 3.12s\n",
            "896:\tlearn: 0.0888389\ttotal: 26.9s\tremaining: 3.09s\n",
            "897:\tlearn: 0.0888269\ttotal: 26.9s\tremaining: 3.06s\n",
            "898:\tlearn: 0.0888228\ttotal: 27s\tremaining: 3.03s\n",
            "899:\tlearn: 0.0888043\ttotal: 27s\tremaining: 3s\n",
            "900:\tlearn: 0.0887781\ttotal: 27s\tremaining: 2.97s\n",
            "901:\tlearn: 0.0887532\ttotal: 27s\tremaining: 2.94s\n",
            "902:\tlearn: 0.0887228\ttotal: 27.1s\tremaining: 2.91s\n",
            "903:\tlearn: 0.0887026\ttotal: 27.1s\tremaining: 2.88s\n",
            "904:\tlearn: 0.0886944\ttotal: 27.1s\tremaining: 2.85s\n",
            "905:\tlearn: 0.0886771\ttotal: 27.1s\tremaining: 2.82s\n",
            "906:\tlearn: 0.0886645\ttotal: 27.2s\tremaining: 2.79s\n",
            "907:\tlearn: 0.0886418\ttotal: 27.2s\tremaining: 2.75s\n",
            "908:\tlearn: 0.0886164\ttotal: 27.2s\tremaining: 2.73s\n",
            "909:\tlearn: 0.0886020\ttotal: 27.2s\tremaining: 2.69s\n",
            "910:\tlearn: 0.0885958\ttotal: 27.3s\tremaining: 2.66s\n",
            "911:\tlearn: 0.0885835\ttotal: 27.3s\tremaining: 2.63s\n",
            "912:\tlearn: 0.0885746\ttotal: 27.3s\tremaining: 2.6s\n",
            "913:\tlearn: 0.0885691\ttotal: 27.3s\tremaining: 2.57s\n",
            "914:\tlearn: 0.0885589\ttotal: 27.4s\tremaining: 2.54s\n",
            "915:\tlearn: 0.0885466\ttotal: 27.4s\tremaining: 2.51s\n",
            "916:\tlearn: 0.0885414\ttotal: 27.4s\tremaining: 2.48s\n",
            "917:\tlearn: 0.0885327\ttotal: 27.4s\tremaining: 2.45s\n",
            "918:\tlearn: 0.0885184\ttotal: 27.5s\tremaining: 2.42s\n",
            "919:\tlearn: 0.0885075\ttotal: 27.5s\tremaining: 2.39s\n",
            "920:\tlearn: 0.0884757\ttotal: 27.5s\tremaining: 2.36s\n",
            "921:\tlearn: 0.0884656\ttotal: 27.6s\tremaining: 2.33s\n",
            "922:\tlearn: 0.0884471\ttotal: 27.6s\tremaining: 2.3s\n",
            "923:\tlearn: 0.0884219\ttotal: 27.6s\tremaining: 2.27s\n",
            "924:\tlearn: 0.0884093\ttotal: 27.6s\tremaining: 2.24s\n",
            "925:\tlearn: 0.0883904\ttotal: 27.7s\tremaining: 2.21s\n",
            "926:\tlearn: 0.0883600\ttotal: 27.7s\tremaining: 2.18s\n",
            "927:\tlearn: 0.0883417\ttotal: 27.7s\tremaining: 2.15s\n",
            "928:\tlearn: 0.0883129\ttotal: 27.7s\tremaining: 2.12s\n",
            "929:\tlearn: 0.0883007\ttotal: 27.8s\tremaining: 2.09s\n",
            "930:\tlearn: 0.0882954\ttotal: 27.8s\tremaining: 2.06s\n",
            "931:\tlearn: 0.0882813\ttotal: 27.8s\tremaining: 2.03s\n",
            "932:\tlearn: 0.0882670\ttotal: 27.8s\tremaining: 2s\n",
            "933:\tlearn: 0.0882611\ttotal: 27.9s\tremaining: 1.97s\n",
            "934:\tlearn: 0.0882254\ttotal: 27.9s\tremaining: 1.94s\n",
            "935:\tlearn: 0.0882062\ttotal: 27.9s\tremaining: 1.91s\n",
            "936:\tlearn: 0.0881909\ttotal: 27.9s\tremaining: 1.88s\n",
            "937:\tlearn: 0.0881760\ttotal: 28s\tremaining: 1.85s\n",
            "938:\tlearn: 0.0881255\ttotal: 28s\tremaining: 1.82s\n",
            "939:\tlearn: 0.0881115\ttotal: 28s\tremaining: 1.79s\n",
            "940:\tlearn: 0.0881017\ttotal: 28.1s\tremaining: 1.76s\n",
            "941:\tlearn: 0.0880931\ttotal: 28.1s\tremaining: 1.73s\n",
            "942:\tlearn: 0.0880767\ttotal: 28.1s\tremaining: 1.7s\n",
            "943:\tlearn: 0.0880589\ttotal: 28.1s\tremaining: 1.67s\n",
            "944:\tlearn: 0.0880317\ttotal: 28.2s\tremaining: 1.64s\n",
            "945:\tlearn: 0.0880202\ttotal: 28.2s\tremaining: 1.61s\n",
            "946:\tlearn: 0.0880146\ttotal: 28.2s\tremaining: 1.58s\n",
            "947:\tlearn: 0.0879978\ttotal: 28.2s\tremaining: 1.55s\n",
            "948:\tlearn: 0.0879871\ttotal: 28.3s\tremaining: 1.52s\n",
            "949:\tlearn: 0.0879741\ttotal: 28.3s\tremaining: 1.49s\n",
            "950:\tlearn: 0.0879597\ttotal: 28.3s\tremaining: 1.46s\n",
            "951:\tlearn: 0.0879386\ttotal: 28.3s\tremaining: 1.43s\n",
            "952:\tlearn: 0.0879227\ttotal: 28.4s\tremaining: 1.4s\n",
            "953:\tlearn: 0.0879122\ttotal: 28.4s\tremaining: 1.37s\n",
            "954:\tlearn: 0.0879059\ttotal: 28.4s\tremaining: 1.34s\n",
            "955:\tlearn: 0.0878914\ttotal: 28.4s\tremaining: 1.31s\n",
            "956:\tlearn: 0.0878785\ttotal: 28.5s\tremaining: 1.28s\n",
            "957:\tlearn: 0.0878525\ttotal: 28.5s\tremaining: 1.25s\n",
            "958:\tlearn: 0.0878408\ttotal: 28.5s\tremaining: 1.22s\n",
            "959:\tlearn: 0.0878193\ttotal: 28.5s\tremaining: 1.19s\n",
            "960:\tlearn: 0.0878113\ttotal: 28.6s\tremaining: 1.16s\n",
            "961:\tlearn: 0.0878010\ttotal: 28.6s\tremaining: 1.13s\n",
            "962:\tlearn: 0.0877772\ttotal: 28.6s\tremaining: 1.1s\n",
            "963:\tlearn: 0.0877590\ttotal: 28.7s\tremaining: 1.07s\n",
            "964:\tlearn: 0.0877561\ttotal: 28.7s\tremaining: 1.04s\n",
            "965:\tlearn: 0.0877298\ttotal: 28.7s\tremaining: 1.01s\n",
            "966:\tlearn: 0.0877065\ttotal: 28.8s\tremaining: 981ms\n",
            "967:\tlearn: 0.0876820\ttotal: 28.8s\tremaining: 951ms\n",
            "968:\tlearn: 0.0876623\ttotal: 28.8s\tremaining: 922ms\n",
            "969:\tlearn: 0.0876548\ttotal: 28.8s\tremaining: 892ms\n",
            "970:\tlearn: 0.0876422\ttotal: 28.9s\tremaining: 862ms\n",
            "971:\tlearn: 0.0876166\ttotal: 28.9s\tremaining: 832ms\n",
            "972:\tlearn: 0.0875986\ttotal: 28.9s\tremaining: 802ms\n",
            "973:\tlearn: 0.0875907\ttotal: 28.9s\tremaining: 772ms\n",
            "974:\tlearn: 0.0875893\ttotal: 29s\tremaining: 743ms\n",
            "975:\tlearn: 0.0875779\ttotal: 29s\tremaining: 713ms\n",
            "976:\tlearn: 0.0875741\ttotal: 29s\tremaining: 683ms\n",
            "977:\tlearn: 0.0875581\ttotal: 29s\tremaining: 653ms\n",
            "978:\tlearn: 0.0875512\ttotal: 29.1s\tremaining: 623ms\n",
            "979:\tlearn: 0.0875322\ttotal: 29.1s\tremaining: 593ms\n",
            "980:\tlearn: 0.0875305\ttotal: 29.1s\tremaining: 564ms\n",
            "981:\tlearn: 0.0875110\ttotal: 29.1s\tremaining: 534ms\n",
            "982:\tlearn: 0.0874957\ttotal: 29.2s\tremaining: 504ms\n",
            "983:\tlearn: 0.0874780\ttotal: 29.2s\tremaining: 475ms\n",
            "984:\tlearn: 0.0874658\ttotal: 29.2s\tremaining: 445ms\n",
            "985:\tlearn: 0.0874419\ttotal: 29.2s\tremaining: 415ms\n",
            "986:\tlearn: 0.0874086\ttotal: 29.3s\tremaining: 385ms\n",
            "987:\tlearn: 0.0873930\ttotal: 29.3s\tremaining: 356ms\n",
            "988:\tlearn: 0.0873801\ttotal: 29.3s\tremaining: 326ms\n",
            "989:\tlearn: 0.0873725\ttotal: 29.4s\tremaining: 296ms\n",
            "990:\tlearn: 0.0873566\ttotal: 29.4s\tremaining: 267ms\n",
            "991:\tlearn: 0.0873436\ttotal: 29.4s\tremaining: 237ms\n",
            "992:\tlearn: 0.0873208\ttotal: 29.4s\tremaining: 207ms\n",
            "993:\tlearn: 0.0873081\ttotal: 29.5s\tremaining: 178ms\n",
            "994:\tlearn: 0.0873009\ttotal: 29.5s\tremaining: 148ms\n",
            "995:\tlearn: 0.0872783\ttotal: 29.5s\tremaining: 119ms\n",
            "996:\tlearn: 0.0872683\ttotal: 29.5s\tremaining: 88.9ms\n",
            "997:\tlearn: 0.0872512\ttotal: 29.6s\tremaining: 59.3ms\n",
            "998:\tlearn: 0.0872412\ttotal: 29.6s\tremaining: 29.6ms\n",
            "999:\tlearn: 0.0872371\ttotal: 29.6s\tremaining: 0us\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97      9131\n",
            "           1       0.97      0.97      0.97      9130\n",
            "\n",
            "    accuracy                           0.97     18261\n",
            "   macro avg       0.97      0.97      0.97     18261\n",
            "weighted avg       0.97      0.97      0.97     18261\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_cb = CatBoostClassifier()\n",
        "model_cb.fit(X_train,y_train)\n",
        "\n",
        "#make predictions on validation set\n",
        "catboost_pred = model_cb.predict(X_test)\n",
        "print (classification_report(y_test,catboost_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ez0yAmDsdopZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7722f82a-6edb-4218-a338-e0350b1de53f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9674168183371572"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "#balanced_accuracy_score(df['malware'], ct_test['malware'])\n",
        "balanced_accuracy_score(y_test, catboost_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_7RG83SdopZ"
      },
      "source": [
        "# lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X442HOY8HEnL"
      },
      "outputs": [],
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "lgbm = LGBMClassifier() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieYHFDfuce4q"
      },
      "outputs": [],
      "source": [
        "ltparam_grid = {\n",
        "    'learning_rate': [0.1, 0.01],\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [4, 6],\n",
        "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
        "    'subsample': [0.7, 0.8, 0.9],\n",
        "    'min_child_samples': [1, 5, 10]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A58ZgfzJeVhW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b79f077-7831-47b5-b80b-4752aa233601"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LGBMClassifier(colsample_bytree=0.7, max_depth=6, min_child_samples=1,\n",
            "               n_estimators=150, objective='regression', random_state=101,\n",
            "               subsample=0.7)\n"
          ]
        }
      ],
      "source": [
        "LBGM = LGBMClassifier(objective='regression', \n",
        "                              random_state=101)\n",
        "\n",
        "# Step 3: Initalise Grid Search with 3-fold cross validation and fit model\n",
        "lgbm_hgs = HalvingGridSearchCV(estimator=LBGM, \n",
        "                     param_grid=ltparam_grid,\n",
        "                     cv=strat_kfold, \n",
        "                     n_jobs=-1, \n",
        "                     scoring='neg_root_mean_squared_error',\n",
        "                     random_state = 15)\n",
        "lgbm_hgs.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Print best parameters\n",
        "best_params = lgbm_hgs.best_estimator_\n",
        "print(best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "924x_3jlG4BO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74812fa4-8722-4a78-d1cd-68b6ef76b902"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.21812330302684665\n"
          ]
        }
      ],
      "source": [
        "print(lgbm_hgs.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpIGttedd16t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec490b85-6606-4e21-e875-f17220d98dd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.96      0.95      9131\n",
            "           1       0.95      0.95      0.95      9130\n",
            "\n",
            "    accuracy                           0.95     18261\n",
            "   macro avg       0.95      0.95      0.95     18261\n",
            "weighted avg       0.95      0.95      0.95     18261\n",
            "\n"
          ]
        }
      ],
      "source": [
        "estimator = LGBMClassifier(colsample_bytree=0.7, max_depth=6, min_child_samples=1,\n",
        "               n_estimators=150, objective='regression', random_state=101,\n",
        "               subsample=0.7)\n",
        "estimator.fit(X_train,y_train)\n",
        "\n",
        "lgbm_pred = estimator.predict(X_test)\n",
        "print (classification_report(y_test,lgbm_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oOxi8eHdopZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f635c4b5-2010-4f05-9676-5495f5db8423"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9515906179051588"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "#balanced_accuracy_score(df['malware'], lt_test['malware'])\n",
        "balanced_accuracy_score(y_test, lgbm_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f398N97Adopa"
      },
      "source": [
        "# Ensemble method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwlpBUHJHEnM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dc1db05-1c5c-453b-bcfd-dfe4f4b90aca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate set to 0.064369\n",
            "0:\tlearn: 0.6308243\ttotal: 31.4ms\tremaining: 31.3s\n",
            "1:\tlearn: 0.5810269\ttotal: 59.2ms\tremaining: 29.5s\n",
            "2:\tlearn: 0.5359098\ttotal: 84.1ms\tremaining: 28s\n",
            "3:\tlearn: 0.5041706\ttotal: 108ms\tremaining: 26.9s\n",
            "4:\tlearn: 0.4756019\ttotal: 133ms\tremaining: 26.4s\n",
            "5:\tlearn: 0.4493463\ttotal: 158ms\tremaining: 26.2s\n",
            "6:\tlearn: 0.4260050\ttotal: 196ms\tremaining: 27.8s\n",
            "7:\tlearn: 0.4047255\ttotal: 223ms\tremaining: 27.6s\n",
            "8:\tlearn: 0.3917571\ttotal: 260ms\tremaining: 28.7s\n",
            "9:\tlearn: 0.3777949\ttotal: 286ms\tremaining: 28.3s\n",
            "10:\tlearn: 0.3623220\ttotal: 314ms\tremaining: 28.2s\n",
            "11:\tlearn: 0.3529262\ttotal: 338ms\tremaining: 27.8s\n",
            "12:\tlearn: 0.3410026\ttotal: 364ms\tremaining: 27.7s\n",
            "13:\tlearn: 0.3259005\ttotal: 393ms\tremaining: 27.7s\n",
            "14:\tlearn: 0.3174242\ttotal: 430ms\tremaining: 28.2s\n",
            "15:\tlearn: 0.3094217\ttotal: 458ms\tremaining: 28.1s\n",
            "16:\tlearn: 0.3037917\ttotal: 483ms\tremaining: 27.9s\n",
            "17:\tlearn: 0.2985157\ttotal: 519ms\tremaining: 28.3s\n",
            "18:\tlearn: 0.2930401\ttotal: 544ms\tremaining: 28.1s\n",
            "19:\tlearn: 0.2893123\ttotal: 567ms\tremaining: 27.8s\n",
            "20:\tlearn: 0.2825008\ttotal: 593ms\tremaining: 27.6s\n",
            "21:\tlearn: 0.2772673\ttotal: 619ms\tremaining: 27.5s\n",
            "22:\tlearn: 0.2728489\ttotal: 645ms\tremaining: 27.4s\n",
            "23:\tlearn: 0.2672581\ttotal: 672ms\tremaining: 27.3s\n",
            "24:\tlearn: 0.2631091\ttotal: 694ms\tremaining: 27.1s\n",
            "25:\tlearn: 0.2606566\ttotal: 718ms\tremaining: 26.9s\n",
            "26:\tlearn: 0.2569403\ttotal: 743ms\tremaining: 26.8s\n",
            "27:\tlearn: 0.2544809\ttotal: 768ms\tremaining: 26.7s\n",
            "28:\tlearn: 0.2528401\ttotal: 793ms\tremaining: 26.5s\n",
            "29:\tlearn: 0.2508019\ttotal: 819ms\tremaining: 26.5s\n",
            "30:\tlearn: 0.2471088\ttotal: 846ms\tremaining: 26.4s\n",
            "31:\tlearn: 0.2431015\ttotal: 874ms\tremaining: 26.4s\n",
            "32:\tlearn: 0.2400737\ttotal: 901ms\tremaining: 26.4s\n",
            "33:\tlearn: 0.2379355\ttotal: 925ms\tremaining: 26.3s\n",
            "34:\tlearn: 0.2363443\ttotal: 949ms\tremaining: 26.2s\n",
            "35:\tlearn: 0.2339436\ttotal: 973ms\tremaining: 26.1s\n",
            "36:\tlearn: 0.2322040\ttotal: 997ms\tremaining: 26s\n",
            "37:\tlearn: 0.2300809\ttotal: 1.02s\tremaining: 25.9s\n",
            "38:\tlearn: 0.2284834\ttotal: 1.06s\tremaining: 26.1s\n",
            "39:\tlearn: 0.2267090\ttotal: 1.08s\tremaining: 26s\n",
            "40:\tlearn: 0.2250963\ttotal: 1.11s\tremaining: 25.9s\n",
            "41:\tlearn: 0.2230742\ttotal: 1.13s\tremaining: 25.8s\n",
            "42:\tlearn: 0.2215806\ttotal: 1.15s\tremaining: 25.7s\n",
            "43:\tlearn: 0.2206552\ttotal: 1.18s\tremaining: 25.7s\n",
            "44:\tlearn: 0.2191503\ttotal: 1.21s\tremaining: 25.6s\n",
            "45:\tlearn: 0.2178832\ttotal: 1.23s\tremaining: 25.5s\n",
            "46:\tlearn: 0.2142105\ttotal: 1.26s\tremaining: 25.6s\n",
            "47:\tlearn: 0.2131240\ttotal: 1.28s\tremaining: 25.5s\n",
            "48:\tlearn: 0.2112525\ttotal: 1.31s\tremaining: 25.5s\n",
            "49:\tlearn: 0.2099112\ttotal: 1.34s\tremaining: 25.5s\n",
            "50:\tlearn: 0.2089078\ttotal: 1.36s\tremaining: 25.4s\n",
            "51:\tlearn: 0.2073195\ttotal: 1.39s\tremaining: 25.4s\n",
            "52:\tlearn: 0.2063349\ttotal: 1.42s\tremaining: 25.3s\n",
            "53:\tlearn: 0.2055148\ttotal: 1.44s\tremaining: 25.2s\n",
            "54:\tlearn: 0.2046830\ttotal: 1.47s\tremaining: 25.2s\n",
            "55:\tlearn: 0.2035522\ttotal: 1.49s\tremaining: 25.2s\n",
            "56:\tlearn: 0.2023226\ttotal: 1.52s\tremaining: 25.2s\n",
            "57:\tlearn: 0.2014904\ttotal: 1.55s\tremaining: 25.1s\n",
            "58:\tlearn: 0.1995138\ttotal: 1.57s\tremaining: 25.1s\n",
            "59:\tlearn: 0.1984219\ttotal: 1.6s\tremaining: 25s\n",
            "60:\tlearn: 0.1975810\ttotal: 1.62s\tremaining: 24.9s\n",
            "61:\tlearn: 0.1962446\ttotal: 1.65s\tremaining: 24.9s\n",
            "62:\tlearn: 0.1951121\ttotal: 1.67s\tremaining: 24.9s\n",
            "63:\tlearn: 0.1942205\ttotal: 1.7s\tremaining: 24.8s\n",
            "64:\tlearn: 0.1930494\ttotal: 1.72s\tremaining: 24.8s\n",
            "65:\tlearn: 0.1924235\ttotal: 1.75s\tremaining: 24.7s\n",
            "66:\tlearn: 0.1918245\ttotal: 1.77s\tremaining: 24.6s\n",
            "67:\tlearn: 0.1910944\ttotal: 1.79s\tremaining: 24.6s\n",
            "68:\tlearn: 0.1903306\ttotal: 1.81s\tremaining: 24.5s\n",
            "69:\tlearn: 0.1895534\ttotal: 1.84s\tremaining: 24.4s\n",
            "70:\tlearn: 0.1887794\ttotal: 1.86s\tremaining: 24.4s\n",
            "71:\tlearn: 0.1881267\ttotal: 1.89s\tremaining: 24.4s\n",
            "72:\tlearn: 0.1874729\ttotal: 1.91s\tremaining: 24.3s\n",
            "73:\tlearn: 0.1870981\ttotal: 1.94s\tremaining: 24.2s\n",
            "74:\tlearn: 0.1863095\ttotal: 1.96s\tremaining: 24.2s\n",
            "75:\tlearn: 0.1852464\ttotal: 1.99s\tremaining: 24.2s\n",
            "76:\tlearn: 0.1844487\ttotal: 2.01s\tremaining: 24.1s\n",
            "77:\tlearn: 0.1836214\ttotal: 2.04s\tremaining: 24.1s\n",
            "78:\tlearn: 0.1822349\ttotal: 2.06s\tremaining: 24s\n",
            "79:\tlearn: 0.1813160\ttotal: 2.09s\tremaining: 24s\n",
            "80:\tlearn: 0.1808184\ttotal: 2.11s\tremaining: 24s\n",
            "81:\tlearn: 0.1802554\ttotal: 2.14s\tremaining: 23.9s\n",
            "82:\tlearn: 0.1796895\ttotal: 2.16s\tremaining: 23.9s\n",
            "83:\tlearn: 0.1790461\ttotal: 2.19s\tremaining: 23.9s\n",
            "84:\tlearn: 0.1783616\ttotal: 2.21s\tremaining: 23.9s\n",
            "85:\tlearn: 0.1771056\ttotal: 2.25s\tremaining: 23.9s\n",
            "86:\tlearn: 0.1763615\ttotal: 2.27s\tremaining: 23.8s\n",
            "87:\tlearn: 0.1756077\ttotal: 2.3s\tremaining: 23.8s\n",
            "88:\tlearn: 0.1747477\ttotal: 2.33s\tremaining: 23.8s\n",
            "89:\tlearn: 0.1739877\ttotal: 2.35s\tremaining: 23.8s\n",
            "90:\tlearn: 0.1734722\ttotal: 2.38s\tremaining: 23.7s\n",
            "91:\tlearn: 0.1730094\ttotal: 2.4s\tremaining: 23.7s\n",
            "92:\tlearn: 0.1722908\ttotal: 2.42s\tremaining: 23.6s\n",
            "93:\tlearn: 0.1714295\ttotal: 2.45s\tremaining: 23.6s\n",
            "94:\tlearn: 0.1708905\ttotal: 2.48s\tremaining: 23.6s\n",
            "95:\tlearn: 0.1702454\ttotal: 2.5s\tremaining: 23.6s\n",
            "96:\tlearn: 0.1696845\ttotal: 2.53s\tremaining: 23.6s\n",
            "97:\tlearn: 0.1690486\ttotal: 2.55s\tremaining: 23.5s\n",
            "98:\tlearn: 0.1687117\ttotal: 2.58s\tremaining: 23.5s\n",
            "99:\tlearn: 0.1679678\ttotal: 2.6s\tremaining: 23.4s\n",
            "100:\tlearn: 0.1674358\ttotal: 2.63s\tremaining: 23.4s\n",
            "101:\tlearn: 0.1670843\ttotal: 2.65s\tremaining: 23.3s\n",
            "102:\tlearn: 0.1665049\ttotal: 2.67s\tremaining: 23.3s\n",
            "103:\tlearn: 0.1660995\ttotal: 2.7s\tremaining: 23.2s\n",
            "104:\tlearn: 0.1657240\ttotal: 2.72s\tremaining: 23.2s\n",
            "105:\tlearn: 0.1653317\ttotal: 2.75s\tremaining: 23.2s\n",
            "106:\tlearn: 0.1648201\ttotal: 2.77s\tremaining: 23.1s\n",
            "107:\tlearn: 0.1644654\ttotal: 2.79s\tremaining: 23.1s\n",
            "108:\tlearn: 0.1640591\ttotal: 2.82s\tremaining: 23s\n",
            "109:\tlearn: 0.1635176\ttotal: 2.85s\tremaining: 23s\n",
            "110:\tlearn: 0.1628331\ttotal: 2.88s\tremaining: 23s\n",
            "111:\tlearn: 0.1621855\ttotal: 2.9s\tremaining: 23s\n",
            "112:\tlearn: 0.1617860\ttotal: 2.93s\tremaining: 23s\n",
            "113:\tlearn: 0.1611618\ttotal: 2.95s\tremaining: 23s\n",
            "114:\tlearn: 0.1605504\ttotal: 2.98s\tremaining: 22.9s\n",
            "115:\tlearn: 0.1601728\ttotal: 3s\tremaining: 22.9s\n",
            "116:\tlearn: 0.1595818\ttotal: 3.03s\tremaining: 22.9s\n",
            "117:\tlearn: 0.1590333\ttotal: 3.06s\tremaining: 22.9s\n",
            "118:\tlearn: 0.1586786\ttotal: 3.08s\tremaining: 22.8s\n",
            "119:\tlearn: 0.1583479\ttotal: 3.11s\tremaining: 22.8s\n",
            "120:\tlearn: 0.1579593\ttotal: 3.13s\tremaining: 22.7s\n",
            "121:\tlearn: 0.1572960\ttotal: 3.16s\tremaining: 22.7s\n",
            "122:\tlearn: 0.1568890\ttotal: 3.19s\tremaining: 22.8s\n",
            "123:\tlearn: 0.1565062\ttotal: 3.22s\tremaining: 22.7s\n",
            "124:\tlearn: 0.1559982\ttotal: 3.24s\tremaining: 22.7s\n",
            "125:\tlearn: 0.1556512\ttotal: 3.27s\tremaining: 22.7s\n",
            "126:\tlearn: 0.1551454\ttotal: 3.29s\tremaining: 22.6s\n",
            "127:\tlearn: 0.1547286\ttotal: 3.32s\tremaining: 22.6s\n",
            "128:\tlearn: 0.1541535\ttotal: 3.34s\tremaining: 22.6s\n",
            "129:\tlearn: 0.1536184\ttotal: 3.37s\tremaining: 22.6s\n",
            "130:\tlearn: 0.1533175\ttotal: 3.4s\tremaining: 22.5s\n",
            "131:\tlearn: 0.1529587\ttotal: 3.42s\tremaining: 22.5s\n",
            "132:\tlearn: 0.1527418\ttotal: 3.45s\tremaining: 22.5s\n",
            "133:\tlearn: 0.1525583\ttotal: 3.47s\tremaining: 22.4s\n",
            "134:\tlearn: 0.1522289\ttotal: 3.5s\tremaining: 22.4s\n",
            "135:\tlearn: 0.1518769\ttotal: 3.52s\tremaining: 22.4s\n",
            "136:\tlearn: 0.1516126\ttotal: 3.55s\tremaining: 22.4s\n",
            "137:\tlearn: 0.1513166\ttotal: 3.57s\tremaining: 22.3s\n",
            "138:\tlearn: 0.1507851\ttotal: 3.6s\tremaining: 22.3s\n",
            "139:\tlearn: 0.1504192\ttotal: 3.63s\tremaining: 22.3s\n",
            "140:\tlearn: 0.1501193\ttotal: 3.65s\tremaining: 22.2s\n",
            "141:\tlearn: 0.1496028\ttotal: 3.67s\tremaining: 22.2s\n",
            "142:\tlearn: 0.1491685\ttotal: 3.7s\tremaining: 22.2s\n",
            "143:\tlearn: 0.1490154\ttotal: 3.72s\tremaining: 22.1s\n",
            "144:\tlearn: 0.1487202\ttotal: 3.75s\tremaining: 22.1s\n",
            "145:\tlearn: 0.1484471\ttotal: 3.77s\tremaining: 22.1s\n",
            "146:\tlearn: 0.1480068\ttotal: 3.8s\tremaining: 22.1s\n",
            "147:\tlearn: 0.1472951\ttotal: 3.83s\tremaining: 22s\n",
            "148:\tlearn: 0.1469031\ttotal: 3.85s\tremaining: 22s\n",
            "149:\tlearn: 0.1464621\ttotal: 3.88s\tremaining: 22s\n",
            "150:\tlearn: 0.1461867\ttotal: 3.91s\tremaining: 22s\n",
            "151:\tlearn: 0.1459746\ttotal: 3.97s\tremaining: 22.2s\n",
            "152:\tlearn: 0.1456772\ttotal: 4.02s\tremaining: 22.2s\n",
            "153:\tlearn: 0.1454506\ttotal: 4.08s\tremaining: 22.4s\n",
            "154:\tlearn: 0.1451348\ttotal: 4.14s\tremaining: 22.6s\n",
            "155:\tlearn: 0.1448361\ttotal: 4.2s\tremaining: 22.7s\n",
            "156:\tlearn: 0.1443087\ttotal: 4.28s\tremaining: 23s\n",
            "157:\tlearn: 0.1439481\ttotal: 4.31s\tremaining: 23s\n",
            "158:\tlearn: 0.1435649\ttotal: 4.34s\tremaining: 23s\n",
            "159:\tlearn: 0.1432628\ttotal: 4.39s\tremaining: 23s\n",
            "160:\tlearn: 0.1431067\ttotal: 4.45s\tremaining: 23.2s\n",
            "161:\tlearn: 0.1427120\ttotal: 4.53s\tremaining: 23.4s\n",
            "162:\tlearn: 0.1425419\ttotal: 4.56s\tremaining: 23.4s\n",
            "163:\tlearn: 0.1423253\ttotal: 4.59s\tremaining: 23.4s\n",
            "164:\tlearn: 0.1422021\ttotal: 4.64s\tremaining: 23.5s\n",
            "165:\tlearn: 0.1419004\ttotal: 4.7s\tremaining: 23.6s\n",
            "166:\tlearn: 0.1415705\ttotal: 4.77s\tremaining: 23.8s\n",
            "167:\tlearn: 0.1413265\ttotal: 4.83s\tremaining: 23.9s\n",
            "168:\tlearn: 0.1411146\ttotal: 4.89s\tremaining: 24.1s\n",
            "169:\tlearn: 0.1409094\ttotal: 4.95s\tremaining: 24.2s\n",
            "170:\tlearn: 0.1407642\ttotal: 5.02s\tremaining: 24.3s\n",
            "171:\tlearn: 0.1404198\ttotal: 5.07s\tremaining: 24.4s\n",
            "172:\tlearn: 0.1401437\ttotal: 5.13s\tremaining: 24.5s\n",
            "173:\tlearn: 0.1398067\ttotal: 5.18s\tremaining: 24.6s\n",
            "174:\tlearn: 0.1395118\ttotal: 5.25s\tremaining: 24.7s\n",
            "175:\tlearn: 0.1392141\ttotal: 5.3s\tremaining: 24.8s\n",
            "176:\tlearn: 0.1388552\ttotal: 5.36s\tremaining: 24.9s\n",
            "177:\tlearn: 0.1387212\ttotal: 5.42s\tremaining: 25s\n",
            "178:\tlearn: 0.1384614\ttotal: 5.49s\tremaining: 25.2s\n",
            "179:\tlearn: 0.1382389\ttotal: 5.52s\tremaining: 25.2s\n",
            "180:\tlearn: 0.1379931\ttotal: 5.58s\tremaining: 25.3s\n",
            "181:\tlearn: 0.1376534\ttotal: 5.66s\tremaining: 25.4s\n",
            "182:\tlearn: 0.1373900\ttotal: 5.73s\tremaining: 25.6s\n",
            "183:\tlearn: 0.1372022\ttotal: 5.78s\tremaining: 25.6s\n",
            "184:\tlearn: 0.1369957\ttotal: 5.84s\tremaining: 25.7s\n",
            "185:\tlearn: 0.1367533\ttotal: 5.9s\tremaining: 25.8s\n",
            "186:\tlearn: 0.1364568\ttotal: 5.97s\tremaining: 26s\n",
            "187:\tlearn: 0.1362098\ttotal: 6.04s\tremaining: 26.1s\n",
            "188:\tlearn: 0.1360392\ttotal: 6.1s\tremaining: 26.2s\n",
            "189:\tlearn: 0.1358715\ttotal: 6.16s\tremaining: 26.3s\n",
            "190:\tlearn: 0.1356702\ttotal: 6.23s\tremaining: 26.4s\n",
            "191:\tlearn: 0.1353730\ttotal: 6.3s\tremaining: 26.5s\n",
            "192:\tlearn: 0.1350870\ttotal: 6.36s\tremaining: 26.6s\n",
            "193:\tlearn: 0.1347639\ttotal: 6.4s\tremaining: 26.6s\n",
            "194:\tlearn: 0.1344956\ttotal: 6.46s\tremaining: 26.7s\n",
            "195:\tlearn: 0.1342636\ttotal: 6.53s\tremaining: 26.8s\n",
            "196:\tlearn: 0.1340222\ttotal: 6.6s\tremaining: 26.9s\n",
            "197:\tlearn: 0.1338236\ttotal: 6.67s\tremaining: 27s\n",
            "198:\tlearn: 0.1335225\ttotal: 6.74s\tremaining: 27.1s\n",
            "199:\tlearn: 0.1333584\ttotal: 6.8s\tremaining: 27.2s\n",
            "200:\tlearn: 0.1331061\ttotal: 6.86s\tremaining: 27.3s\n",
            "201:\tlearn: 0.1329759\ttotal: 6.92s\tremaining: 27.3s\n",
            "202:\tlearn: 0.1328488\ttotal: 6.98s\tremaining: 27.4s\n",
            "203:\tlearn: 0.1326205\ttotal: 7.03s\tremaining: 27.4s\n",
            "204:\tlearn: 0.1324727\ttotal: 7.06s\tremaining: 27.4s\n",
            "205:\tlearn: 0.1322881\ttotal: 7.08s\tremaining: 27.3s\n",
            "206:\tlearn: 0.1320744\ttotal: 7.11s\tremaining: 27.2s\n",
            "207:\tlearn: 0.1318404\ttotal: 7.14s\tremaining: 27.2s\n",
            "208:\tlearn: 0.1317054\ttotal: 7.16s\tremaining: 27.1s\n",
            "209:\tlearn: 0.1315044\ttotal: 7.19s\tremaining: 27s\n",
            "210:\tlearn: 0.1313361\ttotal: 7.21s\tremaining: 27s\n",
            "211:\tlearn: 0.1311131\ttotal: 7.23s\tremaining: 26.9s\n",
            "212:\tlearn: 0.1309381\ttotal: 7.26s\tremaining: 26.8s\n",
            "213:\tlearn: 0.1307193\ttotal: 7.29s\tremaining: 26.8s\n",
            "214:\tlearn: 0.1305870\ttotal: 7.32s\tremaining: 26.7s\n",
            "215:\tlearn: 0.1303221\ttotal: 7.35s\tremaining: 26.7s\n",
            "216:\tlearn: 0.1300960\ttotal: 7.37s\tremaining: 26.6s\n",
            "217:\tlearn: 0.1298749\ttotal: 7.4s\tremaining: 26.5s\n",
            "218:\tlearn: 0.1295849\ttotal: 7.43s\tremaining: 26.5s\n",
            "219:\tlearn: 0.1293942\ttotal: 7.45s\tremaining: 26.4s\n",
            "220:\tlearn: 0.1292283\ttotal: 7.48s\tremaining: 26.4s\n",
            "221:\tlearn: 0.1290803\ttotal: 7.5s\tremaining: 26.3s\n",
            "222:\tlearn: 0.1287661\ttotal: 7.53s\tremaining: 26.2s\n",
            "223:\tlearn: 0.1285332\ttotal: 7.56s\tremaining: 26.2s\n",
            "224:\tlearn: 0.1282867\ttotal: 7.58s\tremaining: 26.1s\n",
            "225:\tlearn: 0.1280709\ttotal: 7.61s\tremaining: 26.1s\n",
            "226:\tlearn: 0.1279218\ttotal: 7.63s\tremaining: 26s\n",
            "227:\tlearn: 0.1277684\ttotal: 7.66s\tremaining: 25.9s\n",
            "228:\tlearn: 0.1275794\ttotal: 7.68s\tremaining: 25.9s\n",
            "229:\tlearn: 0.1273380\ttotal: 7.71s\tremaining: 25.8s\n",
            "230:\tlearn: 0.1271879\ttotal: 7.74s\tremaining: 25.8s\n",
            "231:\tlearn: 0.1270300\ttotal: 7.77s\tremaining: 25.7s\n",
            "232:\tlearn: 0.1268920\ttotal: 7.79s\tremaining: 25.7s\n",
            "233:\tlearn: 0.1266518\ttotal: 7.82s\tremaining: 25.6s\n",
            "234:\tlearn: 0.1264823\ttotal: 7.85s\tremaining: 25.5s\n",
            "235:\tlearn: 0.1263746\ttotal: 7.87s\tremaining: 25.5s\n",
            "236:\tlearn: 0.1262372\ttotal: 7.89s\tremaining: 25.4s\n",
            "237:\tlearn: 0.1260224\ttotal: 7.92s\tremaining: 25.4s\n",
            "238:\tlearn: 0.1259219\ttotal: 7.94s\tremaining: 25.3s\n",
            "239:\tlearn: 0.1258201\ttotal: 7.97s\tremaining: 25.2s\n",
            "240:\tlearn: 0.1256396\ttotal: 8s\tremaining: 25.2s\n",
            "241:\tlearn: 0.1254341\ttotal: 8.02s\tremaining: 25.1s\n",
            "242:\tlearn: 0.1252808\ttotal: 8.04s\tremaining: 25.1s\n",
            "243:\tlearn: 0.1250168\ttotal: 8.07s\tremaining: 25s\n",
            "244:\tlearn: 0.1248139\ttotal: 8.1s\tremaining: 24.9s\n",
            "245:\tlearn: 0.1246762\ttotal: 8.12s\tremaining: 24.9s\n",
            "246:\tlearn: 0.1245021\ttotal: 8.14s\tremaining: 24.8s\n",
            "247:\tlearn: 0.1242966\ttotal: 8.17s\tremaining: 24.8s\n",
            "248:\tlearn: 0.1241430\ttotal: 8.2s\tremaining: 24.7s\n",
            "249:\tlearn: 0.1240169\ttotal: 8.22s\tremaining: 24.7s\n",
            "250:\tlearn: 0.1238860\ttotal: 8.25s\tremaining: 24.6s\n",
            "251:\tlearn: 0.1237707\ttotal: 8.28s\tremaining: 24.6s\n",
            "252:\tlearn: 0.1236290\ttotal: 8.31s\tremaining: 24.5s\n",
            "253:\tlearn: 0.1235103\ttotal: 8.34s\tremaining: 24.5s\n",
            "254:\tlearn: 0.1233036\ttotal: 8.36s\tremaining: 24.4s\n",
            "255:\tlearn: 0.1231555\ttotal: 8.39s\tremaining: 24.4s\n",
            "256:\tlearn: 0.1230102\ttotal: 8.42s\tremaining: 24.3s\n",
            "257:\tlearn: 0.1228366\ttotal: 8.45s\tremaining: 24.3s\n",
            "258:\tlearn: 0.1226642\ttotal: 8.47s\tremaining: 24.2s\n",
            "259:\tlearn: 0.1225379\ttotal: 8.49s\tremaining: 24.2s\n",
            "260:\tlearn: 0.1224245\ttotal: 8.52s\tremaining: 24.1s\n",
            "261:\tlearn: 0.1223148\ttotal: 8.54s\tremaining: 24.1s\n",
            "262:\tlearn: 0.1220304\ttotal: 8.57s\tremaining: 24s\n",
            "263:\tlearn: 0.1219363\ttotal: 8.59s\tremaining: 24s\n",
            "264:\tlearn: 0.1218361\ttotal: 8.62s\tremaining: 23.9s\n",
            "265:\tlearn: 0.1217534\ttotal: 8.64s\tremaining: 23.8s\n",
            "266:\tlearn: 0.1216613\ttotal: 8.66s\tremaining: 23.8s\n",
            "267:\tlearn: 0.1215410\ttotal: 8.69s\tremaining: 23.7s\n",
            "268:\tlearn: 0.1214099\ttotal: 8.71s\tremaining: 23.7s\n",
            "269:\tlearn: 0.1212763\ttotal: 8.74s\tremaining: 23.6s\n",
            "270:\tlearn: 0.1211794\ttotal: 8.76s\tremaining: 23.6s\n",
            "271:\tlearn: 0.1210452\ttotal: 8.79s\tremaining: 23.5s\n",
            "272:\tlearn: 0.1209086\ttotal: 8.82s\tremaining: 23.5s\n",
            "273:\tlearn: 0.1207987\ttotal: 8.84s\tremaining: 23.4s\n",
            "274:\tlearn: 0.1206603\ttotal: 8.87s\tremaining: 23.4s\n",
            "275:\tlearn: 0.1205658\ttotal: 8.89s\tremaining: 23.3s\n",
            "276:\tlearn: 0.1204617\ttotal: 8.91s\tremaining: 23.3s\n",
            "277:\tlearn: 0.1202957\ttotal: 8.94s\tremaining: 23.2s\n",
            "278:\tlearn: 0.1202046\ttotal: 8.96s\tremaining: 23.2s\n",
            "279:\tlearn: 0.1201048\ttotal: 8.99s\tremaining: 23.1s\n",
            "280:\tlearn: 0.1200289\ttotal: 9.02s\tremaining: 23.1s\n",
            "281:\tlearn: 0.1198869\ttotal: 9.05s\tremaining: 23s\n",
            "282:\tlearn: 0.1197341\ttotal: 9.08s\tremaining: 23s\n",
            "283:\tlearn: 0.1195633\ttotal: 9.1s\tremaining: 23s\n",
            "284:\tlearn: 0.1194097\ttotal: 9.13s\tremaining: 22.9s\n",
            "285:\tlearn: 0.1192962\ttotal: 9.15s\tremaining: 22.8s\n",
            "286:\tlearn: 0.1191979\ttotal: 9.18s\tremaining: 22.8s\n",
            "287:\tlearn: 0.1190459\ttotal: 9.2s\tremaining: 22.8s\n",
            "288:\tlearn: 0.1188566\ttotal: 9.23s\tremaining: 22.7s\n",
            "289:\tlearn: 0.1187085\ttotal: 9.26s\tremaining: 22.7s\n",
            "290:\tlearn: 0.1185268\ttotal: 9.28s\tremaining: 22.6s\n",
            "291:\tlearn: 0.1184264\ttotal: 9.32s\tremaining: 22.6s\n",
            "292:\tlearn: 0.1181764\ttotal: 9.34s\tremaining: 22.5s\n",
            "293:\tlearn: 0.1180696\ttotal: 9.37s\tremaining: 22.5s\n",
            "294:\tlearn: 0.1179258\ttotal: 9.39s\tremaining: 22.4s\n",
            "295:\tlearn: 0.1178420\ttotal: 9.42s\tremaining: 22.4s\n",
            "296:\tlearn: 0.1177394\ttotal: 9.45s\tremaining: 22.4s\n",
            "297:\tlearn: 0.1176486\ttotal: 9.47s\tremaining: 22.3s\n",
            "298:\tlearn: 0.1175634\ttotal: 9.49s\tremaining: 22.3s\n",
            "299:\tlearn: 0.1173526\ttotal: 9.53s\tremaining: 22.2s\n",
            "300:\tlearn: 0.1172941\ttotal: 9.55s\tremaining: 22.2s\n",
            "301:\tlearn: 0.1172295\ttotal: 9.57s\tremaining: 22.1s\n",
            "302:\tlearn: 0.1171606\ttotal: 9.6s\tremaining: 22.1s\n",
            "303:\tlearn: 0.1170585\ttotal: 9.62s\tremaining: 22s\n",
            "304:\tlearn: 0.1169446\ttotal: 9.65s\tremaining: 22s\n",
            "305:\tlearn: 0.1168064\ttotal: 9.67s\tremaining: 21.9s\n",
            "306:\tlearn: 0.1166580\ttotal: 9.7s\tremaining: 21.9s\n",
            "307:\tlearn: 0.1165858\ttotal: 9.72s\tremaining: 21.8s\n",
            "308:\tlearn: 0.1165089\ttotal: 9.75s\tremaining: 21.8s\n",
            "309:\tlearn: 0.1164220\ttotal: 9.77s\tremaining: 21.7s\n",
            "310:\tlearn: 0.1163536\ttotal: 9.79s\tremaining: 21.7s\n",
            "311:\tlearn: 0.1162526\ttotal: 9.82s\tremaining: 21.7s\n",
            "312:\tlearn: 0.1161652\ttotal: 9.84s\tremaining: 21.6s\n",
            "313:\tlearn: 0.1161154\ttotal: 9.87s\tremaining: 21.6s\n",
            "314:\tlearn: 0.1160322\ttotal: 9.9s\tremaining: 21.5s\n",
            "315:\tlearn: 0.1159599\ttotal: 9.92s\tremaining: 21.5s\n",
            "316:\tlearn: 0.1158291\ttotal: 9.94s\tremaining: 21.4s\n",
            "317:\tlearn: 0.1156857\ttotal: 9.97s\tremaining: 21.4s\n",
            "318:\tlearn: 0.1155139\ttotal: 9.99s\tremaining: 21.3s\n",
            "319:\tlearn: 0.1154229\ttotal: 10s\tremaining: 21.3s\n",
            "320:\tlearn: 0.1151955\ttotal: 10.1s\tremaining: 21.3s\n",
            "321:\tlearn: 0.1151189\ttotal: 10.1s\tremaining: 21.2s\n",
            "322:\tlearn: 0.1150262\ttotal: 10.1s\tremaining: 21.2s\n",
            "323:\tlearn: 0.1149309\ttotal: 10.1s\tremaining: 21.1s\n",
            "324:\tlearn: 0.1148482\ttotal: 10.2s\tremaining: 21.1s\n",
            "325:\tlearn: 0.1147198\ttotal: 10.2s\tremaining: 21.1s\n",
            "326:\tlearn: 0.1146416\ttotal: 10.2s\tremaining: 21s\n",
            "327:\tlearn: 0.1144898\ttotal: 10.2s\tremaining: 21s\n",
            "328:\tlearn: 0.1142943\ttotal: 10.3s\tremaining: 20.9s\n",
            "329:\tlearn: 0.1141670\ttotal: 10.3s\tremaining: 20.9s\n",
            "330:\tlearn: 0.1140273\ttotal: 10.3s\tremaining: 20.9s\n",
            "331:\tlearn: 0.1137884\ttotal: 10.4s\tremaining: 20.8s\n",
            "332:\tlearn: 0.1137378\ttotal: 10.4s\tremaining: 20.8s\n",
            "333:\tlearn: 0.1135370\ttotal: 10.4s\tremaining: 20.8s\n",
            "334:\tlearn: 0.1133715\ttotal: 10.4s\tremaining: 20.7s\n",
            "335:\tlearn: 0.1132065\ttotal: 10.5s\tremaining: 20.7s\n",
            "336:\tlearn: 0.1130808\ttotal: 10.5s\tremaining: 20.6s\n",
            "337:\tlearn: 0.1129604\ttotal: 10.5s\tremaining: 20.6s\n",
            "338:\tlearn: 0.1128602\ttotal: 10.5s\tremaining: 20.6s\n",
            "339:\tlearn: 0.1127081\ttotal: 10.6s\tremaining: 20.5s\n",
            "340:\tlearn: 0.1125632\ttotal: 10.6s\tremaining: 20.5s\n",
            "341:\tlearn: 0.1124605\ttotal: 10.6s\tremaining: 20.4s\n",
            "342:\tlearn: 0.1123710\ttotal: 10.6s\tremaining: 20.4s\n",
            "343:\tlearn: 0.1122815\ttotal: 10.7s\tremaining: 20.4s\n",
            "344:\tlearn: 0.1121811\ttotal: 10.7s\tremaining: 20.3s\n",
            "345:\tlearn: 0.1120987\ttotal: 10.7s\tremaining: 20.3s\n",
            "346:\tlearn: 0.1120468\ttotal: 10.8s\tremaining: 20.2s\n",
            "347:\tlearn: 0.1120025\ttotal: 10.8s\tremaining: 20.2s\n",
            "348:\tlearn: 0.1119439\ttotal: 10.8s\tremaining: 20.1s\n",
            "349:\tlearn: 0.1119131\ttotal: 10.8s\tremaining: 20.1s\n",
            "350:\tlearn: 0.1118467\ttotal: 10.8s\tremaining: 20.1s\n",
            "351:\tlearn: 0.1116387\ttotal: 10.9s\tremaining: 20s\n",
            "352:\tlearn: 0.1115615\ttotal: 10.9s\tremaining: 20s\n",
            "353:\tlearn: 0.1114672\ttotal: 10.9s\tremaining: 19.9s\n",
            "354:\tlearn: 0.1113590\ttotal: 10.9s\tremaining: 19.9s\n",
            "355:\tlearn: 0.1112708\ttotal: 11s\tremaining: 19.9s\n",
            "356:\tlearn: 0.1111287\ttotal: 11s\tremaining: 19.8s\n",
            "357:\tlearn: 0.1110661\ttotal: 11s\tremaining: 19.8s\n",
            "358:\tlearn: 0.1109987\ttotal: 11.1s\tremaining: 19.8s\n",
            "359:\tlearn: 0.1109015\ttotal: 11.1s\tremaining: 19.7s\n",
            "360:\tlearn: 0.1108321\ttotal: 11.1s\tremaining: 19.7s\n",
            "361:\tlearn: 0.1107354\ttotal: 11.1s\tremaining: 19.6s\n",
            "362:\tlearn: 0.1106868\ttotal: 11.2s\tremaining: 19.6s\n",
            "363:\tlearn: 0.1106089\ttotal: 11.2s\tremaining: 19.6s\n",
            "364:\tlearn: 0.1105232\ttotal: 11.2s\tremaining: 19.5s\n",
            "365:\tlearn: 0.1103564\ttotal: 11.3s\tremaining: 19.5s\n",
            "366:\tlearn: 0.1102785\ttotal: 11.3s\tremaining: 19.5s\n",
            "367:\tlearn: 0.1102290\ttotal: 11.3s\tremaining: 19.4s\n",
            "368:\tlearn: 0.1101407\ttotal: 11.3s\tremaining: 19.4s\n",
            "369:\tlearn: 0.1100105\ttotal: 11.4s\tremaining: 19.4s\n",
            "370:\tlearn: 0.1099377\ttotal: 11.4s\tremaining: 19.3s\n",
            "371:\tlearn: 0.1098562\ttotal: 11.4s\tremaining: 19.3s\n",
            "372:\tlearn: 0.1097839\ttotal: 11.4s\tremaining: 19.2s\n",
            "373:\tlearn: 0.1096986\ttotal: 11.5s\tremaining: 19.2s\n",
            "374:\tlearn: 0.1095867\ttotal: 11.5s\tremaining: 19.2s\n",
            "375:\tlearn: 0.1094062\ttotal: 11.5s\tremaining: 19.1s\n",
            "376:\tlearn: 0.1092907\ttotal: 11.5s\tremaining: 19.1s\n",
            "377:\tlearn: 0.1092059\ttotal: 11.6s\tremaining: 19s\n",
            "378:\tlearn: 0.1091637\ttotal: 11.6s\tremaining: 19s\n",
            "379:\tlearn: 0.1090573\ttotal: 11.6s\tremaining: 19s\n",
            "380:\tlearn: 0.1089937\ttotal: 11.7s\tremaining: 18.9s\n",
            "381:\tlearn: 0.1089347\ttotal: 11.7s\tremaining: 18.9s\n",
            "382:\tlearn: 0.1088292\ttotal: 11.7s\tremaining: 18.9s\n",
            "383:\tlearn: 0.1086557\ttotal: 11.7s\tremaining: 18.8s\n",
            "384:\tlearn: 0.1084933\ttotal: 11.8s\tremaining: 18.8s\n",
            "385:\tlearn: 0.1084043\ttotal: 11.8s\tremaining: 18.7s\n",
            "386:\tlearn: 0.1082989\ttotal: 11.8s\tremaining: 18.7s\n",
            "387:\tlearn: 0.1081833\ttotal: 11.8s\tremaining: 18.7s\n",
            "388:\tlearn: 0.1081328\ttotal: 11.9s\tremaining: 18.6s\n",
            "389:\tlearn: 0.1080961\ttotal: 11.9s\tremaining: 18.6s\n",
            "390:\tlearn: 0.1080366\ttotal: 11.9s\tremaining: 18.6s\n",
            "391:\tlearn: 0.1079775\ttotal: 11.9s\tremaining: 18.5s\n",
            "392:\tlearn: 0.1079307\ttotal: 12s\tremaining: 18.5s\n",
            "393:\tlearn: 0.1078412\ttotal: 12s\tremaining: 18.4s\n",
            "394:\tlearn: 0.1077819\ttotal: 12s\tremaining: 18.4s\n",
            "395:\tlearn: 0.1077001\ttotal: 12s\tremaining: 18.4s\n",
            "396:\tlearn: 0.1076479\ttotal: 12.1s\tremaining: 18.3s\n",
            "397:\tlearn: 0.1076065\ttotal: 12.1s\tremaining: 18.3s\n",
            "398:\tlearn: 0.1075557\ttotal: 12.1s\tremaining: 18.2s\n",
            "399:\tlearn: 0.1075263\ttotal: 12.1s\tremaining: 18.2s\n",
            "400:\tlearn: 0.1074282\ttotal: 12.2s\tremaining: 18.2s\n",
            "401:\tlearn: 0.1073803\ttotal: 12.2s\tremaining: 18.1s\n",
            "402:\tlearn: 0.1072842\ttotal: 12.2s\tremaining: 18.1s\n",
            "403:\tlearn: 0.1071829\ttotal: 12.2s\tremaining: 18.1s\n",
            "404:\tlearn: 0.1071237\ttotal: 12.3s\tremaining: 18s\n",
            "405:\tlearn: 0.1070228\ttotal: 12.3s\tremaining: 18s\n",
            "406:\tlearn: 0.1068686\ttotal: 12.3s\tremaining: 18s\n",
            "407:\tlearn: 0.1067760\ttotal: 12.4s\tremaining: 17.9s\n",
            "408:\tlearn: 0.1067218\ttotal: 12.4s\tremaining: 17.9s\n",
            "409:\tlearn: 0.1066593\ttotal: 12.4s\tremaining: 17.8s\n",
            "410:\tlearn: 0.1065395\ttotal: 12.4s\tremaining: 17.8s\n",
            "411:\tlearn: 0.1064856\ttotal: 12.5s\tremaining: 17.8s\n",
            "412:\tlearn: 0.1063868\ttotal: 12.5s\tremaining: 17.7s\n",
            "413:\tlearn: 0.1062945\ttotal: 12.5s\tremaining: 17.7s\n",
            "414:\tlearn: 0.1061899\ttotal: 12.5s\tremaining: 17.7s\n",
            "415:\tlearn: 0.1061472\ttotal: 12.6s\tremaining: 17.6s\n",
            "416:\tlearn: 0.1060727\ttotal: 12.6s\tremaining: 17.6s\n",
            "417:\tlearn: 0.1059869\ttotal: 12.6s\tremaining: 17.5s\n",
            "418:\tlearn: 0.1059026\ttotal: 12.6s\tremaining: 17.5s\n",
            "419:\tlearn: 0.1058529\ttotal: 12.7s\tremaining: 17.5s\n",
            "420:\tlearn: 0.1058155\ttotal: 12.7s\tremaining: 17.4s\n",
            "421:\tlearn: 0.1057308\ttotal: 12.7s\tremaining: 17.4s\n",
            "422:\tlearn: 0.1056543\ttotal: 12.7s\tremaining: 17.4s\n",
            "423:\tlearn: 0.1055888\ttotal: 12.8s\tremaining: 17.3s\n",
            "424:\tlearn: 0.1055524\ttotal: 12.8s\tremaining: 17.3s\n",
            "425:\tlearn: 0.1054762\ttotal: 12.8s\tremaining: 17.3s\n",
            "426:\tlearn: 0.1054119\ttotal: 12.8s\tremaining: 17.2s\n",
            "427:\tlearn: 0.1053212\ttotal: 12.9s\tremaining: 17.2s\n",
            "428:\tlearn: 0.1052664\ttotal: 12.9s\tremaining: 17.2s\n",
            "429:\tlearn: 0.1051919\ttotal: 12.9s\tremaining: 17.1s\n",
            "430:\tlearn: 0.1051444\ttotal: 12.9s\tremaining: 17.1s\n",
            "431:\tlearn: 0.1050674\ttotal: 13s\tremaining: 17.1s\n",
            "432:\tlearn: 0.1049770\ttotal: 13s\tremaining: 17s\n",
            "433:\tlearn: 0.1049599\ttotal: 13s\tremaining: 17s\n",
            "434:\tlearn: 0.1049051\ttotal: 13.1s\tremaining: 17s\n",
            "435:\tlearn: 0.1048419\ttotal: 13.1s\tremaining: 16.9s\n",
            "436:\tlearn: 0.1047951\ttotal: 13.1s\tremaining: 16.9s\n",
            "437:\tlearn: 0.1046803\ttotal: 13.1s\tremaining: 16.8s\n",
            "438:\tlearn: 0.1046035\ttotal: 13.2s\tremaining: 16.8s\n",
            "439:\tlearn: 0.1045732\ttotal: 13.2s\tremaining: 16.8s\n",
            "440:\tlearn: 0.1045220\ttotal: 13.2s\tremaining: 16.7s\n",
            "441:\tlearn: 0.1044842\ttotal: 13.2s\tremaining: 16.7s\n",
            "442:\tlearn: 0.1044275\ttotal: 13.3s\tremaining: 16.7s\n",
            "443:\tlearn: 0.1043919\ttotal: 13.3s\tremaining: 16.6s\n",
            "444:\tlearn: 0.1043025\ttotal: 13.3s\tremaining: 16.6s\n",
            "445:\tlearn: 0.1041936\ttotal: 13.3s\tremaining: 16.6s\n",
            "446:\tlearn: 0.1041209\ttotal: 13.4s\tremaining: 16.5s\n",
            "447:\tlearn: 0.1040650\ttotal: 13.4s\tremaining: 16.5s\n",
            "448:\tlearn: 0.1040188\ttotal: 13.4s\tremaining: 16.5s\n",
            "449:\tlearn: 0.1039682\ttotal: 13.4s\tremaining: 16.4s\n",
            "450:\tlearn: 0.1038985\ttotal: 13.5s\tremaining: 16.4s\n",
            "451:\tlearn: 0.1038300\ttotal: 13.5s\tremaining: 16.4s\n",
            "452:\tlearn: 0.1037814\ttotal: 13.5s\tremaining: 16.3s\n",
            "453:\tlearn: 0.1037014\ttotal: 13.5s\tremaining: 16.3s\n",
            "454:\tlearn: 0.1036596\ttotal: 13.6s\tremaining: 16.2s\n",
            "455:\tlearn: 0.1036269\ttotal: 13.6s\tremaining: 16.2s\n",
            "456:\tlearn: 0.1035005\ttotal: 13.6s\tremaining: 16.2s\n",
            "457:\tlearn: 0.1034655\ttotal: 13.6s\tremaining: 16.1s\n",
            "458:\tlearn: 0.1033900\ttotal: 13.7s\tremaining: 16.1s\n",
            "459:\tlearn: 0.1033256\ttotal: 13.7s\tremaining: 16.1s\n",
            "460:\tlearn: 0.1032756\ttotal: 13.7s\tremaining: 16s\n",
            "461:\tlearn: 0.1032139\ttotal: 13.7s\tremaining: 16s\n",
            "462:\tlearn: 0.1031181\ttotal: 13.8s\tremaining: 16s\n",
            "463:\tlearn: 0.1030600\ttotal: 13.8s\tremaining: 15.9s\n",
            "464:\tlearn: 0.1030260\ttotal: 13.8s\tremaining: 15.9s\n",
            "465:\tlearn: 0.1029618\ttotal: 13.9s\tremaining: 15.9s\n",
            "466:\tlearn: 0.1029189\ttotal: 13.9s\tremaining: 15.8s\n",
            "467:\tlearn: 0.1028660\ttotal: 13.9s\tremaining: 15.8s\n",
            "468:\tlearn: 0.1028268\ttotal: 13.9s\tremaining: 15.8s\n",
            "469:\tlearn: 0.1028007\ttotal: 14s\tremaining: 15.7s\n",
            "470:\tlearn: 0.1027542\ttotal: 14s\tremaining: 15.7s\n",
            "471:\tlearn: 0.1027305\ttotal: 14s\tremaining: 15.7s\n",
            "472:\tlearn: 0.1026606\ttotal: 14s\tremaining: 15.6s\n",
            "473:\tlearn: 0.1026180\ttotal: 14.1s\tremaining: 15.6s\n",
            "474:\tlearn: 0.1025765\ttotal: 14.1s\tremaining: 15.6s\n",
            "475:\tlearn: 0.1025573\ttotal: 14.1s\tremaining: 15.5s\n",
            "476:\tlearn: 0.1024999\ttotal: 14.1s\tremaining: 15.5s\n",
            "477:\tlearn: 0.1024385\ttotal: 14.2s\tremaining: 15.5s\n",
            "478:\tlearn: 0.1023999\ttotal: 14.2s\tremaining: 15.4s\n",
            "479:\tlearn: 0.1023518\ttotal: 14.2s\tremaining: 15.4s\n",
            "480:\tlearn: 0.1023160\ttotal: 14.2s\tremaining: 15.4s\n",
            "481:\tlearn: 0.1022639\ttotal: 14.3s\tremaining: 15.3s\n",
            "482:\tlearn: 0.1022096\ttotal: 14.3s\tremaining: 15.3s\n",
            "483:\tlearn: 0.1021702\ttotal: 14.3s\tremaining: 15.3s\n",
            "484:\tlearn: 0.1021069\ttotal: 14.3s\tremaining: 15.2s\n",
            "485:\tlearn: 0.1020424\ttotal: 14.4s\tremaining: 15.2s\n",
            "486:\tlearn: 0.1019950\ttotal: 14.4s\tremaining: 15.2s\n",
            "487:\tlearn: 0.1019722\ttotal: 14.4s\tremaining: 15.1s\n",
            "488:\tlearn: 0.1019320\ttotal: 14.4s\tremaining: 15.1s\n",
            "489:\tlearn: 0.1018924\ttotal: 14.5s\tremaining: 15.1s\n",
            "490:\tlearn: 0.1018514\ttotal: 14.5s\tremaining: 15s\n",
            "491:\tlearn: 0.1018135\ttotal: 14.5s\tremaining: 15s\n",
            "492:\tlearn: 0.1017532\ttotal: 14.5s\tremaining: 15s\n",
            "493:\tlearn: 0.1017036\ttotal: 14.6s\tremaining: 14.9s\n",
            "494:\tlearn: 0.1016523\ttotal: 14.6s\tremaining: 14.9s\n",
            "495:\tlearn: 0.1016124\ttotal: 14.6s\tremaining: 14.9s\n",
            "496:\tlearn: 0.1015556\ttotal: 14.6s\tremaining: 14.8s\n",
            "497:\tlearn: 0.1015120\ttotal: 14.7s\tremaining: 14.8s\n",
            "498:\tlearn: 0.1014494\ttotal: 14.7s\tremaining: 14.8s\n",
            "499:\tlearn: 0.1014043\ttotal: 14.7s\tremaining: 14.7s\n",
            "500:\tlearn: 0.1013722\ttotal: 14.8s\tremaining: 14.7s\n",
            "501:\tlearn: 0.1013205\ttotal: 14.8s\tremaining: 14.7s\n",
            "502:\tlearn: 0.1012655\ttotal: 14.8s\tremaining: 14.6s\n",
            "503:\tlearn: 0.1012074\ttotal: 14.8s\tremaining: 14.6s\n",
            "504:\tlearn: 0.1011520\ttotal: 14.9s\tremaining: 14.6s\n",
            "505:\tlearn: 0.1010928\ttotal: 14.9s\tremaining: 14.5s\n",
            "506:\tlearn: 0.1010613\ttotal: 14.9s\tremaining: 14.5s\n",
            "507:\tlearn: 0.1010241\ttotal: 14.9s\tremaining: 14.5s\n",
            "508:\tlearn: 0.1009868\ttotal: 15s\tremaining: 14.4s\n",
            "509:\tlearn: 0.1009377\ttotal: 15s\tremaining: 14.4s\n",
            "510:\tlearn: 0.1008956\ttotal: 15s\tremaining: 14.4s\n",
            "511:\tlearn: 0.1008410\ttotal: 15s\tremaining: 14.3s\n",
            "512:\tlearn: 0.1008035\ttotal: 15.1s\tremaining: 14.3s\n",
            "513:\tlearn: 0.1007488\ttotal: 15.1s\tremaining: 14.3s\n",
            "514:\tlearn: 0.1006786\ttotal: 15.1s\tremaining: 14.2s\n",
            "515:\tlearn: 0.1006146\ttotal: 15.1s\tremaining: 14.2s\n",
            "516:\tlearn: 0.1005660\ttotal: 15.2s\tremaining: 14.2s\n",
            "517:\tlearn: 0.1005019\ttotal: 15.2s\tremaining: 14.1s\n",
            "518:\tlearn: 0.1004316\ttotal: 15.2s\tremaining: 14.1s\n",
            "519:\tlearn: 0.1004187\ttotal: 15.2s\tremaining: 14.1s\n",
            "520:\tlearn: 0.1003891\ttotal: 15.3s\tremaining: 14s\n",
            "521:\tlearn: 0.1003316\ttotal: 15.3s\tremaining: 14s\n",
            "522:\tlearn: 0.1002899\ttotal: 15.3s\tremaining: 14s\n",
            "523:\tlearn: 0.1002045\ttotal: 15.4s\tremaining: 14s\n",
            "524:\tlearn: 0.1001335\ttotal: 15.4s\tremaining: 13.9s\n",
            "525:\tlearn: 0.1000901\ttotal: 15.4s\tremaining: 13.9s\n",
            "526:\tlearn: 0.1000664\ttotal: 15.4s\tremaining: 13.9s\n",
            "527:\tlearn: 0.1000108\ttotal: 15.5s\tremaining: 13.8s\n",
            "528:\tlearn: 0.0999400\ttotal: 15.5s\tremaining: 13.8s\n",
            "529:\tlearn: 0.0999061\ttotal: 15.5s\tremaining: 13.8s\n",
            "530:\tlearn: 0.0998714\ttotal: 15.5s\tremaining: 13.7s\n",
            "531:\tlearn: 0.0998265\ttotal: 15.6s\tremaining: 13.7s\n",
            "532:\tlearn: 0.0997817\ttotal: 15.6s\tremaining: 13.7s\n",
            "533:\tlearn: 0.0997190\ttotal: 15.6s\tremaining: 13.6s\n",
            "534:\tlearn: 0.0997021\ttotal: 15.6s\tremaining: 13.6s\n",
            "535:\tlearn: 0.0996591\ttotal: 15.7s\tremaining: 13.6s\n",
            "536:\tlearn: 0.0996377\ttotal: 15.7s\tremaining: 13.5s\n",
            "537:\tlearn: 0.0995956\ttotal: 15.7s\tremaining: 13.5s\n",
            "538:\tlearn: 0.0995653\ttotal: 15.7s\tremaining: 13.5s\n",
            "539:\tlearn: 0.0995326\ttotal: 15.8s\tremaining: 13.5s\n",
            "540:\tlearn: 0.0994782\ttotal: 15.8s\tremaining: 13.4s\n",
            "541:\tlearn: 0.0994358\ttotal: 15.9s\tremaining: 13.4s\n",
            "542:\tlearn: 0.0993445\ttotal: 15.9s\tremaining: 13.4s\n",
            "543:\tlearn: 0.0992927\ttotal: 16s\tremaining: 13.4s\n",
            "544:\tlearn: 0.0992375\ttotal: 16s\tremaining: 13.4s\n",
            "545:\tlearn: 0.0992197\ttotal: 16s\tremaining: 13.3s\n",
            "546:\tlearn: 0.0991225\ttotal: 16.1s\tremaining: 13.3s\n",
            "547:\tlearn: 0.0990653\ttotal: 16.1s\tremaining: 13.3s\n",
            "548:\tlearn: 0.0990510\ttotal: 16.1s\tremaining: 13.3s\n",
            "549:\tlearn: 0.0990056\ttotal: 16.2s\tremaining: 13.2s\n",
            "550:\tlearn: 0.0989684\ttotal: 16.3s\tremaining: 13.2s\n",
            "551:\tlearn: 0.0989469\ttotal: 16.3s\tremaining: 13.2s\n",
            "552:\tlearn: 0.0989109\ttotal: 16.4s\tremaining: 13.2s\n",
            "553:\tlearn: 0.0988809\ttotal: 16.4s\tremaining: 13.2s\n",
            "554:\tlearn: 0.0988620\ttotal: 16.5s\tremaining: 13.2s\n",
            "555:\tlearn: 0.0988095\ttotal: 16.5s\tremaining: 13.2s\n",
            "556:\tlearn: 0.0987513\ttotal: 16.5s\tremaining: 13.1s\n",
            "557:\tlearn: 0.0986940\ttotal: 16.5s\tremaining: 13.1s\n",
            "558:\tlearn: 0.0986625\ttotal: 16.6s\tremaining: 13.1s\n",
            "559:\tlearn: 0.0986128\ttotal: 16.6s\tremaining: 13s\n",
            "560:\tlearn: 0.0985683\ttotal: 16.6s\tremaining: 13s\n",
            "561:\tlearn: 0.0985285\ttotal: 16.6s\tremaining: 13s\n",
            "562:\tlearn: 0.0984688\ttotal: 16.7s\tremaining: 12.9s\n",
            "563:\tlearn: 0.0984364\ttotal: 16.7s\tremaining: 12.9s\n",
            "564:\tlearn: 0.0983716\ttotal: 16.7s\tremaining: 12.9s\n",
            "565:\tlearn: 0.0983367\ttotal: 16.7s\tremaining: 12.8s\n",
            "566:\tlearn: 0.0982342\ttotal: 16.8s\tremaining: 12.8s\n",
            "567:\tlearn: 0.0982199\ttotal: 16.8s\tremaining: 12.8s\n",
            "568:\tlearn: 0.0981846\ttotal: 16.8s\tremaining: 12.7s\n",
            "569:\tlearn: 0.0981752\ttotal: 16.8s\tremaining: 12.7s\n",
            "570:\tlearn: 0.0981415\ttotal: 16.9s\tremaining: 12.7s\n",
            "571:\tlearn: 0.0981033\ttotal: 16.9s\tremaining: 12.6s\n",
            "572:\tlearn: 0.0980186\ttotal: 16.9s\tremaining: 12.6s\n",
            "573:\tlearn: 0.0979853\ttotal: 17s\tremaining: 12.6s\n",
            "574:\tlearn: 0.0979576\ttotal: 17s\tremaining: 12.6s\n",
            "575:\tlearn: 0.0979187\ttotal: 17.1s\tremaining: 12.6s\n",
            "576:\tlearn: 0.0978809\ttotal: 17.2s\tremaining: 12.6s\n",
            "577:\tlearn: 0.0978286\ttotal: 17.2s\tremaining: 12.6s\n",
            "578:\tlearn: 0.0978022\ttotal: 17.3s\tremaining: 12.6s\n",
            "579:\tlearn: 0.0977791\ttotal: 17.3s\tremaining: 12.6s\n",
            "580:\tlearn: 0.0977308\ttotal: 17.4s\tremaining: 12.6s\n",
            "581:\tlearn: 0.0976637\ttotal: 17.5s\tremaining: 12.5s\n",
            "582:\tlearn: 0.0976307\ttotal: 17.5s\tremaining: 12.5s\n",
            "583:\tlearn: 0.0975759\ttotal: 17.6s\tremaining: 12.5s\n",
            "584:\tlearn: 0.0975377\ttotal: 17.7s\tremaining: 12.5s\n",
            "585:\tlearn: 0.0975044\ttotal: 17.7s\tremaining: 12.5s\n",
            "586:\tlearn: 0.0974805\ttotal: 17.8s\tremaining: 12.5s\n",
            "587:\tlearn: 0.0974261\ttotal: 17.9s\tremaining: 12.5s\n",
            "588:\tlearn: 0.0973997\ttotal: 17.9s\tremaining: 12.5s\n",
            "589:\tlearn: 0.0973759\ttotal: 18s\tremaining: 12.5s\n",
            "590:\tlearn: 0.0973200\ttotal: 18s\tremaining: 12.5s\n",
            "591:\tlearn: 0.0972525\ttotal: 18.1s\tremaining: 12.4s\n",
            "592:\tlearn: 0.0972313\ttotal: 18.1s\tremaining: 12.4s\n",
            "593:\tlearn: 0.0971884\ttotal: 18.2s\tremaining: 12.4s\n",
            "594:\tlearn: 0.0971170\ttotal: 18.2s\tremaining: 12.4s\n",
            "595:\tlearn: 0.0970889\ttotal: 18.3s\tremaining: 12.4s\n",
            "596:\tlearn: 0.0970591\ttotal: 18.4s\tremaining: 12.4s\n",
            "597:\tlearn: 0.0970212\ttotal: 18.4s\tremaining: 12.4s\n",
            "598:\tlearn: 0.0969724\ttotal: 18.5s\tremaining: 12.4s\n",
            "599:\tlearn: 0.0969494\ttotal: 18.6s\tremaining: 12.4s\n",
            "600:\tlearn: 0.0969376\ttotal: 18.6s\tremaining: 12.4s\n",
            "601:\tlearn: 0.0968985\ttotal: 18.7s\tremaining: 12.3s\n",
            "602:\tlearn: 0.0968138\ttotal: 18.7s\tremaining: 12.3s\n",
            "603:\tlearn: 0.0967955\ttotal: 18.8s\tremaining: 12.3s\n",
            "604:\tlearn: 0.0967584\ttotal: 18.9s\tremaining: 12.3s\n",
            "605:\tlearn: 0.0967353\ttotal: 18.9s\tremaining: 12.3s\n",
            "606:\tlearn: 0.0966917\ttotal: 19s\tremaining: 12.3s\n",
            "607:\tlearn: 0.0966391\ttotal: 19s\tremaining: 12.3s\n",
            "608:\tlearn: 0.0966111\ttotal: 19.1s\tremaining: 12.2s\n",
            "609:\tlearn: 0.0965567\ttotal: 19.1s\tremaining: 12.2s\n",
            "610:\tlearn: 0.0964941\ttotal: 19.2s\tremaining: 12.2s\n",
            "611:\tlearn: 0.0964327\ttotal: 19.3s\tremaining: 12.2s\n",
            "612:\tlearn: 0.0964052\ttotal: 19.3s\tremaining: 12.2s\n",
            "613:\tlearn: 0.0963597\ttotal: 19.4s\tremaining: 12.2s\n",
            "614:\tlearn: 0.0963279\ttotal: 19.5s\tremaining: 12.2s\n",
            "615:\tlearn: 0.0963029\ttotal: 19.5s\tremaining: 12.2s\n",
            "616:\tlearn: 0.0962649\ttotal: 19.6s\tremaining: 12.1s\n",
            "617:\tlearn: 0.0962011\ttotal: 19.6s\tremaining: 12.1s\n",
            "618:\tlearn: 0.0961803\ttotal: 19.7s\tremaining: 12.1s\n",
            "619:\tlearn: 0.0961530\ttotal: 19.7s\tremaining: 12.1s\n",
            "620:\tlearn: 0.0960855\ttotal: 19.8s\tremaining: 12.1s\n",
            "621:\tlearn: 0.0960590\ttotal: 19.9s\tremaining: 12.1s\n",
            "622:\tlearn: 0.0960146\ttotal: 19.9s\tremaining: 12s\n",
            "623:\tlearn: 0.0960003\ttotal: 19.9s\tremaining: 12s\n",
            "624:\tlearn: 0.0959611\ttotal: 20s\tremaining: 12s\n",
            "625:\tlearn: 0.0959226\ttotal: 20s\tremaining: 11.9s\n",
            "626:\tlearn: 0.0958989\ttotal: 20s\tremaining: 11.9s\n",
            "627:\tlearn: 0.0958737\ttotal: 20s\tremaining: 11.9s\n",
            "628:\tlearn: 0.0958404\ttotal: 20.1s\tremaining: 11.8s\n",
            "629:\tlearn: 0.0958060\ttotal: 20.1s\tremaining: 11.8s\n",
            "630:\tlearn: 0.0957898\ttotal: 20.1s\tremaining: 11.8s\n",
            "631:\tlearn: 0.0957484\ttotal: 20.1s\tremaining: 11.7s\n",
            "632:\tlearn: 0.0957243\ttotal: 20.2s\tremaining: 11.7s\n",
            "633:\tlearn: 0.0956570\ttotal: 20.2s\tremaining: 11.7s\n",
            "634:\tlearn: 0.0956251\ttotal: 20.2s\tremaining: 11.6s\n",
            "635:\tlearn: 0.0955847\ttotal: 20.2s\tremaining: 11.6s\n",
            "636:\tlearn: 0.0955352\ttotal: 20.3s\tremaining: 11.5s\n",
            "637:\tlearn: 0.0954905\ttotal: 20.3s\tremaining: 11.5s\n",
            "638:\tlearn: 0.0954565\ttotal: 20.3s\tremaining: 11.5s\n",
            "639:\tlearn: 0.0954257\ttotal: 20.3s\tremaining: 11.4s\n",
            "640:\tlearn: 0.0953636\ttotal: 20.4s\tremaining: 11.4s\n",
            "641:\tlearn: 0.0953253\ttotal: 20.4s\tremaining: 11.4s\n",
            "642:\tlearn: 0.0953110\ttotal: 20.4s\tremaining: 11.3s\n",
            "643:\tlearn: 0.0952824\ttotal: 20.5s\tremaining: 11.3s\n",
            "644:\tlearn: 0.0952631\ttotal: 20.5s\tremaining: 11.3s\n",
            "645:\tlearn: 0.0952294\ttotal: 20.5s\tremaining: 11.2s\n",
            "646:\tlearn: 0.0952083\ttotal: 20.5s\tremaining: 11.2s\n",
            "647:\tlearn: 0.0951948\ttotal: 20.6s\tremaining: 11.2s\n",
            "648:\tlearn: 0.0951513\ttotal: 20.6s\tremaining: 11.1s\n",
            "649:\tlearn: 0.0950727\ttotal: 20.6s\tremaining: 11.1s\n",
            "650:\tlearn: 0.0950328\ttotal: 20.6s\tremaining: 11.1s\n",
            "651:\tlearn: 0.0949998\ttotal: 20.7s\tremaining: 11s\n",
            "652:\tlearn: 0.0949660\ttotal: 20.7s\tremaining: 11s\n",
            "653:\tlearn: 0.0949430\ttotal: 20.7s\tremaining: 11s\n",
            "654:\tlearn: 0.0949033\ttotal: 20.7s\tremaining: 10.9s\n",
            "655:\tlearn: 0.0948875\ttotal: 20.8s\tremaining: 10.9s\n",
            "656:\tlearn: 0.0948565\ttotal: 20.8s\tremaining: 10.8s\n",
            "657:\tlearn: 0.0948254\ttotal: 20.8s\tremaining: 10.8s\n",
            "658:\tlearn: 0.0947851\ttotal: 20.8s\tremaining: 10.8s\n",
            "659:\tlearn: 0.0947400\ttotal: 20.9s\tremaining: 10.7s\n",
            "660:\tlearn: 0.0947001\ttotal: 20.9s\tremaining: 10.7s\n",
            "661:\tlearn: 0.0946529\ttotal: 20.9s\tremaining: 10.7s\n",
            "662:\tlearn: 0.0946075\ttotal: 20.9s\tremaining: 10.6s\n",
            "663:\tlearn: 0.0945671\ttotal: 21s\tremaining: 10.6s\n",
            "664:\tlearn: 0.0945360\ttotal: 21s\tremaining: 10.6s\n",
            "665:\tlearn: 0.0944901\ttotal: 21s\tremaining: 10.5s\n",
            "666:\tlearn: 0.0944357\ttotal: 21s\tremaining: 10.5s\n",
            "667:\tlearn: 0.0944050\ttotal: 21.1s\tremaining: 10.5s\n",
            "668:\tlearn: 0.0943628\ttotal: 21.1s\tremaining: 10.4s\n",
            "669:\tlearn: 0.0943340\ttotal: 21.1s\tremaining: 10.4s\n",
            "670:\tlearn: 0.0942940\ttotal: 21.1s\tremaining: 10.4s\n",
            "671:\tlearn: 0.0942505\ttotal: 21.2s\tremaining: 10.3s\n",
            "672:\tlearn: 0.0942264\ttotal: 21.2s\tremaining: 10.3s\n",
            "673:\tlearn: 0.0941831\ttotal: 21.2s\tremaining: 10.3s\n",
            "674:\tlearn: 0.0941228\ttotal: 21.3s\tremaining: 10.2s\n",
            "675:\tlearn: 0.0940997\ttotal: 21.3s\tremaining: 10.2s\n",
            "676:\tlearn: 0.0940857\ttotal: 21.3s\tremaining: 10.2s\n",
            "677:\tlearn: 0.0940619\ttotal: 21.3s\tremaining: 10.1s\n",
            "678:\tlearn: 0.0940403\ttotal: 21.4s\tremaining: 10.1s\n",
            "679:\tlearn: 0.0940085\ttotal: 21.4s\tremaining: 10.1s\n",
            "680:\tlearn: 0.0939758\ttotal: 21.4s\tremaining: 10s\n",
            "681:\tlearn: 0.0939559\ttotal: 21.4s\tremaining: 9.99s\n",
            "682:\tlearn: 0.0939388\ttotal: 21.5s\tremaining: 9.97s\n",
            "683:\tlearn: 0.0939260\ttotal: 21.5s\tremaining: 9.93s\n",
            "684:\tlearn: 0.0938950\ttotal: 21.5s\tremaining: 9.9s\n",
            "685:\tlearn: 0.0938788\ttotal: 21.6s\tremaining: 9.86s\n",
            "686:\tlearn: 0.0938119\ttotal: 21.6s\tremaining: 9.83s\n",
            "687:\tlearn: 0.0937995\ttotal: 21.6s\tremaining: 9.8s\n",
            "688:\tlearn: 0.0937888\ttotal: 21.6s\tremaining: 9.76s\n",
            "689:\tlearn: 0.0937491\ttotal: 21.7s\tremaining: 9.73s\n",
            "690:\tlearn: 0.0937186\ttotal: 21.7s\tremaining: 9.69s\n",
            "691:\tlearn: 0.0936897\ttotal: 21.7s\tremaining: 9.66s\n",
            "692:\tlearn: 0.0936609\ttotal: 21.7s\tremaining: 9.63s\n",
            "693:\tlearn: 0.0936429\ttotal: 21.8s\tremaining: 9.6s\n",
            "694:\tlearn: 0.0936051\ttotal: 21.8s\tremaining: 9.56s\n",
            "695:\tlearn: 0.0935520\ttotal: 21.8s\tremaining: 9.53s\n",
            "696:\tlearn: 0.0935132\ttotal: 21.8s\tremaining: 9.49s\n",
            "697:\tlearn: 0.0934721\ttotal: 21.9s\tremaining: 9.46s\n",
            "698:\tlearn: 0.0934505\ttotal: 21.9s\tremaining: 9.43s\n",
            "699:\tlearn: 0.0934318\ttotal: 21.9s\tremaining: 9.39s\n",
            "700:\tlearn: 0.0933872\ttotal: 21.9s\tremaining: 9.36s\n",
            "701:\tlearn: 0.0933576\ttotal: 22s\tremaining: 9.33s\n",
            "702:\tlearn: 0.0933353\ttotal: 22s\tremaining: 9.29s\n",
            "703:\tlearn: 0.0933123\ttotal: 22s\tremaining: 9.26s\n",
            "704:\tlearn: 0.0933069\ttotal: 22s\tremaining: 9.22s\n",
            "705:\tlearn: 0.0932804\ttotal: 22.1s\tremaining: 9.19s\n",
            "706:\tlearn: 0.0932579\ttotal: 22.1s\tremaining: 9.15s\n",
            "707:\tlearn: 0.0932066\ttotal: 22.1s\tremaining: 9.12s\n",
            "708:\tlearn: 0.0931862\ttotal: 22.1s\tremaining: 9.09s\n",
            "709:\tlearn: 0.0931003\ttotal: 22.2s\tremaining: 9.06s\n",
            "710:\tlearn: 0.0930872\ttotal: 22.2s\tremaining: 9.02s\n",
            "711:\tlearn: 0.0930697\ttotal: 22.2s\tremaining: 8.99s\n",
            "712:\tlearn: 0.0930454\ttotal: 22.2s\tremaining: 8.95s\n",
            "713:\tlearn: 0.0930191\ttotal: 22.3s\tremaining: 8.92s\n",
            "714:\tlearn: 0.0929626\ttotal: 22.3s\tremaining: 8.89s\n",
            "715:\tlearn: 0.0929204\ttotal: 22.3s\tremaining: 8.86s\n",
            "716:\tlearn: 0.0928920\ttotal: 22.4s\tremaining: 8.82s\n",
            "717:\tlearn: 0.0928291\ttotal: 22.4s\tremaining: 8.79s\n",
            "718:\tlearn: 0.0928046\ttotal: 22.4s\tremaining: 8.76s\n",
            "719:\tlearn: 0.0927423\ttotal: 22.4s\tremaining: 8.73s\n",
            "720:\tlearn: 0.0927210\ttotal: 22.5s\tremaining: 8.69s\n",
            "721:\tlearn: 0.0927026\ttotal: 22.5s\tremaining: 8.66s\n",
            "722:\tlearn: 0.0926743\ttotal: 22.5s\tremaining: 8.63s\n",
            "723:\tlearn: 0.0926537\ttotal: 22.5s\tremaining: 8.59s\n",
            "724:\tlearn: 0.0926286\ttotal: 22.6s\tremaining: 8.56s\n",
            "725:\tlearn: 0.0926222\ttotal: 22.6s\tremaining: 8.53s\n",
            "726:\tlearn: 0.0926017\ttotal: 22.6s\tremaining: 8.49s\n",
            "727:\tlearn: 0.0925706\ttotal: 22.6s\tremaining: 8.46s\n",
            "728:\tlearn: 0.0925290\ttotal: 22.7s\tremaining: 8.43s\n",
            "729:\tlearn: 0.0925086\ttotal: 22.7s\tremaining: 8.39s\n",
            "730:\tlearn: 0.0924872\ttotal: 22.7s\tremaining: 8.36s\n",
            "731:\tlearn: 0.0924678\ttotal: 22.7s\tremaining: 8.33s\n",
            "732:\tlearn: 0.0924319\ttotal: 22.8s\tremaining: 8.29s\n",
            "733:\tlearn: 0.0924059\ttotal: 22.8s\tremaining: 8.26s\n",
            "734:\tlearn: 0.0923949\ttotal: 22.8s\tremaining: 8.23s\n",
            "735:\tlearn: 0.0923569\ttotal: 22.8s\tremaining: 8.2s\n",
            "736:\tlearn: 0.0923152\ttotal: 22.9s\tremaining: 8.16s\n",
            "737:\tlearn: 0.0922792\ttotal: 22.9s\tremaining: 8.13s\n",
            "738:\tlearn: 0.0922523\ttotal: 22.9s\tremaining: 8.1s\n",
            "739:\tlearn: 0.0922294\ttotal: 23s\tremaining: 8.06s\n",
            "740:\tlearn: 0.0921978\ttotal: 23s\tremaining: 8.03s\n",
            "741:\tlearn: 0.0921737\ttotal: 23s\tremaining: 8s\n",
            "742:\tlearn: 0.0921633\ttotal: 23s\tremaining: 7.96s\n",
            "743:\tlearn: 0.0921399\ttotal: 23.1s\tremaining: 7.93s\n",
            "744:\tlearn: 0.0921159\ttotal: 23.1s\tremaining: 7.9s\n",
            "745:\tlearn: 0.0920931\ttotal: 23.1s\tremaining: 7.87s\n",
            "746:\tlearn: 0.0920696\ttotal: 23.1s\tremaining: 7.84s\n",
            "747:\tlearn: 0.0920556\ttotal: 23.2s\tremaining: 7.8s\n",
            "748:\tlearn: 0.0920316\ttotal: 23.2s\tremaining: 7.77s\n",
            "749:\tlearn: 0.0919989\ttotal: 23.2s\tremaining: 7.74s\n",
            "750:\tlearn: 0.0919886\ttotal: 23.2s\tremaining: 7.7s\n",
            "751:\tlearn: 0.0919519\ttotal: 23.3s\tremaining: 7.67s\n",
            "752:\tlearn: 0.0919198\ttotal: 23.3s\tremaining: 7.64s\n",
            "753:\tlearn: 0.0919117\ttotal: 23.3s\tremaining: 7.61s\n",
            "754:\tlearn: 0.0918773\ttotal: 23.3s\tremaining: 7.57s\n",
            "755:\tlearn: 0.0918507\ttotal: 23.4s\tremaining: 7.54s\n",
            "756:\tlearn: 0.0918427\ttotal: 23.4s\tremaining: 7.51s\n",
            "757:\tlearn: 0.0918297\ttotal: 23.4s\tremaining: 7.48s\n",
            "758:\tlearn: 0.0918109\ttotal: 23.5s\tremaining: 7.45s\n",
            "759:\tlearn: 0.0917904\ttotal: 23.5s\tremaining: 7.42s\n",
            "760:\tlearn: 0.0917683\ttotal: 23.5s\tremaining: 7.38s\n",
            "761:\tlearn: 0.0917376\ttotal: 23.5s\tremaining: 7.35s\n",
            "762:\tlearn: 0.0917189\ttotal: 23.6s\tremaining: 7.32s\n",
            "763:\tlearn: 0.0917058\ttotal: 23.6s\tremaining: 7.29s\n",
            "764:\tlearn: 0.0916917\ttotal: 23.6s\tremaining: 7.25s\n",
            "765:\tlearn: 0.0916575\ttotal: 23.6s\tremaining: 7.22s\n",
            "766:\tlearn: 0.0916159\ttotal: 23.7s\tremaining: 7.19s\n",
            "767:\tlearn: 0.0915937\ttotal: 23.7s\tremaining: 7.16s\n",
            "768:\tlearn: 0.0915681\ttotal: 23.7s\tremaining: 7.12s\n",
            "769:\tlearn: 0.0915590\ttotal: 23.7s\tremaining: 7.09s\n",
            "770:\tlearn: 0.0915204\ttotal: 23.8s\tremaining: 7.06s\n",
            "771:\tlearn: 0.0914979\ttotal: 23.8s\tremaining: 7.03s\n",
            "772:\tlearn: 0.0914774\ttotal: 23.8s\tremaining: 7s\n",
            "773:\tlearn: 0.0914581\ttotal: 23.9s\tremaining: 6.96s\n",
            "774:\tlearn: 0.0914437\ttotal: 23.9s\tremaining: 6.93s\n",
            "775:\tlearn: 0.0913936\ttotal: 23.9s\tremaining: 6.9s\n",
            "776:\tlearn: 0.0913529\ttotal: 23.9s\tremaining: 6.87s\n",
            "777:\tlearn: 0.0913337\ttotal: 24s\tremaining: 6.83s\n",
            "778:\tlearn: 0.0913085\ttotal: 24s\tremaining: 6.8s\n",
            "779:\tlearn: 0.0912555\ttotal: 24s\tremaining: 6.77s\n",
            "780:\tlearn: 0.0912361\ttotal: 24s\tremaining: 6.74s\n",
            "781:\tlearn: 0.0911898\ttotal: 24.1s\tremaining: 6.71s\n",
            "782:\tlearn: 0.0911747\ttotal: 24.1s\tremaining: 6.67s\n",
            "783:\tlearn: 0.0911483\ttotal: 24.1s\tremaining: 6.64s\n",
            "784:\tlearn: 0.0911145\ttotal: 24.1s\tremaining: 6.61s\n",
            "785:\tlearn: 0.0911073\ttotal: 24.2s\tremaining: 6.58s\n",
            "786:\tlearn: 0.0910976\ttotal: 24.2s\tremaining: 6.55s\n",
            "787:\tlearn: 0.0910661\ttotal: 24.2s\tremaining: 6.51s\n",
            "788:\tlearn: 0.0910439\ttotal: 24.2s\tremaining: 6.48s\n",
            "789:\tlearn: 0.0910219\ttotal: 24.3s\tremaining: 6.45s\n",
            "790:\tlearn: 0.0910167\ttotal: 24.3s\tremaining: 6.42s\n",
            "791:\tlearn: 0.0909876\ttotal: 24.3s\tremaining: 6.38s\n",
            "792:\tlearn: 0.0909631\ttotal: 24.3s\tremaining: 6.35s\n",
            "793:\tlearn: 0.0909402\ttotal: 24.4s\tremaining: 6.32s\n",
            "794:\tlearn: 0.0909153\ttotal: 24.4s\tremaining: 6.29s\n",
            "795:\tlearn: 0.0908931\ttotal: 24.4s\tremaining: 6.26s\n",
            "796:\tlearn: 0.0908808\ttotal: 24.4s\tremaining: 6.23s\n",
            "797:\tlearn: 0.0908622\ttotal: 24.5s\tremaining: 6.19s\n",
            "798:\tlearn: 0.0908509\ttotal: 24.5s\tremaining: 6.16s\n",
            "799:\tlearn: 0.0908358\ttotal: 24.5s\tremaining: 6.13s\n",
            "800:\tlearn: 0.0908197\ttotal: 24.5s\tremaining: 6.1s\n",
            "801:\tlearn: 0.0907884\ttotal: 24.6s\tremaining: 6.07s\n",
            "802:\tlearn: 0.0907699\ttotal: 24.6s\tremaining: 6.03s\n",
            "803:\tlearn: 0.0907469\ttotal: 24.6s\tremaining: 6s\n",
            "804:\tlearn: 0.0907244\ttotal: 24.6s\tremaining: 5.97s\n",
            "805:\tlearn: 0.0906901\ttotal: 24.7s\tremaining: 5.94s\n",
            "806:\tlearn: 0.0906832\ttotal: 24.7s\tremaining: 5.91s\n",
            "807:\tlearn: 0.0906595\ttotal: 24.7s\tremaining: 5.88s\n",
            "808:\tlearn: 0.0906435\ttotal: 24.8s\tremaining: 5.84s\n",
            "809:\tlearn: 0.0906192\ttotal: 24.8s\tremaining: 5.81s\n",
            "810:\tlearn: 0.0905551\ttotal: 24.8s\tremaining: 5.78s\n",
            "811:\tlearn: 0.0905462\ttotal: 24.8s\tremaining: 5.75s\n",
            "812:\tlearn: 0.0905329\ttotal: 24.9s\tremaining: 5.72s\n",
            "813:\tlearn: 0.0905173\ttotal: 24.9s\tremaining: 5.68s\n",
            "814:\tlearn: 0.0904875\ttotal: 24.9s\tremaining: 5.65s\n",
            "815:\tlearn: 0.0904685\ttotal: 24.9s\tremaining: 5.62s\n",
            "816:\tlearn: 0.0904504\ttotal: 25s\tremaining: 5.59s\n",
            "817:\tlearn: 0.0904417\ttotal: 25s\tremaining: 5.56s\n",
            "818:\tlearn: 0.0904223\ttotal: 25s\tremaining: 5.53s\n",
            "819:\tlearn: 0.0904097\ttotal: 25s\tremaining: 5.5s\n",
            "820:\tlearn: 0.0903804\ttotal: 25.1s\tremaining: 5.46s\n",
            "821:\tlearn: 0.0903391\ttotal: 25.1s\tremaining: 5.43s\n",
            "822:\tlearn: 0.0903185\ttotal: 25.1s\tremaining: 5.4s\n",
            "823:\tlearn: 0.0902971\ttotal: 25.1s\tremaining: 5.37s\n",
            "824:\tlearn: 0.0902810\ttotal: 25.2s\tremaining: 5.34s\n",
            "825:\tlearn: 0.0902572\ttotal: 25.2s\tremaining: 5.31s\n",
            "826:\tlearn: 0.0902288\ttotal: 25.2s\tremaining: 5.28s\n",
            "827:\tlearn: 0.0902039\ttotal: 25.3s\tremaining: 5.25s\n",
            "828:\tlearn: 0.0901873\ttotal: 25.3s\tremaining: 5.21s\n",
            "829:\tlearn: 0.0901776\ttotal: 25.3s\tremaining: 5.18s\n",
            "830:\tlearn: 0.0901651\ttotal: 25.3s\tremaining: 5.15s\n",
            "831:\tlearn: 0.0901482\ttotal: 25.4s\tremaining: 5.12s\n",
            "832:\tlearn: 0.0901056\ttotal: 25.4s\tremaining: 5.09s\n",
            "833:\tlearn: 0.0900856\ttotal: 25.4s\tremaining: 5.06s\n",
            "834:\tlearn: 0.0900773\ttotal: 25.4s\tremaining: 5.03s\n",
            "835:\tlearn: 0.0900421\ttotal: 25.5s\tremaining: 5s\n",
            "836:\tlearn: 0.0900266\ttotal: 25.5s\tremaining: 4.96s\n",
            "837:\tlearn: 0.0900058\ttotal: 25.5s\tremaining: 4.93s\n",
            "838:\tlearn: 0.0899891\ttotal: 25.5s\tremaining: 4.9s\n",
            "839:\tlearn: 0.0899713\ttotal: 25.6s\tremaining: 4.87s\n",
            "840:\tlearn: 0.0899620\ttotal: 25.6s\tremaining: 4.84s\n",
            "841:\tlearn: 0.0899570\ttotal: 25.6s\tremaining: 4.81s\n",
            "842:\tlearn: 0.0899241\ttotal: 25.6s\tremaining: 4.78s\n",
            "843:\tlearn: 0.0899143\ttotal: 25.7s\tremaining: 4.74s\n",
            "844:\tlearn: 0.0898928\ttotal: 25.7s\tremaining: 4.71s\n",
            "845:\tlearn: 0.0898743\ttotal: 25.7s\tremaining: 4.68s\n",
            "846:\tlearn: 0.0898579\ttotal: 25.7s\tremaining: 4.65s\n",
            "847:\tlearn: 0.0898292\ttotal: 25.8s\tremaining: 4.62s\n",
            "848:\tlearn: 0.0898042\ttotal: 25.8s\tremaining: 4.59s\n",
            "849:\tlearn: 0.0897888\ttotal: 25.8s\tremaining: 4.56s\n",
            "850:\tlearn: 0.0897716\ttotal: 25.8s\tremaining: 4.53s\n",
            "851:\tlearn: 0.0897532\ttotal: 25.9s\tremaining: 4.49s\n",
            "852:\tlearn: 0.0897158\ttotal: 25.9s\tremaining: 4.46s\n",
            "853:\tlearn: 0.0896654\ttotal: 25.9s\tremaining: 4.43s\n",
            "854:\tlearn: 0.0896506\ttotal: 26s\tremaining: 4.4s\n",
            "855:\tlearn: 0.0896333\ttotal: 26s\tremaining: 4.37s\n",
            "856:\tlearn: 0.0896098\ttotal: 26s\tremaining: 4.34s\n",
            "857:\tlearn: 0.0895963\ttotal: 26s\tremaining: 4.31s\n",
            "858:\tlearn: 0.0895887\ttotal: 26.1s\tremaining: 4.28s\n",
            "859:\tlearn: 0.0895814\ttotal: 26.1s\tremaining: 4.25s\n",
            "860:\tlearn: 0.0895578\ttotal: 26.1s\tremaining: 4.21s\n",
            "861:\tlearn: 0.0895458\ttotal: 26.1s\tremaining: 4.18s\n",
            "862:\tlearn: 0.0895312\ttotal: 26.2s\tremaining: 4.15s\n",
            "863:\tlearn: 0.0895112\ttotal: 26.2s\tremaining: 4.12s\n",
            "864:\tlearn: 0.0895080\ttotal: 26.2s\tremaining: 4.09s\n",
            "865:\tlearn: 0.0894330\ttotal: 26.2s\tremaining: 4.06s\n",
            "866:\tlearn: 0.0894237\ttotal: 26.3s\tremaining: 4.03s\n",
            "867:\tlearn: 0.0893886\ttotal: 26.3s\tremaining: 4s\n",
            "868:\tlearn: 0.0893826\ttotal: 26.3s\tremaining: 3.97s\n",
            "869:\tlearn: 0.0893394\ttotal: 26.3s\tremaining: 3.94s\n",
            "870:\tlearn: 0.0893263\ttotal: 26.4s\tremaining: 3.9s\n",
            "871:\tlearn: 0.0893025\ttotal: 26.4s\tremaining: 3.87s\n",
            "872:\tlearn: 0.0892904\ttotal: 26.4s\tremaining: 3.84s\n",
            "873:\tlearn: 0.0892832\ttotal: 26.4s\tremaining: 3.81s\n",
            "874:\tlearn: 0.0892745\ttotal: 26.5s\tremaining: 3.78s\n",
            "875:\tlearn: 0.0892612\ttotal: 26.5s\tremaining: 3.75s\n",
            "876:\tlearn: 0.0892419\ttotal: 26.5s\tremaining: 3.72s\n",
            "877:\tlearn: 0.0892347\ttotal: 26.5s\tremaining: 3.69s\n",
            "878:\tlearn: 0.0892161\ttotal: 26.6s\tremaining: 3.66s\n",
            "879:\tlearn: 0.0891948\ttotal: 26.6s\tremaining: 3.63s\n",
            "880:\tlearn: 0.0891903\ttotal: 26.6s\tremaining: 3.6s\n",
            "881:\tlearn: 0.0891781\ttotal: 26.6s\tremaining: 3.56s\n",
            "882:\tlearn: 0.0891665\ttotal: 26.7s\tremaining: 3.53s\n",
            "883:\tlearn: 0.0891401\ttotal: 26.7s\tremaining: 3.5s\n",
            "884:\tlearn: 0.0891242\ttotal: 26.7s\tremaining: 3.47s\n",
            "885:\tlearn: 0.0890993\ttotal: 26.8s\tremaining: 3.44s\n",
            "886:\tlearn: 0.0890749\ttotal: 26.8s\tremaining: 3.41s\n",
            "887:\tlearn: 0.0890561\ttotal: 26.8s\tremaining: 3.38s\n",
            "888:\tlearn: 0.0890392\ttotal: 26.8s\tremaining: 3.35s\n",
            "889:\tlearn: 0.0890238\ttotal: 26.9s\tremaining: 3.32s\n",
            "890:\tlearn: 0.0890049\ttotal: 26.9s\tremaining: 3.29s\n",
            "891:\tlearn: 0.0889739\ttotal: 26.9s\tremaining: 3.26s\n",
            "892:\tlearn: 0.0889599\ttotal: 26.9s\tremaining: 3.23s\n",
            "893:\tlearn: 0.0889390\ttotal: 27s\tremaining: 3.2s\n",
            "894:\tlearn: 0.0889190\ttotal: 27s\tremaining: 3.17s\n",
            "895:\tlearn: 0.0888938\ttotal: 27s\tremaining: 3.14s\n",
            "896:\tlearn: 0.0888389\ttotal: 27s\tremaining: 3.1s\n",
            "897:\tlearn: 0.0888269\ttotal: 27.1s\tremaining: 3.07s\n",
            "898:\tlearn: 0.0888228\ttotal: 27.1s\tremaining: 3.04s\n",
            "899:\tlearn: 0.0888043\ttotal: 27.1s\tremaining: 3.01s\n",
            "900:\tlearn: 0.0887781\ttotal: 27.1s\tremaining: 2.98s\n",
            "901:\tlearn: 0.0887532\ttotal: 27.2s\tremaining: 2.95s\n",
            "902:\tlearn: 0.0887228\ttotal: 27.2s\tremaining: 2.92s\n",
            "903:\tlearn: 0.0887026\ttotal: 27.2s\tremaining: 2.89s\n",
            "904:\tlearn: 0.0886944\ttotal: 27.2s\tremaining: 2.86s\n",
            "905:\tlearn: 0.0886771\ttotal: 27.3s\tremaining: 2.83s\n",
            "906:\tlearn: 0.0886645\ttotal: 27.3s\tremaining: 2.8s\n",
            "907:\tlearn: 0.0886418\ttotal: 27.3s\tremaining: 2.77s\n",
            "908:\tlearn: 0.0886164\ttotal: 27.3s\tremaining: 2.74s\n",
            "909:\tlearn: 0.0886020\ttotal: 27.4s\tremaining: 2.71s\n",
            "910:\tlearn: 0.0885958\ttotal: 27.4s\tremaining: 2.68s\n",
            "911:\tlearn: 0.0885835\ttotal: 27.4s\tremaining: 2.65s\n",
            "912:\tlearn: 0.0885746\ttotal: 27.5s\tremaining: 2.62s\n",
            "913:\tlearn: 0.0885691\ttotal: 27.5s\tremaining: 2.58s\n",
            "914:\tlearn: 0.0885589\ttotal: 27.5s\tremaining: 2.56s\n",
            "915:\tlearn: 0.0885466\ttotal: 27.5s\tremaining: 2.52s\n",
            "916:\tlearn: 0.0885414\ttotal: 27.6s\tremaining: 2.49s\n",
            "917:\tlearn: 0.0885327\ttotal: 27.6s\tremaining: 2.46s\n",
            "918:\tlearn: 0.0885184\ttotal: 27.6s\tremaining: 2.43s\n",
            "919:\tlearn: 0.0885075\ttotal: 27.6s\tremaining: 2.4s\n",
            "920:\tlearn: 0.0884757\ttotal: 27.7s\tremaining: 2.37s\n",
            "921:\tlearn: 0.0884656\ttotal: 27.7s\tremaining: 2.34s\n",
            "922:\tlearn: 0.0884471\ttotal: 27.7s\tremaining: 2.31s\n",
            "923:\tlearn: 0.0884219\ttotal: 27.7s\tremaining: 2.28s\n",
            "924:\tlearn: 0.0884093\ttotal: 27.8s\tremaining: 2.25s\n",
            "925:\tlearn: 0.0883904\ttotal: 27.8s\tremaining: 2.22s\n",
            "926:\tlearn: 0.0883600\ttotal: 27.8s\tremaining: 2.19s\n",
            "927:\tlearn: 0.0883417\ttotal: 27.8s\tremaining: 2.16s\n",
            "928:\tlearn: 0.0883129\ttotal: 27.9s\tremaining: 2.13s\n",
            "929:\tlearn: 0.0883007\ttotal: 27.9s\tremaining: 2.1s\n",
            "930:\tlearn: 0.0882954\ttotal: 27.9s\tremaining: 2.07s\n",
            "931:\tlearn: 0.0882813\ttotal: 27.9s\tremaining: 2.04s\n",
            "932:\tlearn: 0.0882670\ttotal: 28s\tremaining: 2.01s\n",
            "933:\tlearn: 0.0882611\ttotal: 28s\tremaining: 1.98s\n",
            "934:\tlearn: 0.0882254\ttotal: 28s\tremaining: 1.95s\n",
            "935:\tlearn: 0.0882062\ttotal: 28s\tremaining: 1.92s\n",
            "936:\tlearn: 0.0881909\ttotal: 28.1s\tremaining: 1.89s\n",
            "937:\tlearn: 0.0881760\ttotal: 28.1s\tremaining: 1.86s\n",
            "938:\tlearn: 0.0881255\ttotal: 28.1s\tremaining: 1.83s\n",
            "939:\tlearn: 0.0881115\ttotal: 28.1s\tremaining: 1.8s\n",
            "940:\tlearn: 0.0881017\ttotal: 28.2s\tremaining: 1.77s\n",
            "941:\tlearn: 0.0880931\ttotal: 28.2s\tremaining: 1.74s\n",
            "942:\tlearn: 0.0880767\ttotal: 28.2s\tremaining: 1.71s\n",
            "943:\tlearn: 0.0880589\ttotal: 28.2s\tremaining: 1.68s\n",
            "944:\tlearn: 0.0880317\ttotal: 28.3s\tremaining: 1.65s\n",
            "945:\tlearn: 0.0880202\ttotal: 28.3s\tremaining: 1.61s\n",
            "946:\tlearn: 0.0880146\ttotal: 28.3s\tremaining: 1.58s\n",
            "947:\tlearn: 0.0879978\ttotal: 28.3s\tremaining: 1.55s\n",
            "948:\tlearn: 0.0879871\ttotal: 28.4s\tremaining: 1.52s\n",
            "949:\tlearn: 0.0879741\ttotal: 28.4s\tremaining: 1.49s\n",
            "950:\tlearn: 0.0879597\ttotal: 28.4s\tremaining: 1.46s\n",
            "951:\tlearn: 0.0879386\ttotal: 28.5s\tremaining: 1.43s\n",
            "952:\tlearn: 0.0879227\ttotal: 28.5s\tremaining: 1.4s\n",
            "953:\tlearn: 0.0879122\ttotal: 28.5s\tremaining: 1.37s\n",
            "954:\tlearn: 0.0879059\ttotal: 28.5s\tremaining: 1.34s\n",
            "955:\tlearn: 0.0878914\ttotal: 28.6s\tremaining: 1.31s\n",
            "956:\tlearn: 0.0878785\ttotal: 28.6s\tremaining: 1.28s\n",
            "957:\tlearn: 0.0878525\ttotal: 28.6s\tremaining: 1.25s\n",
            "958:\tlearn: 0.0878408\ttotal: 28.6s\tremaining: 1.22s\n",
            "959:\tlearn: 0.0878193\ttotal: 28.7s\tremaining: 1.19s\n",
            "960:\tlearn: 0.0878113\ttotal: 28.7s\tremaining: 1.16s\n",
            "961:\tlearn: 0.0878010\ttotal: 28.7s\tremaining: 1.13s\n",
            "962:\tlearn: 0.0877772\ttotal: 28.7s\tremaining: 1.1s\n",
            "963:\tlearn: 0.0877590\ttotal: 28.8s\tremaining: 1.07s\n",
            "964:\tlearn: 0.0877561\ttotal: 28.8s\tremaining: 1.04s\n",
            "965:\tlearn: 0.0877298\ttotal: 28.8s\tremaining: 1.01s\n",
            "966:\tlearn: 0.0877065\ttotal: 28.8s\tremaining: 984ms\n",
            "967:\tlearn: 0.0876820\ttotal: 28.9s\tremaining: 955ms\n",
            "968:\tlearn: 0.0876623\ttotal: 28.9s\tremaining: 925ms\n",
            "969:\tlearn: 0.0876548\ttotal: 28.9s\tremaining: 895ms\n",
            "970:\tlearn: 0.0876422\ttotal: 28.9s\tremaining: 865ms\n",
            "971:\tlearn: 0.0876166\ttotal: 29s\tremaining: 835ms\n",
            "972:\tlearn: 0.0875986\ttotal: 29s\tremaining: 805ms\n",
            "973:\tlearn: 0.0875907\ttotal: 29s\tremaining: 775ms\n",
            "974:\tlearn: 0.0875893\ttotal: 29s\tremaining: 745ms\n",
            "975:\tlearn: 0.0875779\ttotal: 29.1s\tremaining: 715ms\n",
            "976:\tlearn: 0.0875741\ttotal: 29.1s\tremaining: 685ms\n",
            "977:\tlearn: 0.0875581\ttotal: 29.1s\tremaining: 655ms\n",
            "978:\tlearn: 0.0875512\ttotal: 29.1s\tremaining: 625ms\n",
            "979:\tlearn: 0.0875322\ttotal: 29.2s\tremaining: 595ms\n",
            "980:\tlearn: 0.0875305\ttotal: 29.2s\tremaining: 565ms\n",
            "981:\tlearn: 0.0875110\ttotal: 29.2s\tremaining: 536ms\n",
            "982:\tlearn: 0.0874957\ttotal: 29.2s\tremaining: 506ms\n",
            "983:\tlearn: 0.0874780\ttotal: 29.3s\tremaining: 476ms\n",
            "984:\tlearn: 0.0874658\ttotal: 29.3s\tremaining: 446ms\n",
            "985:\tlearn: 0.0874419\ttotal: 29.3s\tremaining: 416ms\n",
            "986:\tlearn: 0.0874086\ttotal: 29.3s\tremaining: 387ms\n",
            "987:\tlearn: 0.0873930\ttotal: 29.4s\tremaining: 357ms\n",
            "988:\tlearn: 0.0873801\ttotal: 29.4s\tremaining: 327ms\n",
            "989:\tlearn: 0.0873725\ttotal: 29.4s\tremaining: 297ms\n",
            "990:\tlearn: 0.0873566\ttotal: 29.5s\tremaining: 268ms\n",
            "991:\tlearn: 0.0873436\ttotal: 29.5s\tremaining: 238ms\n",
            "992:\tlearn: 0.0873208\ttotal: 29.5s\tremaining: 208ms\n",
            "993:\tlearn: 0.0873081\ttotal: 29.5s\tremaining: 178ms\n",
            "994:\tlearn: 0.0873009\ttotal: 29.6s\tremaining: 149ms\n",
            "995:\tlearn: 0.0872783\ttotal: 29.6s\tremaining: 119ms\n",
            "996:\tlearn: 0.0872683\ttotal: 29.6s\tremaining: 89.1ms\n",
            "997:\tlearn: 0.0872512\ttotal: 29.6s\tremaining: 59.4ms\n",
            "998:\tlearn: 0.0872412\ttotal: 29.7s\tremaining: 29.7ms\n",
            "999:\tlearn: 0.0872371\ttotal: 29.7s\tremaining: 0us\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.97      9131\n",
            "           1       0.97      0.96      0.97      9130\n",
            "\n",
            "    accuracy                           0.97     18261\n",
            "   macro avg       0.97      0.97      0.97     18261\n",
            "weighted avg       0.97      0.97      0.97     18261\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "rnd_clf = RandomForestClassifier(n_estimators=10, random_state=42)\n",
        "\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('xb', xgb_classifier), ('lgbm', estimator), ('ct', model_cb), ('rf',rnd_clf),('lr', model)],\n",
        "    voting='hard')\n",
        "\n",
        "voting_clf.fit(X_train, y_train)\n",
        "predict=voting_clf.predict(X_test)\n",
        "\n",
        "print (classification_report(y_test,predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBZRR8iddopa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78adddb3-9c93-4f31-f829-58be4b2162a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.966485821623028"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "balanced_accuracy_score(y_test, predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5YTzDFIl3Yj"
      },
      "outputs": [],
      "source": [
        "#test['malware'] = model.predict(test[features])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Slk-MEIl3l4"
      },
      "outputs": [],
      "source": [
        "#sub = test[['hash', 'malware']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Eimzr23mBX9"
      },
      "outputs": [],
      "source": [
        "#sub.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SSi3zotmPlN"
      },
      "outputs": [],
      "source": [
        "#sub.to_csv('results.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}